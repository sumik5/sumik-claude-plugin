# LLM Evaluation

大規模言語モデルの評価は困難だが不可欠。評価手法、メトリクス、失敗モード、RAG/エージェントシステム特有の評価、オブザーバビリティパイプライン、自動化戦略を包括的に解説する。

---

## 目次

1. [なぜ評価が難しいのか](#なぜ評価が難しいのか)
2. [パフォーマンス評価](#パフォーマンス評価)
3. [失敗モードの早期検出](#失敗モードの早期検出)
4. [RAGアプリケーションのメトリクス](#ragアプリケーションのメトリクス)
5. [エージェントシステムのメトリクス](#エージェントシステムのメトリクス)
6. [一般的な評価考慮事項](#一般的な評価考慮事項)
7. [自動メトリクスの価値](#自動メトリクスの価値)
8. [モデルドリフト](#モデルドリフト)
9. [従来メトリクスの限界](#従来メトリクスの限界)
10. [オブザーバビリティパイプライン](#オブザーバビリティパイプライン)
11. [AskUserQuestion指針](#askuserquestion指針)

---

## なぜ評価が難しいのか

### 評価の定義

LLM評価はパフォーマンスと能力を評価するプロセス。意図された目的をどれだけ達成し、倫理的ガイドラインを遵守しているかを判定する手法の組み合わせ。

### MLとLLMの違い

| 観点 | 従来のML | LLM |
|------|---------|-----|
| **ランダム性** | 学習時のみ使用、推論は決定論的（同じ入力→同じ出力） | 学習・推論両方で使用、非決定論的（同じ入力→異なる出力の可能性） |
| **テスト方法** | 集約データセット・特定の原子的データで検証 | 同上だが、同じ入力でも異なる出力が発生するため追加の考慮必要 |
| **解釈可能性** | 解釈ツール利用可能（大量例を実行し入力変化が出力に与える影響を測定） | パラメータ数が膨大で非決定論的なため解釈ツール未発達 |

### 評価の必要性

運用MLソリューションは本番稼働前に期待パフォーマンス特性を提供し、デプロイ後のパフォーマンス問題を特定・修正する効果的な監視方法が必要。

モデル評価は以下を支援：

- モデルが期待通り動作しているか確認
- 改善領域の特定
- 安全で責任ある使用の確保

### 評価が困難な理由

| 理由 | 説明 |
|------|------|
| **言語の複雑性** | 人間の言語は複雑で定量化困難、正確な品質評価メトリクス開発が難しい |
| **大規模データセット** | 大量テキストで学習されるため、モデルが未見のテキストサンプルを見つけることが困難 |
| **バイアス** | 学習データセットに沿ったバイアスを示し、社会的・倫理的・法的規範に違反するテキストを生成する可能性 |
| **再現性・一貫性** | なぜ特定の出力を生成したのか解釈が困難で、再現性と一貫した実験設計に課題 |
| **無限の可能性** | 膨大なデータで学習、受信可能な入力数は実質無限、すべてのシナリオを網羅的テストは不可能 |

### 評価カテゴリ

膨大な可能性すべてをテストできないため、以下のシナリオカテゴリで評価：

#### 情報性と事実性

- 出力は事実的に正しいか
- 入力プロンプトに関連する十分な情報を含むか
- 生成テキストは入力への完全な応答か

#### 流暢性と一貫性

- 出力は文法的に正しく読みやすいか
- 論理的な流れに従っているか
- 出力言語は適切なレベルか

#### エンゲージメントとスタイル

- LLM出力はどれだけ魅力的で興味深いか
- ライティングスタイルは適切か

#### 安全性とバイアス

- このLLMはどのような有害コンテンツを生成する可能性があるか
- 出力が人々をリスクにさらす用途に使用される可能性があるか
- 出力はバイアスのある概念や言語を使用しているか

#### グラウンディング

- LLMの応答は実世界情報にどれだけグラウンドされているか
- 適切な参照を提供しているか
- ハルシネーションを避けているか

#### 効率性

- LLMが出力生成に必要な計算リソースは何か
- 応答生成開始までの時間はどれくらいか
- 完全な応答生成にかかる時間はどれくらいか

### 「良いパフォーマンス」の曖昧性

画像認識の精度（「これは鳥の写真か？」）のような明確な成功メトリクスを持つタスクとは異なり、LLMからの「良い」応答の定義は主観的。出力は関連情報を提供しているか？創造的か？事実的に正確か？これらの目標は対立する可能性があり、すべてをキャプチャする単一メトリクス設計は困難。

---

## パフォーマンス評価

### 評価方法

| 方法 | 説明 | 利点 | 欠点 |
|------|------|------|------|
| **手動チェック** | 出力の正確性・正しさを手動で確認 | - | 時間がかかる、評価者の判断に依存 |
| **自動評価** | ツールでLLM出力の正確性を評価（LLMでLLMを評価） | 自動化可能 | LLM自身のバイアス・限界に依存 |
| **ユーザーフィードバック** | ユーザーからの直接フィードバック | 実世界パフォーマンスを反映 | 収集コスト・時間がかかる |

### アプリケーションなしに評価は不可能

多くのLLMアプリでは、ユーザーは有用な実世界パフォーマンスメトリクスを知っている。例えば、LLMでWeb広告用テキストスクリプトを生成する場合、人間がコピーを書くときの典型的な評価方法は**A/Bテスト**：類似オーディエンスA・Bにランダムに異なるオプションを提供し、成功率（例: 広告クリック数）を測定。オプションAとBの成功率が統計的に有意に異なる場合、より成功したスクリプトを選択。LLM生成コピーにも同じ方法を使用可能。

多くの一般的MLタスク（テキスト分類、画像識別、オブジェクトカウント等）では、既存のpre-LLMメソッド・メトリクスを単純に使用することが理にかなっている。

### 生成メトリクスの種類

#### 1. n-gramベースメトリクス

生成テキストと既存データの類似度を、*n*語のシーケンスの重複で評価。期待される「正解」答えを知っている必要があり、LLMが生成した*n*語のうちいくつが正解に含まれるかを比較。

- **n = 1**: 個別単語を比較
- **n = 2**: 単語のペアを比較
- **以降同様**

**例**:

- **Q**: What's the capital of France?
- **A（期待）**: Paris
- **LLM回答1**: Paris → 100%マッチ
- **LLM回答2**: The capital of France is Paris. → 16.6%マッチ（"Paris"のみ一致）

n-gramテストはシンプルだが、完全な正しい答えでもスコアが低くなる可能性。

#### 2. 類似度ベースメトリクス

生成テキストと参照テキストの類似度の様々な側面を捉える。埋め込みを計算して比較し、文全体の意味的類似度を測定。

| メトリクス | 説明 |
|---------|------|
| **BERTScore** | コンテンツの重複と流暢性の両方を測定 |
| **SemScore** | 生成テキストが参照テキストと同じ意味・意図を伝えるか確認 |
| **MoverScore** | あるテキストを別のテキストに変換するのに必要な最小「作業量」を計算 |

**例**:

- "It's Paris"
- "The capital of France is Paris"

両方とも高スコアを生成（意味的に類似）。

**問題点**:

- "Teh KaPiTaLL of Franceland is PARIS" → スペルミス・造語があっても意味的類似度は高い

#### 3. LLMベースメトリクス

他のLLMを使用してターゲットLLMの生成品質を評価し、潜在的なハルシネーションを特定。正解を識別し、流暢性・文法的正確性も評価可能だが、計算コストが高い。

| メトリクス | 説明 | 論文リンク |
|---------|------|----------|
| **G-Eval** | 他のLLMが判断した一貫性・流暢性・事実的一貫性に基づき生成テキストをスコアリング | [リンク](https://oreil.ly/IzuUL) |
| **UniEval** | 流暢性・文法性・事実的一貫性などの複数要因をLLM評価者のアンサンブルで考慮 | [リンク](https://oreil.ly/nMMsh) |
| **GPTScore** | GPT系モデル専用、一貫性・安全性・事実的一貫性を評価 | [リンク](https://oreil.ly/ylJna) |
| **TRUE** | 他のLLMで事実的正確性を評価し、潜在的な事実的ハルシネーションを特定 | [リンク](https://oreil.ly/UwZvJ) |
| **SelfCheckGPT** | GPTモデル専用、生成テキスト内の論理的不整合・事実的エラーを特定 | [リンク](https://oreil.ly/8AKE9) |

**重要**: これらメトリクスは特定ユースケースに設定可能。論文で例として質問・回答が提供されているが、ユースケースに適用可能な質問・回答データベースを生成すべき。

### 一般ベンチマーク

プラットフォームレベルのLLM（Google Gemini、OpenAI ChatGPT等）を構築する場合に有用。特定タスクのパフォーマンスは保証されないため、注意が必要。

#### 主要ベンチマーク

| ベンチマーク | 説明 | フォーカス |
|------------|------|----------|
| **GLUE (General Language Understanding Evaluation)** | コアNLP能力を評価するタスクスイート | 自然言語理解（NLU） |
| **SuperGLUE** | GLUEの後継、より挑戦的なタスク | NLU |
| **HellaSwag** | 推論と常識理解に焦点 | 自然言語推論（NLI） |
| **TruthfulQA** | 事実的正確性とハルシネーション回避を評価 | 質問応答（QA） |
| **MMLU (Massive Multitask Language Understanding)** | 多様なタスクの大規模ベンチマーク | マルチタスク学習 |

#### ベンチマークの問題点

| 問題 | 説明 |
|------|------|
| **公開されている** | LLM開発者が単にベンチマークで良好なパフォーマンスを示すように学習させる可能性（学生が試験の答えを暗記するのと同様） |
| **プロンプト感度** | 学習データとプロンプトの互換性に高度に敏感。プロンプトの小さな変更で出力が劇的に異なる可能性（例: "think step-by-step"、"please"の追加で結果が変わる） |
| **質問の繰り返し** | LLMは質問の一部を繰り返し・言い換えて応答に含めることで理解・同意の誤った感覚を作り出す（答えの品質が低くても関連性が高く見える） |

**結論**: ベンチマークはLLM間の比較に有用だが、限界を認識し注意して使用すべき。

---

## 失敗モードの早期検出

### 失敗モードとは

LLM本番環境での初期失敗は散発的で予測不可能に見えたが、使用拡大・データ蓄積により、より一貫したパターンが浮上。これらは従来のソフトウェアバグ（セグメンテーションフォールト・クラッシュ）ではなく、**失敗モード**と呼ばれる。

**失敗モード**は、モデルの内部仮定と実世界データ・相互作用の複雑な現実とのミスマッチによる、再発性のある説明可能な故障。表面的には正常動作し、構文的に有効・スタイル的に一貫した出力を生成するが、事実的に誤っている・倫理的に問題がある・構造的に欠陥がある可能性。この微妙さが失敗モードを特に陰湿にし、従来のデバッグ方法では検出困難。

### 評価パラダイムの進化

反応的デバッグから予防的アプローチへ。ユーザーを混乱させる前に失敗モードを予測・検出する。洗練された監視フレームワークが必要：

- 自動メトリクス
- Human-in-the-Loopバリデーション
- ドメイン固有チェック

これによりモデル仮定が成立しなくなったとき、出力が期待動作から逸脱したときを特定。評価をポストホック修正から継続的・予防的監視にシフトすることで、LLMデプロイの信頼性・安全性・倫理的統合性を確保。

### 一般的な失敗モードと評価ポイント

| 失敗モード | 評価箇所 | ツール/シグナル |
|---------|---------|--------------|
| **ハルシネーション** | Retrieval, Prompt, Inference | ソースとの類似度、事実チェック |
| **プロンプト回帰** | Orchestration | プロンプト差分、品質劣化ログ |
| **レイテンシスパイク** | Inference, Retrieval | p95/p99レイテンシメトリクス、トレーシング |
| **データドリフト** | Input, Retrieval | 埋め込みシフト、クラスタ分布 |
| **一貫性のない動作** | Inference | セッションレベルトレーシング、繰り返しクエリ |
| **安全性違反** | Output | 毒性フィルタ、PII検出 |

### 1. ハルシネーション

LLMが言語的に流暢で自信ありげだが、事実的に誤っている・完全に捏造された応答を生成する現象。LLMは信頼性のある最新の事実ナレッジベースをクエリするのではなく、学習データに基づき統計的に最も可能性の高いトークンシーケンスを予測してテキストを生成するために発生。

#### 評価アプローチ

- **ログ記録**: 全生成出力をログ
- **グラウンドトゥルース比較**: 可能な場合、検証されたグラウンドトゥルースと比較
- **一貫性チェック**: グラウンドトゥルースがない場合、モデル応答の複数生成で矛盾・不安定性を検出
- **RAGシステムでの注意**: ハルシネーションは検索コンポーネントの問題（無関係・古い・低品質文書の取得）を示唆することが多い

#### 監視フレームワーク

検索・推論レイヤー全体のオブザーバビリティを維持。取得文書の品質・関連性をモデル出力と並行して追跡。根本原因理解により、検索精度向上・信頼性の高いナレッジソース統合・生成中検証メカニズム組み込みなどのターゲット緩和策を設計可能。

### 2. プロンプト回帰

プロンプトテンプレートへの一見マイナーな変更（変数リネーム・空白挿入削除・フォーマット調整）が予期せずモデル出力の品質を劣化させる。劣化は即座には明らかでなく、リアルタイム検出・診断が困難。

#### 課題

LLMの固有の**非決定論性**: 同じ入力で異なる出力を生成する可能性（サンプリング方法・確率的トークン予測による）。プロンプト回帰の一貫した再現が困難で、従来デバッグアプローチに大きな障壁。

#### 管理手法

- **詳細なプロンプトバージョニング・ログ**: 細かいレベルで変更を追跡
- **プロンプト差分サポート**: バージョン間で何が変更されたかを正確にハイライト
- **メトリクスとの相関**: プロンプト変更と測定可能メトリクス（応答の有用性・事実的正確性・構造的一貫性の低下）を関連付け、回帰が現れ始めるタイミング・方法を正確に特定

これにより効果的な根本原因分析が可能になり、問題のあるプロンプトイテレーションを迅速特定。より重要なことに、回帰検出時に以前の安定したプロンプトバージョンにロールバックでき、出力品質とユーザー信頼を維持。

### 3. レイテンシスパイク

システムの知能・洗練度に関係なく、ユーザーは一律に遅く応答しない体験を拒否。特に高パーセンタイル（p95/p99）のレイテンシは、頻度は稀だが、目立つ遅延を引き起こし、相互接続システムでダウンストリームタイムアウト・失敗をトリガーする可能性があり、ユーザー体験に不均衡な影響を与える。

#### 評価要件

- **継続的・細粒度監視**: 平均応答時間だけでなくトークン使用パターン・システムレベルメトリクスも追跡
- **早期検出**: サービス品質が大規模に劣化する前にレイテンシ急増を検出

#### ロバストトレーシングメカニズム

レイテンシスパイク発生時の根本原因分析に不可欠。エンジニアがリクエストパイプラインを解剖し、ボトルネック・障害点を特定可能。

**潜在的原因**:

- 過度に長い入力プロンプト（処理時間増加）
- 関連文書取得の遅延
- アップストリーム依存（ベクトルDB・外部API）のボトルネック
- 基礎モデルバージョン・システムインフラの変更による予期しないレイテンシ回帰

このレベルのオブザーバビリティなしでは、エンドユーザーがパフォーマンス劣化・失敗を経験するまでレイテンシスパイクは監視ダッシュボード・アラートシステムに見えない。エンドツーエンドトレーシング・リアルタイムレイテンシ監視を評価ワークフローに組み込むことは、スムーズで予測可能なシステム動作維持、一貫して応答性のあるユーザー体験確保に不可欠。

### 4. データドリフト

ライブ本番環境では、ユーザー動作と入力データは継続的に変動。この動的な状況により**データドリフト**が発生：システムに組み込まれた基礎仮定（期待される入力フォーマット・ユーザー意図の分布・コンテキスト埋め込みの性質）が受信データの進化する現実から徐々に乖離。

#### ドリフトの種類

| ドリフトタイプ | 説明 |
|------------|------|
| **Input Drift** | 元の学習/設計期待から逸脱する敵対的・不正形式のクエリの増加。システムのロバスト性にストレスをかけ出力品質を劣化 |
| **Retriever Drift** | 検索アルゴリズム・設定が変わらなくても、返される文書の関連性が低下 |
| **Embedding Drift** | セマンティック類似度比較に使用されるベクトル表現の効果が低下、安定したシステムパラメータにもかかわらず検索システム失敗 |

#### 評価手法

- **入力特徴分布の統計監視**: 時間経過での分布変化を追跡
- **クエリタイプのクラスタ分析**: 新興ユーザー意図・相互作用パターンの検出
- **トークン長ヒストグラム**: 入力冗長性のシフトを追跡
- **埋め込み類似度スコア継続測定**: セマンティック表現の微妙なシフトをキャッチ

これらの定量的早期警告シグナルにより、エンジニアリングチームはシステム仮定が成立しなくなるタイミングを予測可能。

#### 予防的対応

ドリフトを予防的に検出することで、劣化がエンドユーザーに目立つ前に介入機会を得る：

- モデル再学習
- 検索インデックス更新
- プロンプトテンプレート再設計

この予防的アプローチにより、システムは進化するデータ景観にシームレスに適応し、時間経過とともに正確性とユーザー満足度を維持。

### 5. 一貫性のない動作

LLM生成の固有の確率的性質により、全く同じクエリを複数回繰り返すと、毎回異なる応答が得られる可能性（**非決定論**）。この変動性は確率的トークンサンプリング戦略の自然な結果で、生成テキストの多様性・創造性を促進。しかし、監査可能性・コンプライアンス・再現性が重要なユースケースでは、このランダム性が根本的な課題。一貫性のない出力は信頼を損ない、デバッグを複雑化し、規制要件に違反する可能性。

#### 評価・管理要件

**セッションレベルトレーシングフレームワーク**が必要。単に入出力をログするだけでなく、リッチなコンテキストメタデータをキャプチャ：

- **モデルハイパーパラメータ**: temperature, top-kサンプリング値
- **特定モデルバージョン**
- **関連する事前会話履歴/ユーザー相互作用**

この包括的トレースにより、チームは与えられた出力を生成した正確な環境・条件を再構築・分析可能。

#### 利点

- **変動性パターン特定**: 出力の一貫性のなさと特定設定・コンテキスト変更を関連付け
- **再現性強制**: 必要に応じてサンプリングパラメータを固定/相互作用シーケンスを再生
- **デプロイの責任**: 監査可能・検証可能な動作が必須の敏感なドメインでLLMを責任持ってデプロイ可能

#### 一貫性選択的強制

決定論的デコード戦略（greedy/beam search）で一貫性を強制可能だが、通常は出力多様性を犠牲にする。重要なのは、必要に応じて一貫性をバランスし、重要な場合に一貫性のなさを強調する監視システムを構築すること。

### 6. 倫理・コンプライアンスリスク

LLMは不注意に有毒コンテンツ・バイアスのある言語を生成、個人情報を漏洩、ジェイルブレイクプロンプトに脆弱になる可能性。これらのリスクは深刻な法的・評判的結果を伴う。

#### 緩和手法

- **自動フィルタ・分類器統合**: リアルタイムで問題のある出力をフラグ
- **メトリクス収集**: 安全性スコア、毒性インデックス、バイアス測定をモデルメタデータと共に監査目的で収集

---

## RAGアプリケーションのメトリクス

### RAGアプリワークフロー

RAGアプリケーションはLLMを使用してテキスト生成するが、ナレッジベースからデータを取得しユーザープロンプトに追加することでLLMの精度を向上させる。

#### ワークフローステップ

1. **User Input**: ユーザーが質問/プロンプトをRAGアプリに送信
2. **Retrieval**: 関連文書/テキストデータのデータベースを検索（*n*件の記事・マニュアル・コードスニペット等）。ベクトル類似度検索等の技術でユーザークエリに基づき最も関連する部分を特定
3. **Prompt Augmentation**: 開発者が作成したプロンプト・前ステップで取得したテキスト・元のユーザー入力を連結
4. **LLM Generation**: 拡張プロンプトをLLMに送信、追加コンテキストを使用して応答生成・ユーザーに提示

### 検索メトリクス

一般的な生成メトリクスに加え、RAGは検索コンポーネントの有効性を評価する検索メトリクスの恩恵を受ける。

| メトリクス | 説明 | 計算方法 |
|---------|------|---------|
| **Recall (再現率/感度/真陽性率)** | システムが重要な資料をどれだけ徹底的に収集するか | グラウンドトゥルース文書コレクション（専門家が既にクエリに関連すると判断）と検索ステップが生成した文書の重複を見る。エンジンがほぼすべての専門家識別項目を表面化すれば再現率は高い。多くを逃せば低い。パーセンテージで測定 |
| **MRR (Mean Reciprocal Rank)** | ユーザーが最初の本当に有用な結果を見る速さ | 各クエリについて、ランクリストを上からスキャンし最初の関連文書に遭遇するまでの位置を記録。1位理想、5位は印象的でない等。位置をスコアに変換（早い出現を報酬）し多くのクエリで平均。高MRRはユーザーが通常ページ上/近くで関連するものに遭遇することを意味。典型的なスコアリング: *n*文書取得の検索で、正解が1位なら*n*ポイント、2位なら*n*-1ポイント... |
| **MAP (Mean Average Precision)** | リスト全体での関連項目の配置と一貫性を評価 | 単一クエリの結果をダウンしながら、別の関連文書が表示されるたびに実行中集計を保持し、これまで見たもののうち関連する割合をチェック。リスト終了時、これらの中間分数を平均し1つのクエリを要約。多くのクエリで再度平均しMAP生成。例: 3件結果が期待され、3件とも関連なら平均精度100%。1位2位関連なら(100%+100%+0%)/3=67%。1位3位関連なら(100%+0%+67%)/3=56%。2クエリのMAP=(67%+56%)/2=61%。高値は関連文書が頻繁に表示され結果の上部に分散、疎に散在/下部束ではないことを示す |
| **Context Precision (コンテキスト精度)** | 再現率の裏返し：検索者が返したもののうちどれだけが本当に役立つか | 各パッセージを検査し言語モデルタスクをサポートするかノイズを追加するだけかを決定。取得結果の大部分がグラウンドトゥルース文書コレクションと一致すればコンテキスト精度高、無関係/誤解を招くパッセージが支配すればスコア低下。パーセンテージで測定 |
| **Relevance (関連性)** | 精度と再現率のバランス | 取得セットが必要な事実をどれだけ完全にカバーし、余分な材料がどれだけないかを考慮。高関連性は言語モデルに供給されるコンテキストがほぼすべての重要情報を含み、雑然性を回避し、正確で焦点を絞った応答のための理想的な基盤をモデルに与えることを意味。精度と再現率の単純平均（または合計）で計算可能だが、実務者は通常精度と再現率の調和平均（F1スコア）を取る。これにより60%精度60%再現率のようなバランス結果が90%精度30%再現率のような不均衡結果よりも高スコアになる |

### 評価ツール

| ツール | タイプ | 説明 |
|-------|--------|------|
| **Ragas** | フレームワーク | Python、事前構築機能・合理化ワークフロー、前述のすべてのメトリクス測定可能、単一スコアで要約、ユーザーフレンドリー・明確ドキュメント・例提供 |
| **LangSmith** | カスタマイズ可能評価者 | 独自メトリクス定義・データセット追加・CI/CDツール統合可能。SDK提供、開発中テスト実行可能、新モデルデプロイ時に自動テスト実行可能（CI/CDツールでデプロイ後に新モデルにプロンプト送信・LangSmithで回答評価スクリプト作成）、本番で固定データセットで定期テスト実行可能（**ドリフト**検出：モデルパフォーマンスの時間経過変化。同じテスト・同じデータセットで同じスコア期待だが、OpenAI GPT API/Google Gemini API等LLMサービス使用時はコントロール外で基礎モデルが変わる可能性。**モデルドリフト**と呼ばれ、定期テストで検出可能） |

---

## エージェントシステムのメトリクス

### エージェントシステムとは

2024年後半から**エージェントシステム**という用語が普及。LLMコンテキストでは、複数の内部モジュール・複数ステップを持ち、戦略的な人間監視のみで高レベル目標を追求するため自律的に計画・決定・行動できるAIシステム。

#### ワークフロー

ユーザーがリクエストを調整LLMに送信 → リクエストをタスクに分解 → 各タスクを自身・他のLLM・専門プログラムに送信 → レスポンスをコンパイルしユーザーに提供。

このマルチステッププロセスは多数の評価問題を生成。

### 追加の複雑性

| 複雑性 | 説明 |
|-------|------|
| **動的動作** | エージェントは相互作用に基づき創発的動作を示す可能性、結果・発生タイミングの予測困難 |
| **コンテキスト感度** | エージェントパフォーマンスはコンテキストで大幅に変動、様々なシナリオでの広範なテスト必要 |
| **継続学習** | 多くのLLM・エージェントは相互作用に基づき時間経過で適応、静的評価の関連性低下 |
| **フィードバックループ** | エージェント間のフィードバックループが非線形効果を生み出し再現困難 |
| **既存システムとの統合** | 実世界環境でエージェントをデプロイすると、シミュレーション設定にない予見しない問題が明らかに |
| **環境変動性** | 運用環境の変化が予期しない動作につながり評価プロセス複雑化 |
| **複数目標** | エージェントは対立する目的を持つ/複数基準のバランスが必要な方法で協力する可能性、評価メトリクス複雑化。個別に貧弱なメトリクスの2エージェントが、より良い個別メトリクスの2エージェント協力より優れたコラボレーション・出力を生成することがある |
| **普遍的な受け入れメトリクス不在** | エージェントシステム評価の普遍的に受け入れられたメトリクスセットがなく、不整合につながる |
| **リソース制約** | 計算能力・メモリのリソース制約が評価量を制限。リソース消費は異なる構成で大きく変動しスケーラビリティ評価に影響 |

### 実践的評価アプローチ

エージェントコラボレーションの最終製品を評価する方が容易。

#### 主な評価方法

| 方法 | 説明 | 利点 | 欠点 |
|------|------|------|------|
| **人間評価者** | - | ゴールドスタンダード | 高コスト・時間がかかる |
| **LLM評価者** | LLMを使用して別のモデル評価 | コスト・品質・有効性の良いバランス | 時々バイアスあり、不透明、リソース集約的 |

**注意**: LLM評価者を使用する場合、完全に放置しない。評価モデル自体のパフォーマンス低下の可能性があるため、ある程度の人間ダブルチェックを推奨。

### LLMベースエージェントシステムの4つの主要評価目的

#### 1. 内部プロパティ検査

コア言語スキル・コンテキスト把握・学習と知識転送能力・創発的能力（emergent behaviors）の出現しやすさを調べる。新環境/タスクへの適応速度・複数エージェントの効果的な協力も評価。

**エビデンス源**:

- 回答の一貫性・関連性
- ライブ相互作用中の理解
- 制御シナリオでの意思決定
- 状況変化への応答性
- ログとシミュレーション（集団動作）
- 縦断的テスト（時間経過でのパフォーマンス向上・停滞・劣化）

**測定**: 前述定義のメトリクス使用可能。

#### 2. エンジニアリングレベルパフォーマンス監査

効率性・スケーラビリティ・間違い発生時のロバスト性を評価。タスク実行に使用される計算リソース測定。ストレステストでエージェント数/ワークロードをスケールアップした際の動作確認。フォールトインジェクション実験で敵対条件下のレジリエンスと回復戦略を調査。

#### 3. 相互作用品質に焦点

人間ユーザーに対する対話の魅力・明瞭性・信頼性を評価。

**測定**:

- **定量メトリクス**: セッション長、ターンテイキング頻度、レスポンスレイテンシ（エンゲージメント定量化）
- **調査**: 認識信頼性・会話一貫性・関係の暖かさを調査
- **観察研究**: 実世界使用でユーザーがエージェント周りで実際にどう行動するかを記録

#### 4. ユーザー満足度測定

人々がシステムが目標達成を助けると感じる必要があり、肯定的な感情的印象を残すべき。タスク成功に関する明示的フィードバック（各応答後のサムズアップ/ダウン等）、ユーザーコメントのセンチメント分析、瞬間的感情と全体的承認の両方を測定する調査を実施。

**典型的測定: NPS (Net Promoter Score)**

「タスクにこのシステムを推薦する可能性はどれくらいですか？」と尋ね、0～10のスコアを付与。

- **9-10**: Promoters（推奨者）
- **0-6**: Detractors（批判者）
- **NPS = %Promoters - %Detractors**
- **範囲**: +100（全ユーザーがPromoter）～ -100（全ユーザーがDetractor）
- **+30以上**: 強力なパフォーマンス

これら4つの視点（システムプロパティ・技術パフォーマンス・相互作用品質・ユーザー満足度）を組み合わせることで、エージェントLLMシステムが実際にどれだけうまく動作するかの総合的・補完的な見方を提供。

### 開発ステージ別評価戦略

エージェントシステムの複雑性を考慮し、実務者は通常、システム開発プロセスの異なるステップで異なる測定戦略を使用。

#### Stage 1: モデル開発・学習・エージェントシステムへの統合

モデルがまだラボ内にある間は**内在能力**に焦点：

| 項目 | 測定方法 |
|------|---------|
| **言語能力** | 応答一貫性・エンドユーザー理解を追跡。この章で説明した生成メトリクスと関連ツール使用可能 |
| **統合** | ユーザーリクエスト時にエージェントシステムの各コンポーネントがどう使用されるか測定。適切なエージェントがタスクに関与しているかテスト。例: 数学を実行するプログラム（計算機エージェント）があり、ユーザーが数学質問入力時にオーケストレーティングLLMがそれを呼び出すべき場合、実際にそうなっているか確認。そうでなければオーケストレーティングプロンプト調整必要 |

#### Stage 2: エージェントシステムデプロイ

学習済みモデルチェックポイントを持ち、「人々はこのシステムを信頼し有用と感じるか？」を問う：

| 項目 | 測定方法 |
|------|---------|
| **信頼と信頼性** | 調査ベース内部ユーザー信頼スコア使用。前述定義のNPSメトリクスがユーザーがシステムを好み有用と感じるかの良い指標 |
| **ユーザー-エージェント関係** | 長文ユーザーインタビューと迅速なユーザー満足度投票でテストユーザーのシステムに対する感じ方を教える |
| **全体的満足度と認識有効性** | A/Bタスク、成功率集計、オープンテキストフィードバックのセンチメント分析でグラウンドトゥルース提供 |

実顧客に公開前に制御されたサンドボックスでデータ収集容易にするため、組み込み調査ウィジェットが有効。

#### Stage 3: 本番

大規模では、高次現象と運用健全性を監視：

| 項目 | 測定方法 |
|------|---------|
| **エージェントコンポーネント利用率** | コンポーネントエージェントが期待通り使用されているか確認。期待ユーザーワークロードを見越して複数の専門エージェントを作成したが、一部が使用されていない場合、それらをシャットダウンし機能をオーケストレーティングLLMに移動して迅速に回答提供することが理にかなう可能性 |
| **エンゲージメント** | 平均セッション期間・ユーザーごとの相互作用頻度をチャーンの主要指標として測定。ユーザーはタスクを完了しているか？日々戻ってより多くのタスクを完了しているか？ |
| **計算効率** | 任意の計算システム同様、計算リソース監視。平均タスク完了時間・リソース利用率（CPU/GPU）をログしクラウド請求が急増する前にボトルネックを発見 |

---

## 一般的な評価考慮事項

### ユーザー中心評価

最終的にシステムの成功はユーザーによって測定される。自動測定可能メトリクスの主な目標は、ユーザーを苛立たせることなくエラーをキャッチしシステムを改善し、ユーザー体験向上。しかし、できる限り、製品と相互作用する際の信頼・満足度の変化を追跡する長期ユーザー研究を実施すべき。

### 迅速なフィードバック収集

**NPS**: 成功の迅速で有用な1質問指標。広く多くの業界で採用。

**満足度ウィジェット**: 各相互作用後にユーザーフィードバック収集（例: 各応答後に「サムズアップ」「サムズダウン」ボタン追加）、実世界相互作用でユーザーフィードバック提供。

### 商用監視プラットフォーム

**Weights & Biases**: 商用監視プラットフォーム

**LangSmith**: この章で前述したツール。本番でエージェントシステムの出力を自動評価可能。Weights & Biasesでメトリクス収集・ダッシュボード表示・定義した閾値より低くなったときにアラート発行。

### 反復的改善

即座のユーザーフィードバックのチャネルを統合することで、ユーザー相互作用から学びアプリを時間経過で改善可能。フィードバック収集とアプリ更新の反復的プロセスにより、アプリがユーザー好みに適応し、最終的に信頼と満足度を向上。

---

## 自動メトリクスの価値

### 変更改善の検証容易化

自動メトリクスにより、変更がアプリを改善しているかを確認しやすくなる。

**例**: 画像説明テキスト生成アプリで、既存プロンプトがNPS 90%だが、新しい論文が異なるプロンプト技術（例: 箇条書き使用）を提案。メトリクスが自動化されている場合、A/Bテスト作成が容易：

- **オーディエンスA**: 既存プロンプト（NPS 90%付近を期待）
- **オーディエンスB**: 新プロンプト
- **オーディエンスBのNPSが高ければ**: 全員を新プロンプトに切り替え決定可能

### 計算効率向上

A/Bテストの別用途は計算効率向上。LLMOps実務者は同じパフォーマンスを維持しながらプロンプトを縮小しようとする。ほとんどのLLMがプロンプトサイズに基づき価格設定/リソース消費するため、与えられた品質閾値を達成する最小プロンプトを使用したい。

LLMを使用して既存プロンプトを要約/削減し元のプロンプトの意味・意図を維持することも可能。自動メトリクスがあれば、複数プロンプトをテストしパフォーマンス要件を達成する最小のものを選択可能。膨大な金額とリソース節約可能。もちろん自動メトリクスなしでも可能だが、遥かに時間がかかる。

---

## モデルドリフト

LLMは常に開発中で、新しいモデル・新モデルバージョンが常に登場。モデル変更によりアプリのパフォーマンスがドリフトする可能性。改善する場合もあれば低下する場合もある。測定しなければ分からない。

### 例: GPT-3.5 Turbo

人気のGPT-3.5 Turboモデルには4つのバージョンがあり、最初の2つは2025年2月13日に動作停止。「自動更新」に設定したユーザーは、これら非推奨バージョンへの呼び出しが自動的に最新バージョンに移行開始。他のユーザーはエラーを返し始めた。

両ケースでLLMOpsが役立つ。後者は基本的な監視システム（失望したユーザーからの大量の怒りメール受信）でさえキャッチする。

前者（モデルが自動的に新バージョンに変更）は予期しない問題を生成可能。例えば、以前のモデルバージョンでエラー防止のため実装したガードレールが不要になる可能性。典型的ケースはバイアス・攻撃的回答に対する防御にプロンプトの大部分を割くこと。新しいモデルバージョンは通常、既知の攻撃に対する防御を組み込むため、プロンプトにこれら防御を含めることが金の無駄になる可能性。

より困難なシナリオはパフォーマンスが予期せず低下するとき。旧バージョンで動作したプロンプトが新バージョンで動作しなくなる可能性（理由不明）。

### 理想的対応

バージョンシフトを事前に知り、両バージョンがまだ利用可能な間にテストを実施し調整を行う。しかし、初期AIブーム中に開発された全アプリがメトリクスと監視を念頭に構築されたわけではない。多くの開発者は、クラウドモデルプロバイダーのバックエンド変更によりアプリが突然動作停止/異なる結果を出し始め驚いた。

---

## 従来メトリクスの限界

### 学習・検証フェーズの標準メトリクス

精度（Accuracy）と損失（Loss）は学習・検証フェーズでのモデルパフォーマンスの基礎的指標として長く機能。これらメトリクスは、モデルが学習データにどれだけ適合するか、または保持検証セットにどれだけ一般化するかを効果的に定量化。しかし、複雑な実世界本番環境にモデルがデプロイされると、発生する微妙で多面的な失敗モードを捉えるには不十分。

### 本番環境の課題

本番では、出力が構文的に流暢でスタイル的に洗練されていても、ハルシネーション・潜在的バイアス・構造的不整合を含む可能性がある。これら微妙な問題は、精度/損失のような従来メトリクスでは単に検出されない。深刻な下流結果（誤情報伝播・倫理的違反・ユーザー不満）を引き起こす可能性。

### 本番レベル評価の要求

モデル動作の継続的・リアルタイム監視専用に設計されたツールセット・フレームワークが必要。これらシステムは異常検出・データと概念ドリフトの追跡・ユーザー影響評価・新興倫理リスク特定に焦点。

効果的な評価には失敗モード認識以上が必要：これら失敗を早期・高精度でキャプチャできる包括的オブザーバビリティパイプラインのアーキテクト構築が必要。

### オブザーバビリティシステムの要件

エラーを推論/データ処理パイプラインの正確なステージ（入力前処理・検索コンポーネント・生成モデル自身・後処理レイヤー等）にトレースバック可能であること。この細粒度マッピングにより、エンジニアリングチームが迅速な根本原因分析を実行し、修正を優先順位付け、緩和策を自信持ってロールアウト可能。

この予防的・エンドツーエンド監視インフラにより、評価が反応的な後付けから、大規模LLM駆動システムで信頼性・安全性・倫理的統合性維持の戦略的・不可欠な部分に変換される。

---

## オブザーバビリティパイプライン

### 評価の統合

評価は応答生成後に適用される後付けではなく、LLMパイプライン全体（初期入力から最終ユーザーフィードバックまで）に組み込まれなければならない。

### オブザーバビリティパイプラインのステージ

#### 1. 前処理とプロンプト構成

LLMデプロイの失敗はしばしばモデル自身ではなく受信するプロンプトに遡る。本番環境でプロンプトは固定・手作りスニペットではなく、動的に生成・テンプレートから組み立て・アップストリームデータソース/進化するユーザー状態に基づきパラメータ化される。この動態性が複雑性・変動性を導入し、注意深く管理しないとシステムパフォーマンスを微妙に損なう可能性。

**評価の重要次元**:

- **構文的妥当性**: プロンプトが正しくフォーマットされ、解析/トークナイゼーションを妨げるエラーがない
- **セマンティック一貫性**: 明確・曖昧でない指示提供、モデルの期待入力フォーマットと整合
- **厳格なバージョン管理**: プロンプトテンプレート・バリアントのすべてをキャプチャ、下流推論エラーを特定プロンプト変更に直接リンクするトレーサビリティを提供
- **不正形式入力の早期検出**: 欠損コンテキスト変数/誤注入パラメータのような不正形式入力を検出しモデル推論中のカスケード失敗を防止
- **プロンプトトークン長分布の監視**: 過度に長いプロンプト（トランケーションリスク・重要コンテキスト省略・出力品質劣化）と短すぎるプロンプト（十分コンテキスト提供失敗・正確関連応答生成に必要情報をモデルに飢えさせる）を検出

これら分布を継続追跡することで、チームは回帰を予防的に特定しエンドユーザー体験に影響する前に介入可能。

プロンプトエンジニアリングが形式化された規律に成熟するにつれ、このステージでの評価は反応的デバッグから基礎的パイプラインガバナンスモデルに進化。体系的監視・再現性・制御反復を強調し、プロンプト生成が全体LLM推論パイプラインの安定・信頼性の礎として機能することを確保。

#### 2. RAGパイプラインでの検索

RAGシステムでは、失敗は頻繁にLLM自身でなく検索ステージから発生。検索パフォーマンス評価は複数次元を評価することを含む：

- 取得文書のコンテキスト関連性
- 情報の鮮度
- クエリ意図・ドメインに対する適時性

**効果的RAGオブザーバビリティフレームワーク**:

- **各ユーザークエリで取得された文書正確セットをログ**: 遡及分析・再現性を可能に
- **定量メトリクス**: 取得文書と検証されたグラウンドトゥルースソース間の類似度スコア（取得精度の客観的測定）
- **検索レイテンシ監視**: 文書フェッチ遅延がシステムの全体応答性・ユーザー体験に直接影響

**埋め込み類似度ドリフト検出**:

クエリ・文書埋め込みの統計分布を継続追跡し微妙なシフトを検出。これらシフトはハルシネーション・曖昧で非特異的な応答などのより明白な失敗に先立つことが多い（無関係/古い文書が原因）。

ドリフトが検出されたら、適時介入：

- Retriever再学習
- インデックス更新
- 検索パイプライン再設定

この細粒度オブザーバビリティなしに、検索問題による失敗と生成ステージで発生する失敗を区別することは極めて困難。検索・生成コンポーネント両方に及ぶ適切に計装された評価パイプラインは、RAG駆動エンタープライズLLMシステムの信頼性・精度・ユーザー信頼性維持に不可欠。

#### 3. LLM推論

推論ステージでの主要メトリクスは複数次元に及ぶ：

- **事実的精度**: 生成テキストが検証可能真実と整合するか
- **ハルシネーション率**: ハルシネーション頻度測定
- **流暢性**: 出力の可読性・一貫性評価
- **レイテンシ**: 応答時間追跡（ユーザー体験・システムスループットに直接影響）

**詳細診断のためのオブザーバビリティシステム**:

すべての推論呼び出しで詳細メタデータをログ：

- **入出力トークン数**: 使用パターン・潜在的トランケーション明示
- **Temperature・その他サンプリングパラメータ**: 生成の確率的性質を明確化
- **モデルバージョニング**: パフォーマンス変化を特定コード/モデル更新にトレース
- **完了長の急激シフト**: トランケーションエラー/配信応答で即座に明白でない潜在的失敗を示す可能性

**内部評価技術**:

- **Self-consistency checks**: 同じプロンプトの複数生成を比較し表面的に流暢だが不整合/矛盾のある出力を特定
- **補助評価者/専門分類器の信頼スコア**: 期待される事実/倫理基準から逸脱する出力をフラグ

推論は単独プロセスではなく、通常、複数呼び出し・検索ステップ・後処理を含む複雑チェーン/パイプライン内に埋め込まれている。ここで構造化ログ・トレース可視化ツールが不可欠。リアルタイム監視を可能にし、根本原因分析を容易にし、チームが複雑ワークフロー内で失敗/非効率が発生する正確な場所を特定できる。

これらオブザーバビリティプラクティスを組み合わせることで、推論評価が受動的測定から、デプロイされたLLMシステムで信頼性・精度・信頼性を維持するために不可欠な能動的ガバナンスメカニズムに昇格。

#### 4. 後処理と出力検証

生成フェーズ後、出力は通常**後処理**ステージを経る：フォーマット・クリーンアップ・構造調整でエンドユーザー/下流システムへの配信用データを準備。このステップは単純に見えるかもしれないが、ここで導入される小さな構造エラーさえアプリケーションスタック全体に深刻な失敗をカスケードする可能性。

**後処理ステージでの評価は構造的検証に集中**:

- 生成出力が期待フォーマットに適合するか検証
- JSON応答が構文的に有効か確認
- 事前定義スキーマに厳格に準拠するか確認
- すべての必須フィールドを含むか確認

文法的に正しく見える出力でも、キーデータ要素が欠損/不正形式の場合、機能的に使用不可能になる可能性。

**自動ツールの重要役割**:

- **スキーマバリデーター**: 構造的統合性を体系的にチェック
- **追加自動チェック**: 空完了/下流処理を妨害する他の異常検出

高ステーク・コンプライアンス重要アプリでは、後処理中の未検出エラーがサイレント失敗/規制違反をトリガーするリスクがあり、潜在的に深刻な結果を伴う。

後処理を全体システムパイプライン内の形式的・評価可能ステージに昇格することで、チームは伝播前に構造問題を予防的に検出・修正する能力を得る。この視点により、後処理が受動的フォーマットステップから、本番LLMデプロイで出力信頼性・正確性・コンプライアンス確保の重要チェックポイントに変換される。

#### 5. フィードバックキャプチャ

フィードバックデータには、ユーザー評価・サムズアップ/ダウン・直接テキストフィードバック・エンゲージメント期間・クエリ放棄・人間エージェントへのエスカレーション率などの暗黙的行動指標が含まれる。

このフィードバックを一貫してキャプチャ・統合することで、評価をしっかりと実世界ユーザー体験に基づかせ、静的内部ベンチマーク・オフラインテストが見落とす可能性のある微妙なギャップ・失敗モードを明らかにする。

**このステージのメトリクス**:

重要なユーザビリティ指標として機能し、システム改善優先順位を直接通知：

- **滞在時間（Dwell time）**: ユーザーが生成コンテンツとどれだけ長くエンゲージするか測定
- **放棄率（Abandonment rates）**: フラストレーション/不満シグナル
- **再試行頻度（Retry frequency）**: 不明確/役立たない応答を示す可能性

**評価プラットフォーム（LangSmith等）**:

ルーブリック駆動の出力スコアリングを容易化し、事実性・関連性・構造的正確性などの次元に沿って評価。これらスコアは、モデルバージョン・プロンプトバリアント・コンテキスト情報を含むメタデータで強化され、細粒度トレーサビリティ・縦断的パフォーマンス分析を可能にする。

**Human-in-the-Loopファインチューニング・報酬モデリングのような手法が成熟するにつれ**:

フィードバックが受動的測定ツールから継続改善の能動的ドライバーに移行。ユーザーシグナルがモデル更新・パイプライン調整を動的に舵取りする学習データになり、デプロイと反復間のループを閉じる。

### パイプラインの各ステージが独自洞察をもたらす

これらの観察をエンドツーエンドオブザーバビリティフレームワークに統合すると真の力が発揮される。この相互接続された可視性は、動的本番環境でロバスト・信頼性・ユーザー中心LLMアプリを維持するために重要。

---

## 異常検出としてのオブザーバビリティ

コアとして、オブザーバビリティは異常検出問題。システムメトリクス・ログ・トレース・出力でパターン/期待動作からの逸脱を探している。煙探知機のように、あらゆる小さな問題をキャッチする目標ではなく、深刻な失敗に広がる前に重要なものをキャッチすること。

LLM評価メトリクスを学習で設定した後、これらオブザーバビリティメトリクスがパイプラインの残りをカバー。4つのステージで実施可能：

### Stage 1: 閾値ベースアラート

最もシンプルな形式。主要メトリクスに明示的制限設定（APIレスポンスタイム2秒超/トークン数1024超等）。閾値を超えるとPrometheusがデータ収集、GrafanaがSlack/イシュートラッカー経由でチームに通知するアラートトリガー。直接的で実装高速だが、閾値が静的なため複雑/進化する問題を見逃す可能性。

### Stage 2: 統計的異常検出

時間経過でメトリクス動作を分析し固定制限を超える。移動平均・z-scoreのような転がり統計を使用。例: 高z-scoreの突然のレイテンシスパイクが調査価値のある異常をシグナル。AlertManagerと組み合わせたGrafanaダッシュボードがこれら偏差をハイライト、LangSmithのようなトレースツールとの統合でどのリクエスト/出力がアラート原因かピンポイント特定を支援。この手法は通常変動に適応し偽陽性を削減。

### Stage 3: ドリフト検出

入力データ/検索品質の変化を監視し時間経過でAIパフォーマンスを劣化させる可能性。例: ユーザークエリシフト/Retriever埋め込みの類似度スコア低下は、データ/検索が古い兆候。FAISS（埋め込み分析）とLangChain（パイプライン監視）のようなフレームワークを使用してこれらシフトを早期検出。自動ワークフローでRetriever更新/モデル再学習し、システムを正確・関連性維持。

### Stage 4: フィードバックシグナル監視

ユーザーフィードバック・フォールバック動作は実世界システム健全性への直接洞察を提供。肯定評価低下/フォールバック（デフォルト）応答増加はユーザー体験/モデル劣化の問題を示す。LangSmith・MLflowのようなツールでこのフィードバックを特定モデルバージョン・デプロイにリンクし、チームが根本原因を診断しロールバック/再学習すべきか決定するのを支援。

### ロバストなオブザーバビリティシステム

これら4つのレイヤー全てを組み合わせる。以下ツールは一般的推奨だが、既存スタックを使用してもよい：

- **Prometheus**: ランタイムメトリクス収集（CPU, メモリ, レイテンシ, トークン使用）
- **Grafana**: リアルタイムダッシュボード・閾値/統計異常アラート
- **MLflow/ZenML**: モデルバージョン・実験メタデータ追跡
- **LangSmith**: トレースレベル洞察提供、フィードバックシグナルをモデルパフォーマンスに接続

目標はツール推奨ではなく実装テクニック提供。ツール選択/ハードコーディングに関係なく、最も重要なのは実装テクニック。シンプルな閾値アラート・適応統計手法・ドリフト検出・ユーザーフィードバック監視を階層化することで、明白な違反から微妙なAIシステム健全性劣化までをキャッチする包括的パイプラインを構築可能。

---

## AskUserQuestion指針

以下の状況で判断が必要な場合、AskUserQuestionを使用してユーザーに確認する：

### 評価メトリクス選択時

- **n-gramベース vs 類似度ベース vs LLMベース**: アプリ要件（正確性重視/意味理解重視/コスト制約）を確認
- **一般ベンチマーク使用**: GLUEやMMLU等の一般ベンチマークを使用するか、ドメイン固有データセットを作成するか確認

### RAG評価戦略時

- **検索メトリクス優先度**: Recall/MRR/MAP/Context Precision/Relevanceのうち最重要メトリクスを確認
- **Dense vs Sparse検索**: クエリタイプと精度要件に基づき選択
- **評価ツール選択**: Ragas（シンプル）vs LangSmith（カスタマイズ可能）vs 自社開発の選択基準

### エージェントシステム評価時

- **評価方法選択**: 人間評価者 vs LLM評価者 vs 両方のハイブリッドアプローチを確認
- **評価目的優先順位**: 内部プロパティ/エンジニアリングレベルパフォーマンス/相互作用品質/ユーザー満足度のうち最重要項目
- **ステージ別メトリクス**: 開発/デプロイ/本番各ステージで何を測定するか確認

### オブザーバビリティ戦略時

- **監視範囲**: 前処理/検索/推論/後処理/フィードバックのうちどのステージを監視するか確認
- **アラート閾値**: 各失敗モード（ハルシネーション/レイテンシスパイク/ドリフト等）のアラート発火条件
- **ツールスタック**: Prometheus/Grafana/LangSmith等の組み合わせ vs 既存ツール利用の選択

### 自動化投資判断時

- **自動メトリクス導入範囲**: どのメトリクスを自動化し、どれを手動評価に残すか
- **A/Bテスト実施**: どのパラメータでA/Bテストを実施するか（プロンプトバリアント/モデルバージョン/検索戦略等）
- **ドリフト検出感度**: どの程度のドリフトでアラートを発火させるか

### モデルドリフト対応時

- **モデルバージョン管理**: 自動更新を有効にするか、手動承認プロセスを挟むか
- **ロールバック戦略**: パフォーマンス低下検出時に旧バージョンにロールバックする条件
- **再学習トリガー**: どのメトリクス低下時にモデル再学習をトリガーするか

### ユーザーフィードバック戦略時

- **フィードバック収集方法**: NPS/サムズアップダウン/詳細調査の組み合わせ
- **フィードバック統合**: 収集したフィードバックをどのようにモデル改善に統合するか
- **Human-in-the-Loop範囲**: どの判断に人間介入を求めるか

### コスト vs 品質トレードオフ時

- **評価頻度**: リアルタイム評価 vs バッチ評価 vs 定期サンプリングの選択
- **計算リソース**: LLMベース評価の使用範囲（コスト高だが精度高）vs ルールベース評価（コスト低だが精度制限）
- **ログ保持期間**: すべてのリクエスト/レスポンスをログするか、サンプリングするか、保持期間は何か

---

**このリファレンスは評価戦略構築時の意思決定支援を目的としています。評価は継続的プロセスであり、状況に応じて戦略を調整してください。不明点がある場合は、常にユーザーに確認してから作業を進めてください。**
