# スケーリング・インフラ最適化リファレンス

LLMのインフラストラクチャ、リソース管理、スケーリング戦略の実践ガイド。水平/垂直スケーリング、監視、A/Bテスト、IaCプロビジョニング、並列分散処理を含む。

---

## スケーリングアプローチの選定

LLMの展開方法は、アプリケーションの要件に応じて選択する。

### 展開戦略の比較

| 戦略 | 適用ケース | メリット | デメリット |
|------|----------|---------|----------|
| **サードパーティAPI** | スタートアップ、小規模アプリ | 迅速な開始、初期コスト低 | 従量課金、カスタマイズ制限 |
| **クラウドインフラ** | エンタープライズ、高負荷 | 柔軟性とスケーラビリティ | 運用コスト |
| **オンプレミス** | 厳格なプライバシー、レイテンシ要件 | 完全な制御、データ主権 | 高い初期投資、運用複雑性 |

### 推奨アプローチ

**最初は必ずサードパーティAPIから始める**:
1. LLMが問題解決に適しているかをプロトタイプで検証
2. 実際の負荷とコストを測定
3. 検証後、必要に応じてカスタムインフラに移行

---

## リソース割り当てとスケーリング

### スケーリングの基本原則

**重要な洞察（"氷山問題"）**:
- 多くの学習失敗は**メモリ不足**が原因（計算力不足ではない）
- 最適化されていないメモリ使用は目に見えない
- 適切な手法を使えば24GBのGPUを48GB A100のように動作させることが可能

**主要手法**:
- シャーディング（Sharding）
- アクティベーションチェックポインティング（Activation Checkpointing）
- 動的バッチング（Dynamic Batching）
- モデルオフローディング（Model Offloading）

### リソース割り当ての2つの柱

1. **モニタリング**: リソースの過剰/過小割り当てを検知
2. **自動デプロイメント**: 検知後に迅速に対応

手動デプロイも可能だが、需要変動が大きい場合（時間帯、地域差等）はコストが高くなる。

---

## モニタリング

### 主要メトリクス

| メトリクス | 説明 | 目標 |
|----------|------|------|
| **レイテンシ** | ユーザークエリへの応答時間 | 最小化（ユーザー満足度に直結） |
| **スループット** | 単位時間あたりの処理リクエスト数（通常は秒） | ピーク負荷時の容量確保 |
| **リソース使用率** | CPU、GPU、メモリ、ディスクI/O、ネットワーク帯域幅 | 適切な割り当ての判断 |
| **エラー率** | サーバーエラー、トークン制限超過、安全性応答 | 問題の早期発見 |
| **コスト** | リソース消費に伴うコスト | 経済的な持続可能性 |

### モニタリングツールの比較

| ツール | タイプ | 主要機能 |
|--------|--------|---------|
| **AWS CloudWatch** | クラウドネイティブ | AWSリソースの統合監視、標準/カスタムメトリクス |
| **Azure Monitor** | クラウドネイティブ | Azureリソース監視、Application Insights統合 |
| **Google Cloud Operations Suite** | クラウドネイティブ | GCPリソース監視、トレース、ログ |
| **Datadog** | APM（アプリケーション性能監視） | 依存関係の可視化、ボトルネック分析 |
| **New Relic** | APM | 詳細なアプリケーション洞察、トランザクショントレース |
| **AppDynamics** | APM | ビジネスメトリクスとの統合 |
| **Weights & Biases** | ML特化 | モデル動作追跡、ファインチューニング比較 |
| **MLflow** | ML特化 | モデル管理、デプロイメント比較 |
| **ELK Stack** | ログ管理 | Elasticsearch、Logstash、Kibanaによるログ集約 |
| **Fluentd** | ログ管理 | 統一ロギングレイヤー |
| **OpenTelemetry** | 分散トレーシング | クロスサービストレース、レイテンシ特定 |
| **Jaeger** | 分散トレーシング | 分散トランザクション追跡 |

### モニタリングレイヤーアーキテクチャ

最低3層、推奨は4層：

| レイヤー | 焦点 | メトリクス例 |
|---------|------|------------|
| **クライアント層** | ユーザー側のパフォーマンス | 満足度評価（👍/👎） |
| **アプリケーション層** | API性能 | スループット、処理時間、エラー率 |
| **インフラ層** | 基盤リソース | CPU、GPU、メモリ、ストレージ、I/O性能 |
| **モデル層**（推奨） | LLM固有 | 推論時間、トークン使用量、トークンキャッシング、パープレキシティ |

### リアルタイムアラートと自動対応

**アラート設定**:
- レイテンシ、リソース使用率、エラー率に閾値を設定
- 閾値超過時にメール/SMS通知

**Synthetic Monitoring**:
- 既知の応答を期待するリクエストを自動送信
- 出力を測定して正常性を確認

**自動スクリプトトリガー**:
- 閾値失敗時にスクリプト自動実行
- 例: CPU/メモリ閾値超過時に新しいVMを起動
- 例: 定期的なサービス再起動、需要予測に基づくスケーリング

### 最適化手法

| 手法 | 説明 | 効果 |
|------|------|------|
| **オートスケーリング** | 負荷に応じて動的にリソース調整 | コスト削減、性能維持 |
| **水平スケーリング** | インスタンス追加で容量増強 | リクエスト数増加に対応 |
| **垂直スケーリング** | 既存ノードの容量増強 | 単一インスタンスの性能向上 |
| **キャッシング** | 頻繁にアクセスされる応答をキャッシュ | レイテンシ削減、モデル負荷軽減 |
| **バッチング** | 低優先度クエリをまとめて処理 | 効率向上 |
| **蒸留・量子化** | モデルサイズ削減 | 性能とリソース消費のバランス |

---

## A/Bテストとシャドウテスト

### A/Bテストの基本

**目的**: 2つのモデルバージョンの性能を実世界で比較

**用語**:
- **Champion（チャンピオン）**: 既存の本番モデル
- **Challenger（チャレンジャー）**: 新しい候補モデル

**手法**:
- ユーザーをランダムに2グループに分割
- 各グループに異なるモデルを提供
- メトリクス（レイテンシ、スループット、ユーザー満足度等）を比較

**利点**: ユーザーフィードバックを直接収集可能

### シャドウテスト

**目的**: ユーザーに影響を与えずに新しいモデルを評価

**手法**:
- チャレンジャーモデルをバックグラウンドで実行
- チャンピオンモデルと同じ入力を処理（またはサンプリング）
- 出力はユーザーには提供せず、性能データのみ収集

**利点**:
- 高リスクアプリケーション（カスタマーサービス、医療等）で安全にテスト
- インフラとモデルの信頼性をデプロイ前に検証

**制約**:
- ユーザーが新しいモデルの出力を見ないため、ユーザーフィードバック収集不可
- A/Bテストはユーザーフィードバックが必須の場合に最適
- シャドウテストはインフラと信頼性の検証に最適

### A/B vs シャドウテスト比較

| 観点 | A/Bテスト | シャドウテスト |
|------|----------|--------------|
| ユーザー影響 | あり（チャレンジャーを一部ユーザーに提供） | なし（バックグラウンドのみ） |
| ユーザーフィードバック | 収集可能 | 収集不可 |
| リスク | 中程度（不具合がユーザーに影響） | 低（本番に影響なし） |
| 適用場面 | フィードバックが必須の場合 | 高リスクアプリ、インフラ検証 |
| コスト | 中程度 | 高（並列実行のため） |

---

## 自動インフラプロビジョニングと管理

### クラウドアーキテクチャ

#### Infrastructure as Code（IaC）ツール

| ツール | プラットフォーム | 説明 |
|--------|--------------|------|
| **AWS CloudFormation** | AWS | YAML/JSON形式のテンプレートでインフラ定義 |
| **Azure Resource Manager (ARM)** | Azure | JSONテンプレートでAzureリソース管理 |
| **Google Cloud Deployment Manager** | GCP | YAML/Pythonでリソース宣言 |
| **Terraform** | マルチクラウド | マルチクラウド対応のIaCツール |

**利点**:
- 環境の一貫性（dev、staging、prod）
- バージョン管理可能
- 自動化されたデプロイメント

#### オートスケーリングサービス

| サービス | プラットフォーム | 機能 |
|---------|--------------|------|
| **AWS Auto Scaling** | AWS | CPU、メモリ、GPU使用率に基づく自動スケール |
| **Azure VMSS** | Azure | 仮想マシンスケールセット |
| **GCP Autoscaler** | GCP | メトリクスベースの動的スケーリング |

**使用例**:
- LLM推論の負荷変動に対応
- 需要減少時にリソース自動縮小（コスト削減）
- 需要増加時にリソース自動拡張（レイテンシ維持）

#### コスト最適化オプション

| オプション | プラットフォーム | 特徴 |
|----------|--------------|------|
| **AWS Spot Instances** | AWS | 未使用容量を低価格で利用、中断可能性あり |
| **Azure Spot VMs** | Azure | 同上 |
| **GCP Preemptible VMs** | GCP | 同上 |

**適用場面**:
- バッチ処理、分散学習等の非クリティカルワークロード
- フォールトトレランスとジョブリトライの実装が必須

#### セルフヒーリングアーキテクチャ

**監視＋自動化の統合**:
- AWS Lambda、Azure Functions、GCP Cloud Functionsを使用
- 例: GPU インスタンス障害時に自動で代替インスタンスをプロビジョニング、ジョブ再開

**カスタムメトリクス**:
- 事前設定メトリクス（CPU、メモリ等）をそのまま使用可能
- ユースケース固有のカスタムメトリクスも設定可能

### オンプレミス（所有ハードウェア）

#### ベアメタル vs 仮想化

| 環境 | 特徴 | 適用場面 |
|------|------|---------|
| **ベアメタル** | 高性能、直接ハードウェアアクセス | LLM学習・ファインチューニング、NVIDIA A100/H100使用 |
| **仮想化** | 柔軟性、リソース共有 | 複数ワークロードの共存 |

**ツール**:
- **VMware、Proxmox、Hyper-V**: 仮想化プラットフォーム
- **Kubernetes**: GPUリソースをポッドに動的に割り当て

#### IaCツール（オンプレミス）

| ツール | 用途 |
|--------|------|
| **Terraform** | インフラ定義、マルチ環境対応 |
| **Ansible** | サーバー設定、MLフレームワーク（PyTorch、TensorFlow）インストール |
| **Chef** | 設定管理 |

**例**: TerraformでGPU対応ノードを定義し、AnsibleでPyTorchをインストール

#### モニタリングとスケジューリング

| ツール | 機能 |
|--------|------|
| **Prometheus** | メトリクス収集 |
| **Grafana** | メトリクス可視化 |
| **SLURM** | HPC環境向けワークロードスケジューラ |
| **Kubernetes** | コンテナオーケストレーション、リソース割り当て |

#### ハイブリッドアプローチ

**課題**: オンプレミスはハードウェア追加にコストと時間がかかる

**解決策**: ハイブリッド構成
- 学習: ローカルGPU
- 推論・テスト: クラウドでピーク時対応

**注意**: エンドポイント設定、モニタリング、自動障害復旧の実装が必要

### クラウド vs オンプレミス比較

| 観点 | クラウド | オンプレミス |
|------|---------|-------------|
| **スケーラビリティ** | 高（オートスケーリング） | 制限あり（ハードウェア依存） |
| **初期コスト** | 低（従量課金） | 高（ハードウェア購入） |
| **運用コスト** | 使用量ベース | 固定（電力、冷却、保守） |
| **性能** | 高（クラウドGPU） | 高（ベアメタル特化） |
| **柔軟性** | 容易にリソース再構成可能 | 手動または自動再構成 |
| **制御** | クラウドプロバイダーの制約 | 完全な制御 |

### インフラ管理のベストプラクティス

1. **クラウドバースティング**: ピーク需要時に追加ワークロードをクラウドで処理
2. **自動化パイプライン**: IaCとCI/CD（Jenkins、GitHub Actions）でデプロイ自動化
3. **コストと性能の最適化**: コストシミュレータ（クラウド）やベンチマークテスト（オンプレミス）を活用
4. **高可用性と冗長性**: マルチゾーン配置（クラウド）、冗長ハードウェア（オンプレミス）、自動フェイルオーバー

---

## スケーリング法則とCompute-Optimal引数

### Chinchillaスケーリング法則

**原則**: モデルサイズ（パラメータ数）と学習データ量（トークン数）のバランスを最適化

**問題**: GPT-3等の初期モデルは**アンダートレーン**（パラメータ数に対してデータ量が不足）

**式**:
- 計算予算 C ∝ N × D
- データ量 D ∝ N
- 最適比率: **トークン数 = パラメータ数 × 15〜25**

### 実例比較

**シナリオ1: モデルサイズ優先**（非推奨）
- N = 2000億パラメータ
- D = 3000億トークン
- D/N = 1.5（Chinchilla推奨範囲外）
- 計算量: C = k × 6 × 10^22 FLOPs

**シナリオ2: Compute-Optimal戦略**（推奨）
- N = 500億パラメータ
- D = 1兆トークン
- D/N = 20（Chinchilla推奨範囲内）
- 計算量: C = k × 5 × 10^22 FLOPs

**結論**: シナリオ2は同じ計算予算でより良い性能を実現
- 各パラメータが十分なデータに露出
- 過学習を削減
- ファインチューニングの必要性が低い

### 実務上の意味

- **大きいモデル ≠ 良いモデル**
- **データとモデルサイズのバランスが重要**
- GPT-4、Claude、Gemini等の最新モデルはCompute-Optimal原則を適用済み

---

## LLMインフラの最適化

### コンパイラ最適化

**役割**: 高レベルコードをハードウェアに最適化された機械命令に変換

**主要コンパイラ**:
- **NVIDIA NVCC**: CUDA用
- **TensorFlow XLA**: TensorFlow用
- **PyTorch TorchScript**: PyTorch用

#### 3つの最適化タイプ

**1. カーネルフュージョン（Kernel Fusion）**

**問題**: 個別の演算（行列乗算、加算、活性化関数）がそれぞれグローバルメモリにアクセス → レイテンシ増加

**解決**: 複数演算を単一GPUカーネルに統合

**効果**:
- メモリアクセス削減（中間結果をレジスタ/共有メモリに保持）
- カーネル起動オーバーヘッド削減
- キャッシュ効率向上

**例**: `ReLU(Wx + b)` を単一カーネルに統合（W: 重み、b: バイアス）

**2. 精度スケーリング（Precision Scaling）**

**原理**: 高精度（FP32）の代わりに低精度（FP16、BF16）を使用

**手法**:
- **混合精度学習**: FP16で演算、FP32で勾配累積（数値安定性維持）
- **テンソルコア活用**: NVIDIA A100/H100のテンソルコアは低精度演算に最適化

**効果**:
- メモリ使用量削減 → バッチサイズ増加可能
- 計算速度向上

**3. ハードウェア使用率（Hardware Utilization）**

**最適化手法**:
- **専用ユニットへのマッピング**: テンソルコア、行列乗算ユニット、ベクトルプロセッサを活用
- **命令レベル並列性**: スレッドレベル、ベクトルレベルの並列化
- **メモリ階層最適化**: 共有メモリ、レジスタ、キャッシュを効率的に使用、低速なグローバルメモリへの依存を削減

---

## 並列・分散コンピューティング

### CUDAとNCCLの役割

| フレームワーク | 役割 | 主要機能 |
|--------------|------|---------|
| **CUDA** | GPU並列計算 | 行列乗算、注意機構、勾配計算 |
| **NCCL** | マルチGPU通信 | all-reduce、all-gather、broadcast |

### データ並列処理（Data Parallelism）

**原理**: データセットを分割、各GPUで並列処理

**手順**:
1. データセットをチャンクに分割、各GPUに割り当て
2. 各GPUに同一モデルのコピーを配置
3. 各GPUがチャンクの勾配を計算
4. 勾配を `all-reduce` で平均化
5. 平均勾配で各GPUのモデルを更新

**利点**: 学習速度の向上
**適用場面**: モデルが単一GPU に収まる場合

### モデル並列処理（Model Parallelism）

**原理**: モデルを分割、各GPUで異なる部分を担当

**手順**:
1. モデルを複数デバイスに分割（レイヤー単位等）
2. 入力をフォワードパス（順伝播）で順次処理
3. バックワードパス（逆伝播）で勾配を計算
4. パラメータを更新（各デバイスで独立 or パラメータサーバー経由）

**利点**: 大規模モデルをメモリ制約下で学習可能
**欠点**: スループット低下（あるデバイスが処理中、他は待機）

### パイプライン並列処理（Pipeline Parallelism）

**原理**: モデル並列処理の改良版。データバッチをマイクロバッチに分割し、複数デバイスを同時稼働

**手順**:
1. モデルを複数デバイスに分割（レイヤー単位）
2. データバッチをマイクロバッチに分割
3. 各デバイスがマイクロバッチをパイプライン処理

**効果**: アイドル時間削減、スループット向上

**実装**:
- **PiPPy**（Meta開発） → PyTorchに統合（`torch.distributed.pipelining`）

**図解**: 4デバイス、4マイクロバッチの例
```
Device 1: [MB1] [MB2] [MB3] [MB4]
Device 2:       [MB1] [MB2] [MB3] [MB4]
Device 3:             [MB1] [MB2] [MB3] [MB4]
Device 4:                   [MB1] [MB2] [MB3] [MB4]
```

### 並列処理手法の比較

| 手法 | メモリ効率 | スループット | 適用場面 |
|------|-----------|------------|---------|
| **データ並列** | 低（モデルコピー） | 高 | モデルが単一GPUに収まる |
| **モデル並列** | 高（モデル分割） | 低 | モデルが単一GPUに収まらない |
| **パイプライン並列** | 高（モデル分割） | 中〜高 | モデル分割＋スループット最適化 |

---

## 高度なフレームワーク: ZeROとDeepSpeed

### ZeRO（Zero Redundancy Optimizer）

**開発**: Microsoft
**目的**: メモリオーバーヘッド削減

**原理**: モデル状態（パラメータ、勾配、オプティマイザ状態）をデバイス間で分割

**効果**: 数百億パラメータのモデルを過剰なメモリ容量なしで学習可能

### DeepSpeed

**開発**: Microsoft（ZeROをベースに構築）
**機能**:
- 混合精度学習
- 勾配累積
- メモリ最適化

**効果**: 学習時間とコスト大幅削減

### メモリ最適化手法の比較

| 手法 | 解決する問題 | 動作原理 | トレードオフ |
|------|-------------|---------|-------------|
| **シャーディング** | モデルが1GPUに収まらない | モデル重み/レイヤーを複数GPUに分割 | 同期・通信の複雑性増加 |
| **アクティベーションチェックポインティング** | バックプロパゲーション時の高メモリ使用 | 主要なアクティベーションのみ保存、後で再計算 | 追加の計算時間 |
| **動的バッチング** | 小リクエストでの計算資源浪費 | 入力を動的にグループ化してGPU使用率最大化 | わずかな応答遅延 |
| **モデルオフローディング** | GPUがモデル全体を保持できない | 未使用部分をCPU/ディスクに移動、必要時にフェッチ | 転送時間による遅延 |
| **混合精度学習** | アクティベーション・重みが大量のメモリ消費 | 低精度（FP16等）を使用、FP32の代わり | わずかな精度損失（通常は無視可能） |
| **量子化** | デプロイメント時のモデルサイズ | 重みを8bit以下に圧縮 | 慎重に行わないと精度損失 |
| **勾配累積** | バッチサイズがGPUに収まらない | 大バッチを小チャンクに分割、勾配を累積 | イテレーション時間増加 |
| **ZeRO** | GPU間で冗長なオプティマイザ状態 | オプティマイザ状態と勾配をデバイス間で分割 | 複雑性と通信オーバーヘッド |
| **オペレータフュージョン** | 多数の小さな中間テンソル | 複数演算を1つに結合してメモリ操作削減 | コンパイラ/ツールサポート必要 |
| **ページドアテンション（推論用）** | 長いコンテキストによるメモリスパイク | Key-Valueキャッシュを仮想メモリのようにストリーム | スマートスケジューリング必要 |

---

## バックアップ・リストア戦略

### バックアップ対象

**開発段階**:
- 学習データ
- 中間モデルチェックポイント
- IaCファイル（小容量）

**本番段階**:
- 本番IaCファイル
- ユーザーデータ（クエリログ、パーソナライゼーション）
- 性能メトリクス

**重要性**:
- データ消失は極めて高コスト
- チェックポイントは障害時の進捗保護
- コンプライアンス要件（監査・説明責任）

### バックアップ戦略の種類

| 戦略 | 内容 | メリット | デメリット |
|------|------|---------|----------|
| **フルバックアップ** | 特定時点の完全なスナップショット | リストアが簡単、包括的 | ストレージ容量大 |
| **増分バックアップ** | 前回（フル or 増分）からの差分のみ | ストレージ効率的 | リストア時に全履歴必要 |
| **差分バックアップ** | 前回のフルバックアップからの差分 | リストア高速（最新フル+最新差分） | 増分よりストレージ消費 |

### バックアップ戦略の選定基準

| 要因 | 推奨戦略 |
|------|---------|
| **高リスクアプリケーション** | 頻繁なフルバックアップ（高速・確実なリストア） |
| **大容量データ** | 増分 or 差分（ストレージコスト削減） |
| **頻繁に変更されるデータ** | 頻繁なバックアップ（小容量なら毎日フル） |
| **静的なデータ** | 低頻度（例: デプロイ済み推論モデルは週次） |

### ストレージの種類

| タイプ | 特徴 | アクセス時間 | コスト |
|--------|------|------------|-------|
| **ホットストレージ** | クラウド上のフォルダのように即座にアクセス可能 | 即時 | 高 |
| **コールドストレージ** | 倉庫のディスクのようにアクセスに時間がかかる | 数時間〜数日 | 低 |

### 最重要プラクティス: リストアテストを定期実行

**警告**: バックアップを長年実施していても、テストしていなければリストア失敗のリスク

**リスクシナリオ**:
- 大容量バックアップがコールドストレージに保存
- 障害時にリストアしようとすると2週間待ち
- 「データはバックアップされていますが、復旧に2週間かかります」

**対策**:
- 定期的にリストア手順を実行
- 障害ポイントの特定
- リストア時間の測定
- 手順のドキュメント化

---

## AskUserQuestion指針

以下の状況ではAskUserQuestionで確認する：

### スケーリング戦略の選定

```python
AskUserQuestion(
    questions=[{
        "question": "LLMデプロイメント戦略を選択してください",
        "header": "デプロイメント戦略",
        "options": [
            {
                "label": "サードパーティAPI（推奨スタート）",
                "description": "OpenAI、Anthropic等のAPI。迅速な検証、初期コスト低、カスタマイズ制限"
            },
            {
                "label": "クラウドインフラ",
                "description": "AWS、Azure、GCP。高スケーラビリティ、運用コスト、柔軟性高"
            },
            {
                "label": "オンプレミス",
                "description": "自社ハードウェア。完全制御、データ主権、高初期投資"
            },
            {
                "label": "ハイブリッド",
                "description": "オンプレミス（学習）+クラウド（推論・ピーク対応）"
            }
        ],
        "multiSelect": False
    }]
)
```

### モニタリングツールの選定

```python
AskUserQuestion(
    questions=[{
        "question": "主要なモニタリングツールを選択してください（複数選択可）",
        "header": "モニタリングツール",
        "options": [
            {"label": "クラウドネイティブ（CloudWatch/Azure Monitor/GCP Operations）", "description": "クラウドプラットフォーム統合監視"},
            {"label": "APM（Datadog/New Relic/AppDynamics）", "description": "アプリケーション性能監視、依存関係可視化"},
            {"label": "ML特化（Weights & Biases/MLflow）", "description": "モデル動作追跡、ファインチューニング比較"},
            {"label": "ログ管理（ELK Stack/Fluentd）", "description": "ログ集約、クエリ詳細"},
            {"label": "分散トレーシング（OpenTelemetry/Jaeger）", "description": "クロスサービストレース、レイテンシ特定"}
        ],
        "multiSelect": True
    }]
)
```

### バックアップ戦略の選定

```python
AskUserQuestion(
    questions=[{
        "question": "バックアップ戦略を選択してください",
        "header": "バックアップ戦略",
        "options": [
            {
                "label": "フルバックアップ",
                "description": "完全なスナップショット。リストア簡単。高リスクアプリに推奨"
            },
            {
                "label": "増分バックアップ",
                "description": "前回からの差分のみ。ストレージ効率的。全履歴必要"
            },
            {
                "label": "差分バックアップ",
                "description": "最新フルからの差分。バランス型。最新フル+最新差分で復旧"
            },
            {
                "label": "カスタム",
                "description": "データタイプに応じて戦略を組み合わせ"
            }
        ],
        "multiSelect": False
    }]
)
```

### 並列処理手法の選定

```python
AskUserQuestion(
    questions=[{
        "question": "LLM学習に使用する並列処理手法を選択してください",
        "header": "並列処理手法",
        "options": [
            {
                "label": "データ並列",
                "description": "モデルが単一GPUに収まる場合。スループット高"
            },
            {
                "label": "モデル並列",
                "description": "モデルが単一GPUに収まらない場合。メモリ効率高、スループット低"
            },
            {
                "label": "パイプライン並列",
                "description": "モデル分割＋スループット最適化。PyTorch PiPPy利用"
            },
            {
                "label": "ZeRO + DeepSpeed",
                "description": "メモリ最適化。数百億パラメータモデルに対応"
            },
            {
                "label": "組み合わせ",
                "description": "複数手法を組み合わせて最適化"
            }
        ],
        "multiSelect": False
    }]
)
```

### インフラ最適化手法の選定

```python
AskUserQuestion(
    questions=[{
        "question": "適用するメモリ最適化手法を選択してください（複数選択可）",
        "header": "メモリ最適化",
        "options": [
            {"label": "シャーディング", "description": "モデルを複数GPUに分割"},
            {"label": "アクティベーションチェックポインティング", "description": "メモリ節約、計算時間増"},
            {"label": "動的バッチング", "description": "GPU使用率最大化、わずかな遅延"},
            {"label": "モデルオフローディング", "description": "CPU/ディスクに退避、転送時間増"},
            {"label": "混合精度学習", "description": "FP16使用、わずかな精度損失"},
            {"label": "量子化", "description": "8bit以下に圧縮、精度注意"},
            {"label": "勾配累積", "description": "大バッチを分割、イテレーション時間増"},
            {"label": "ZeRO", "description": "オプティマイザ状態分割、通信オーバーヘッド"}
        ],
        "multiSelect": True
    }]
)
```
