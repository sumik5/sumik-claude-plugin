# LLMデータエンジニアリング

## 概要

LLMにおけるデータエンジニアリングは、モデルのトレーニング・評価・デプロイを支援するデータパイプラインとインフラの設計・開発・管理を担う。**「Garbage in, garbage out」**: LLMOpsの成熟度はデータエンジニアリングシステムの品質に依存する。

### データエンジニアリングの革命

- **リレーショナルDB（1970年代）**: Edgar Codd氏による関係モデルの導入
- **Web時代（1990年代）**: 非構造化データの爆発的増加
- **NoSQLデータベース**: Key-Value、Document、Graph、Vectorデータベースの台頭
- **Vectorデータベース**: LLM向けにセマンティック検索を実現

### DBタイプとLLMでの役割

| DBタイプ | 用途 |
|---------|------|
| リレーショナル | ACID準拠トランザクション、構造化データ |
| Document/Key-Value | 柔軟な半構造化コンテンツ、メディアBlob |
| Graph | ノード・エッジ表現、関係性の高速探索 |
| Vector | 高次元埋め込み、ANN検索、RAGパイプライン |

---

## DataOpsエンジニアの役割

### 従来のデータエンジニアとの違い

| 従来 | LLM時代 |
|------|---------|
| 構造化データ（行・列） | 非構造化データ（テキスト・コード・画像・音声） |
| ETL/ELT、データウェアハウス | 連続的な埋め込み・再埋め込みループ、Vectorインデックス |
| スキーマ適合、重複排除 | セマンティックリッチネス、毒性・バイアスフィルタリング |
| 精度・再現率 | グラウンディング・事実性・バイアス評価 |

### DataOpsエンジニアの責任範囲

- データライフサイクルのオーケストレーション（取得→デプロイ）
- スケーリング則の実装と最適化
- 品質・量のトレードオフバランス管理
- 多様な大規模データセット管理
- グローバル重複排除、動的データ選択（継続的ファインチューニング用）

---

## データ管理の4V

| 要素 | 説明 | LLMでの課題 |
|------|------|------------|
| **Volume** | データ量 | 大規模テキストコーパス、埋め込み生成コスト |
| **Variety** | データ多様性 | 構造化データ・非構造化データの混在処理 |
| **Velocity** | データ更新頻度 | リアルタイムデータパイプライン、ストリーミング |
| **Veracity** | データ正確性 | 毒性・バイアス・誤情報のフィルタリング |

### 静的 vs 動的データ管理

| 静的データ管理 | 動的データ管理 |
|--------------|--------------|
| トレーニング中データセット固定 | トレーニング中に継続的更新・調整 |
| 実装容易 | 柔軟性高い |
| 繰り返しデータのリスク | 品質・関連性の常時監視が必要 |

**動的手法例:**
- **動的データプルーニング**: トレーニング進行に伴い有用でない例を削除
- **バイナリ分類器**: 早期停止判定
- **合成データ生成**: 統計的特性を維持しながら既存データから自動生成

---

## LLMトレーニングの2ステップ

### 1. 事前トレーニング（Pretraining）

- **目的**: 言語の一般ルール・事実・文法・構文・スタイル・ドメイン知識を学習
- **手法**: オクルージョン（単語を隠してモデルに推測させる）
- **目標**: 単語推測エラーの最小化

### 2. 指示ファインチューニング（Instruction Fine-Tuning）

- **目的**: 指示に従う能力を学習
- **手法**: 複雑な指示と期待される回答のセット提供
- **目標**: 回答エラーの最小化

---

## データ前処理10ステップパイプライン

### ステップ0: 成功の測定定義（実行前）

**コアメトリクス（パイプライン実行後に即座に計算可能なもの）:**
- 単純な質問セット: "2+2は？", "フランスの首都は？"
- 複雑な質問セット: "これは鳥の写真か？（Yes/No）"

**定期評価:**
- 従来のベンチマーク（例: MMLU）
- セーフティ・バイアスチェックプロンプト

### ステップ1: データのカタログ化

- **目的明確化**: モデルの最終目標、適用方法
- **基準定義**: データタイプ、言語、ドメイン、品質標準
- **データベース化**: ソースをタグ付けして整理

### ステップ2: プライバシー・法的コンプライアンス確認

- データプライバシー法の遵守確認
- 適切なライセンス取得
- ライセンス情報をデータベースにタグ付け

### ステップ3: データのフィルタリング

**フィルタリング基準（クリーンデータルール）:**
- 不完全な文の削除
- PII（個人識別情報）の削除または置換
- 有害コンテンツ（暴力・ポルノ等）の削除
- 異常シンボルの削除
- 技術的クラッター（HTML・CSS・JavaScript識別子）の削除
- 中括弧を含む文の削除
- 短すぎる文の削除
- 冗長コンテンツ（ナビゲーションバー・「いいね」ボタン等）の削除
- 特定の不要単語を含むテキストの削除

**ツール例:**
- CulturaXコーパス: ブラックリストによる有害コンテンツフィルタリング
- クラウドベースフィルタリングソリューション

### ステップ4: データ重複排除

**重複排除手法:**

| 手法 | 説明 | 特徴 |
|------|------|------|
| **TF-IDF Soft Deduping** | テキスト内単語頻度とコーパス全体での頻度を比較 | 重要単語に高い重みを付与 |
| **MinHash** | ランダムハッシュで最小ハッシュ値セット生成し類似性推定 | 計算・ストレージ効率が高い |
| **SimHash** | テキスト特徴ベクトルを固定長ハッシュコードに変換 | ハッシュコード距離で類似性計算 |

**その他の方法:**
- 連続重複文の削除（最初のインスタンスのみ保持）
- 同一URL削除
- MinHashLSH + n-gram（類似度閾値: 通常0.8）

### ステップ5: データ収集

**収集方法:**
- Webクローラー、API、その他ツール使用
- 利用規約確認・著作権違反回避
- HTML解析、PDFテキスト抽出

**推奨データセット:**
- **Falcon**: キュレートされたデータセット
- **CommonCrawl**: 公開Webアーカイブ
  - **WARCフォーマット**: ページの生データすべて
  - **WETフォーマット**: 本文プレーンテキストのみ

**メタデータ付与**: 前ステップ（ソース、ライセンス、フィルタ情報）のメタデータを追加

### ステップ6: エンコーディング検出

- **重要性**: エンコーディングエラーは一見正常に見えるが検出困難、文字化けが発生
- **ツール**: Chardet（オープンソース）
- **作業**: 正しいエンコーディングでテキストファイルを処理し、エラーを出力前に検出
- **メタデータ付与**: エンコーディング情報を追加

### ステップ7: 言語検出

- **ツール**: lingua-py
- **作業**: 言語別にデータをサブセット分離
- **用途**: 言語表現の十分性確認（例: ポルトガル語LLMならポルトガル語データの量確認）
- **メタデータ付与**: 言語情報を追加

### ステップ8: チャンキング

**チャンキング手法:**

| 手法 | 説明 | 特徴 |
|------|------|------|
| **固定サイズチャンク** | 実装容易 | アイデアが分断されるリスク |
| **文ベースチャンク** | 明確な区別のあるアイデアに最適 | |
| **段落ベースチャンク** | 広範なコンテキスト保持 | サイズが大きい |

**高度な手法:**
- **メタデータ追加**: 既存LLMでチャンクの感情分析やトピック判定
- **LLMベースチャンキング**: ドキュメント全体を送信してチャンク返却を依頼
- **エージェントチャンキング**: LLMエージェントがアナリストをシミュレート、頻繁に使用されるチャンクを記録

**注意**: LLMベースチャンキングは計算コストが高い

**メタデータ**: 前ステップすべて（ソース、ライセンス、エンコーディング、言語）を含める

### ステップ9: データのバックアップ

- 定期的バックアップは安全ネット
- データ損失は壊滅的

### ステップ10: メンテナンスと更新

- データ収集システムは一度限りではない
- ソース更新、戦略改善により**データの鮮度と関連性**を維持
- 継続的改善が鍵

---

## ベクトル化（Vectorization）

### 概要

**ベクトル化**: テキストデータを高次元数値表現（ベクトル）に変換し、本質的特性をキャプチャするプロセス。「埋め込み（embedding）」とも呼ばれる。

**良い埋め込みモデルの特性:**
- 意味が近い単語・フレーズ → ベクトルが近い
- 意味が異なる単語・フレーズ → ベクトルが遠い

### 主要な埋め込み手法

| 手法 | 説明 | 特徴 |
|------|------|------|
| **Word2Vec** | 単語を分散表現ベクトル化 | 古典的手法 |
| **GloVe** | グローバルベクトル表現 | コーパス全体の統計利用 |
| **FastText** | サブワード情報考慮 | 未知語対応 |
| **Sentence-BERT** | 文レベルの埋め込み | 文の意味をキャプチャ |
| **OpenAI text-embedding-3-small** | 最大8,191トークン入力 → 1,536次元ベクトル出力 | 商用API |
| **BERT** | 小規模チャンク向け | カスタム埋め込み |

### 埋め込み生成のアプローチ

1. **Vectorデータベースへのアップロード**: データベースが自動的に埋め込み生成
2. **カスタム埋め込み生成**: OpenAI、BERT等のモデルで生成 → Vectorデータベースに保存

### ベクトル化の用途

- **RAG（Retrieval-Augmented Generation）**: クエリに類似したチャンクを検索 → LLMで自然な回答生成
- **セマンティック検索**: 意味的類似性に基づく検索
- **レコメンデーションシステム**: 類似アイテム推薦

---

## ベクトルデータベース

### 概要

**ベクトルデータベース**: 埋め込みを保存し、近似最近傍（ANN）検索を高速実行するように設計されたデータベース。

### 主な機能

- **インデックス化**: ベクトルを効率的に保存・検索
- **最近傍検索**: クエリベクトルに最も近いアイテムを返す
- **メタデータフィルタリング**: メタデータで検索空間を絞り込み、クエリ効率向上

### ベクトルデータベース選定の考慮事項

| 特性 | 説明 | 一般的なメトリクス | インデックス技術（影響） |
|------|------|-------------------|----------------------|
| **スケーラビリティ** | データ量・クエリ負荷増加への対応能力 | スループット（QPS）<br>レイテンシ<br>ストレージ容量 | 水平スケーリング機能（スループット影響）<br>シャーディング戦略（クエリ効率影響） |
| **耐障害性** | 障害時の可用性維持能力 | 稼働率%<br>MTTR（平均復旧時間） | データ複製（可用性保証）<br>HA機能（ダウンタイム最小化） |
| **インデックス技術** | 高次元ベクトル空間での効率的検索手法 | 検索精度<br>検索速度 | メトリックツリー（HNSW、VP-Tree）<br>ハッシング（LSH）<br>倒立ファイル（IVF） |

### 主要なベクトルデータベース

| データベース | 特徴 |
|------------|------|
| **Pinecone** | マネージドサービス、スケーラビリティ高い |
| **Weaviate** | オープンソース、GraphQL対応 |
| **Milvus** | オープンソース、分散アーキテクチャ |
| **Qdrant** | Rustベース、高速 |
| **ChromaDB** | 軽量、組み込み可能 |

### データ鮮度の維持

**ポーリング**:
- 定期的にソースデータをクエリし、最新スナップショットと比較
- 実装容易、リソース無駄、レイテンシあり

**CDC（Change Data Capture）**:
- ソースのトランザクションログ・コミットログまたは鮮度メタデータ（最終更新日等）に直接アクセス
- 変更ドキュメントリストを読み取り、該当ドキュメントのみ更新
- 無駄な更新を削減

**イベント駆動更新**:
- データ所有者が「商品説明変更」「記事更新」等のメッセージを送信
- 各イベントは自己完結、データベースへの即時更新トリガー

**ストリーミング**:
- Kafka、Apache Pulsar等の低レイテンシメッセージングプロトコル使用
- リアルタイムデータフィード統合

---

## LlamaIndex

**LlamaIndex**: データをLLMワークフローに接続するオープンソースデータフレームワーク（2022年末にGPT Indexとしてリリース）。

### 主な機能

- 数百フォーマットからのデータロード
- チャンキング
- 埋め込み
- インデックス化
- ベクトル埋め込みの取得

### LlamaIndexの活用

- データ前処理とベクトル表現生成
- CDC・イベント駆動更新パイプラインと連携し、変更データの再ベクトル化をトリガー
- データベースAPIを通じてベクトルデータベース更新

---

## ファインチューニングデータセットの生成

### 概要

事前トレーニングデータだけでは不十分。実用アプリケーションでは**指示データセット（Instruction Dataset）**または**ファインチューニングトレーニングデータセット**が必要。

### ファインチューニングデータセット作成の4アプローチ

| アプローチ | 説明 | メリット | デメリット |
|----------|------|---------|----------|
| **手動キュレーション** | チームで各指示を選択・作成 | 制御性高い、タスク特化可能 | 時間・労力がかかる |
| **既存オープンソースデータセット収集・改善** | オープンソースデータセットを洗練・改善 | 時間短縮、コミュニティ活用 | 調整が必要 |
| **LLMで生成** | 既存LLMで指示データセット生成 | 自動化、スケーラブル | 品質確認必要 |
| **ハイブリッド** | 上記すべてを組み合わせ | 柔軟性高い | 複雑性増加 |

### ファインチューニングデータセットのカテゴリ

| カテゴリ | 説明 | 用途 |
|---------|------|------|
| **汎用指示データセット** | 幅広いタスク・ドメインをカバー | 多目的モデルの指示追従能力向上 |
| **ドメイン特化指示データセット** | 特定分野（医療、法律、科学等）に特化 | 専門分野での正確性向上 |

### 指示ファインチューニングデータセットの自動生成（4ステップ）

**ステップ1: 前処理とベクトル化**
- **LlamaIndex使用**: 大規模テキストコーパスを前処理
  - トークン化、クリーニング
  - 高品質ベクトル表現生成
- **ベクトルデータベースに保存**: 多様なデータベース対応

**ステップ2: 検索メカニズム構築**
- 質問を与えると、ベクトルデータベースから最も近いチャンクを取得する簡易プログラム作成
- **LlamaIndexの`VectorIndexRetriever`**を活用可能

**ステップ3: 質問生成**
- ドキュメント（チャンクではない）を既存LLMに送信し、そのドキュメントで回答可能な質問セット生成を依頼
- 大きなドキュメントは複数部分に分割可能（ただしチャンクより大幅に大きい）
- 例: GPT-4oは約40万文字のドキュメントから質問リスト生成可能

**ステップ4: 最適な回答を既存LLMに決定させる**
- ステップ3で生成した各質問をステップ2のプログラムに送信 → 関連チャンクリスト取得
- 質問とチャンクリストの両方を既存LLMに送信
- **LLMに依頼**: 最適回答を含むチャンクを選択 → 理解可能で完全な回答を生成
- **JSON形式出力依頼**: `{"instruction": <question>, "input": "", "output": <answer>}`
- 必要な例数に達するまでサイクル繰り返し

### 生成後の品質確認

- **重複排除**: コサイン類似度でほぼ同一のQ&Aペアを削除
- **情報追加フィルタリング**: 取得パッセージに存在しない情報を導入する回答を除外
- **スポットチェック**: ランダムサンプルを手動確認し、自動フィルタの校正確認

### データセットの拡張

- **フォローアップ質問**: 同一パッセージについてより深い質問生成をLLMに依頼
- **制約付きフォーマット**: 有効なJSON等の制約付き形式での回答生成を依頼
- **目的**: ファインチューニングされたモデルがより複雑な指示に対応できるようにする

### リソース制約時の簡略化パイプライン

- **軽量埋め込みライブラリ**: BERTで埋め込み事前計算
- **検索ステップスキップ**: LLMが単一パッセージから質問と回答を生成
- **コサイン類似度で検証**: 回答がソーステキストに近いことを確認

---

## 動的データの扱い

### 推奨事項

| 推奨 | 説明 |
|------|------|
| **リアルタイムデータフィード統合** | Kafka、Apache Pulsar等の低レイテンシメッセージングプロトコル使用 |
| **タイムウィンドウセグメント化** | データ更新頻度に合わせたコンテキストウィンドウにデータをセグメント化<br>タイムスタンプをメタデータとして追加（例: 1週間前、数ヶ月前、履歴データ） |
| **タイムスタンプ別のトレーニングパイプライン分離** | 再トレーニングコスト削減<br>例: 1週間前データは毎日再トレーニング、1ヶ月前データは週次再トレーニング |
| **データバージョニング** | 異なるLLMデータイテレーションを追跡し、必要に応じて以前のバージョンにロールバック |

---

## データ品質の重要指標

### ドメイン構成（Domain Composition）

- **マルチドメインアプローチ**: Webページ、Wikipedia、書籍、学術論文等の多様なソース
- **コード混在の効果**: コードと非構造化テキストの混合トレーニングにより、非構造化タスクでの性能向上
- **最適なドメインミックス比率**: 実験と自動化手法により決定

### スケーリング則（Scaling Laws）

**Kaplan et al. (2020)のスケーリング則:**

- **損失とモデルサイズ・データサイズの関係**:
  - Loss ∝ (1/N)^α
  - Loss ∝ (1/D)^β
  - N: モデルサイズ、D: トレーニングデータサイズ

- **最適リソース配分（固定計算バジェットC）**:
  - D_opt ∝ C^0.27
  - N_opt ∝ C^0.73
  - モデルサイズがトレーニングデータサイズより速く増加すべき

**Chinchillaスケーリング則（Hoffmann et al.）:**

- 既存LLM（GPT-3等）は**アンダートレーニング**（パラメータ数に対してデータ量不足）
- 固定計算バジェットでは、パラメータ数増加とデータ量増加のバランスが重要
- データ量を優先的にスケールすることで、より大きいモデルより良い性能を少ない計算リソースで達成

### データ繰り返し（Data Repetition）

- **マルチエポック劣化**: 複数エポックでの繰り返しトレーニングにより性能低下
- **影響要因**: データセットサイズ、モデルパラメータ、トレーニング目標
- **改善手法**: ドロップアウトが一定の効果

### データ品質管理

**品質フィルタリング（Quality Filtering）:**
- 低品質データ（Common Crawl等）のフィルタリング
- スパム、誤情報、偏向、有害コンテンツの除外

**重複排除（Deduplication）:**
- **目的**: 記憶化（Memorization）リスク削減、Train-Testオーバーラップ最小化、多様性向上
- **効果**: 低いパープレキシティ達成

**毒性・バイアスフィルタリング（Toxicity and Bias Filtering）:**
- ヒューリスティック・ルールベース手法、n-gram分類器使用
- **課題**: マイノリティグループ関連テキストに毒性用語含まれる場合、過剰フィルタリングのリスク

**データ多様性（Data Diversity）:**
- 多様な言語スタイル、文化的コンテキスト、知識ドメインからの学習保証
- **課題**: 公開データセットは特定言語・地域・人口統計を過剰表現

**データ経年（Data Age）:**
- 新しいデータでの事前トレーニング推奨（時間依存知識対応）
- 事前トレーニングデータと評価データの時間的シフトにより性能推定不正確化

---

## AskUserQuestion指針

### ドメインミックス比率決定時

**質問例:**
```markdown
最適なドメインミックス比率を決定するため、以下の情報を教えてください：

1. ターゲットドメイン:
   - [ ] 汎用（Web・Wikipedia・書籍等）
   - [ ] コード重視（GitHub等）
   - [ ] 専門分野（医療・法律・科学等）

2. 期待する性能:
   - [ ] 幅広いタスク対応（汎用性）
   - [ ] 特定タスク高精度（専門性）

3. 計算バジェット:
   - [ ] 無制限
   - [ ] 制約あり（具体的に: ___）
```

### データ品質フィルタリング手法選定時

**質問例:**
```markdown
データ品質フィルタリング手法を選定するため、以下を確認します：

1. 許容可能な品質トレードオフ:
   - [ ] 高品質優先（低量でも可）
   - [ ] 量優先（品質は妥協可）
   - [ ] バランス重視

2. 特定フィルタリング要件:
   - [ ] PII除去必須
   - [ ] 毒性コンテンツ除去必須
   - [ ] ドメイン特化用語保持必須

3. 計算リソース制約:
   - [ ] 高度なフィルタリング（LLMベース）可能
   - [ ] 基本的フィルタリング（ルールベース）のみ
```

### スケーリング戦略選択時

**質問例:**
```markdown
スケーリング戦略を決定するため、以下を教えてください：

1. 現在のリソース状況:
   - モデルサイズ: ___（パラメータ数）
   - データサイズ: ___（トークン数）
   - 計算バジェット: ___

2. 優先事項:
   - [ ] モデルサイズ拡大優先
   - [ ] データ量拡大優先
   - [ ] バランス重視

3. 目標性能:
   - ターゲットパープレキシティ: ___
   - 許容トレーニング時間: ___
```