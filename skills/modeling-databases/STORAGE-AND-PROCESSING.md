# ストレージ戦略と分散処理フレームワーク

データベースのストレージアーキテクチャと分散処理に関する詳細リファレンス。データウェアハウススキーマ、行/列ストア、ハイブリッドストレージフォーマット、分散処理フレームワークの選択基準とアーキテクチャを解説します。

---

## Star Schema（スタースキーマ）

### 概要

Star Schemaはデータマート・データウェアハウスで最も広く使用されるシンプルなスキーマ設計パターン。中心に1つのファクトテーブル、周囲に複数のディメンションテーブルを配置し、物理モデルが星型に見えることが名前の由来。

### 構造

**ファクトテーブル（Fact Table）**
- 測定可能な定量データを格納（売上金額、販売数量、時間、距離等）
- 各レコードは特定のイベントまたはトランザクションを表現
- ディメンションテーブルへの外部キーを含む
- サロゲートキーで一意性を保証

**ディメンションテーブル（Dimension Table）**
- ファクトを説明する記述的属性を格納
- 主要なディメンション例：
  - **時間ディメンション**: 日付、週、月、四半期、年
  - **地理ディメンション**: 国、州、都市
  - **製品ディメンション**: カテゴリ、ブランド、SKU
  - **従業員ディメンション**: 部門、役職、営業担当者
  - **範囲ディメンション**: 価格帯、年齢層
- ファクトテーブルに比べてレコード数は少ない

### 3種類のファクトテーブル

| 種類 | 説明 | 例 |
|------|------|-----|
| **トランザクション型** | 特定イベントの記録 | 個別の売上トランザクション |
| **スナップショット型** | ある時点の状態 | 月末の口座残高 |
| **累積スナップショット型** | ある時点までの累計 | 月初来累計売上 |

### SQL例：スタースキーマクエリ

```sql
-- 1997年にブランド別・国別でTVセットの販売台数を集計
SELECT
  P.Brand,
  S.Country AS Countries,
  SUM(F.Units_Sold) AS Total_Units
FROM Fact_Sales F
INNER JOIN Dim_Date D ON (F.Date_Id = D.Id)
INNER JOIN Dim_Store S ON (F.Store_Id = S.Id)
INNER JOIN Dim_Product P ON (F.Product_Id = P.Id)
WHERE D.Year = 1997 AND P.Product_Category = 'tv'
GROUP BY P.Brand, S.Country;
```

### 長所

| 長所 | 詳細 |
|------|------|
| **シンプルなクエリ** | 高度に正規化されたスキーマと比較してJOINロジックが単純 |
| **ビジネスレポートロジックの簡素化** | 期間比較、時点比較レポートが容易 |
| **クエリパフォーマンス向上** | 読み取り専用レポーティングで性能改善 |
| **高速な集計** | シンプルなクエリ構造により集計操作が高速 |
| **OLAP Cubeとの親和性** | 全OLAPシステムがStar Schemaを基盤として効率的にキューブを構築 |

### 短所

| 短所 | 詳細 |
|------|------|
| **柔軟性の制約** | 特定の分析ビューに最適化されており、複雑な分析には不向き |
| **多対多関係のサポート不足** | ビジネスエンティティ間の多対多関係をシンプルに表現できない |
| **データ整合性の脆弱性** | 非正規化により更新異常が発生しやすい |
| **制御されたデータロードが必須** | バッチ処理またはトリクルフィードで厳密にロードする必要がある |

### Snowflake Schemaとの比較

**Snowflake Schema**は、ディメンションテーブルをさらに正規化したバリエーション。Star Schemaの特殊ケースと位置づけられる。

| 項目 | Star Schema | Snowflake Schema |
|------|-------------|------------------|
| ディメンション構造 | 非正規化（フラット） | 正規化（階層化） |
| ストレージ効率 | 冗長性あり | 冗長性少ない |
| クエリ複雑度 | シンプル | JOIN増加で複雑化 |
| パフォーマンス | 高速 | JOIN増加で若干遅延 |

### 選択判断基準

| 条件 | 推奨 |
|------|------|
| OLAP/分析レポーティングが主目的 | Star Schema |
| クエリパフォーマンス最優先 | Star Schema |
| ストレージコスト削減が最優先 | Snowflake Schema |
| 複雑な多対多関係が必要 | 正規化スキーマまたはハイブリッド |
| リアルタイム更新が頻繁 | OLTP向けの正規化スキーマ |

---

## Row-oriented vs Column-oriented Systems

### 概要

データベースがテーブルをディスクに永続化する際のシリアライズ戦略の違い。行ストア（Row-store）はレコード単位、列ストア（Column-store）は列単位でデータを物理的に配置する。

### Row-oriented Systems（行ストア）

**シリアライズ例**:
```
001:10,Smith,Joe,40000;
002:12,Jones,Mary,50000;
003:11,Johnson,Cathy,44000;
004:22,Jones,Bob,55000;
```

**特徴**:
- 1レコード全体が連続して格納される
- 1回のディスクI/Oで完全なレコードを取得可能
- トランザクション処理（OLTP）に最適

**適用場面**:
| ユースケース | 理由 |
|-------------|------|
| OLTP（オンライントランザクション処理） | 単一レコードの挿入・更新・削除が頻繁 |
| 特定オブジェクトの完全情報取得 | 顧客情報全体、商品詳細全体の取得 |
| ロードレックス、オンラインショッピング | 単一エンティティの全属性が必要 |

### Column-oriented Systems（列ストア）

**シリアライズ例**:
```
10:001,12:002,11:003,22:004;
Smith:001,Jones:002,004,Johnson:003;
Joe:001,Mary:002,Cathy:003,Bob:004;
40000:001,50000:002,44000:003,55000:004;
```

**特徴**:
- 同一列の値を連続して格納
- 重複値の圧縮が効率的（例: Jones:002,004）
- 列単位のクエリが高速

**適用場面**:
| ユースケース | 理由 |
|-------------|------|
| OLAP（分析クエリ） | 特定列のみをスキャンすればよい |
| 集計クエリ（SUM, AVG, COUNT） | 必要な列だけを読み込むため高速 |
| 「全ての人の姓を取得」 | 1列だけの読み込みで完結 |
| データウェアハウス | 分析用途で列単位アクセスが主 |

### 選択判断基準

| 条件 | 推奨システム | 理由 |
|------|-------------|------|
| 頻繁な INSERT/UPDATE/DELETE | Row-store | レコード単位の書き込みが効率的 |
| レコード全体の取得が主 | Row-store | 1回のディスクI/Oで完結 |
| 特定列のみのスキャンが主 | Column-store | 不要な列を読まない |
| 集計・分析クエリが主 | Column-store | 列圧縮と選択的読み込みで高速 |
| 給与範囲での絞り込み検索 | Column-store | 給与列のみをスキャン |
| トランザクション整合性が必須 | Row-store | ACID特性の実装が容易 |

### 性能比較

| 操作 | Row-store | Column-store |
|------|-----------|--------------|
| 単一レコード取得 | ◎ 高速 | △ 複数列からの再構築が必要 |
| 列単位集計 | △ 全行スキャン必要 | ◎ 高速（該当列のみ読み込み） |
| INSERT/UPDATE | ◎ 高速 | △ 複数の列ファイルに分散書き込み |
| 圧縮率 | △ 低い | ◎ 高い（同一列内で重複パターン多い） |

---

## RCFile (Record Columnar File)

### 概要

RCFileは、行ストアと列ストアの利点を組み合わせた**ハイブリッドストレージフォーマット**。MapReduce環境での大規模データ処理に最適化されている。

### 水平-垂直パーティショニング

**データ例**:
```
c1  c2  c3  c4
11  12  13  14
21  22  23  24
31  32  33  34
41  42  43  44
51  52  53  54
```

**ステップ1: 水平パーティショニング（行グループ化）**

行グループサイズ=3と仮定:
```
Row Group 1:
11 12 13 14
21 22 23 24
31 32 33 34

Row Group 2:
41 42 43 44
51 52 53 54
```

**ステップ2: 各行グループ内で垂直パーティショニング**

```
Row Group 1:
11, 21, 31;  # c1列
12, 22, 32;  # c2列
13, 23, 33;  # c3列
14, 24, 34;  # c4列

Row Group 2:
41, 51;      # c1列
42, 52;      # c2列
43, 53;      # c3列
44, 54;      # c4列
```

### 性能上の利点

| 利点 | 説明 |
|------|------|
| **高速データロード** | 行グループ単位でバッチ書き込み |
| **高速クエリ処理** | 必要な列のみを行グループから読み込み |
| **高効率ストレージ** | 列単位の圧縮により高圧縮率 |
| **動的アクセスパターン対応** | 行単位アクセスと列単位アクセスの両方に対応 |

### MapReduce環境での利用

- **行グループ = Map入力単位**: 各Mapperが1つまたは複数の行グループを処理
- **列圧縮によるネットワーク負荷削減**: 圧縮されたデータを転送するためシャッフルコストが低減
- **データローカリティ**: HDFSブロック境界と行グループを整合させることで、ネットワークI/Oを最小化

### 後続フォーマット

| フォーマット | 説明 |
|------------|------|
| **ORC (Optimized Row Columnar)** | Hortonworksが開発。RCFileの性能改善版 |
| **Parquet** | ClouderaとTwitterが開発。入れ子構造のサポート強化 |

### 採用実績

- **Facebook**: 2010年時点で世界最大のHadoopクラスタ（日次40TB追加）の標準フォーマット
- **Apache Hive**: v0.4から標準サポート
- **Apache Pig**: v0.7から標準サポート
- **Twitter, Yahoo, LinkedIn, AOL, Salesforce.com**: データ分析基盤で利用

---

## MapReduce

### 概要

MapReduceは、クラスタ上での並列分散アルゴリズムによる大規模データ処理のためのプログラミングモデル。Map（フィルタ・ソート）とReduce（集約）の2つの関数で構成される。

### プログラミングモデル

**論理ビュー**:
```
Map:    (k1, v1) → list(k2, v2)
Reduce: (k2, list(v2)) → list(k3, v3)
```

**データフロー（5ステップ）**:
1. **Map入力準備**: MapReduceシステムがMap入力キーK1を各プロセッサに割り当て
2. **Map実行**: 各K1キーに対してMap()を1回実行、K2キーで整理された出力を生成
3. **Shuffle**: Map出力をK2キーでソート・転送し、同じK2を持つデータを同じReducerに集約
4. **Reduce実行**: 各K2キーに対してReduce()を1回実行
5. **最終出力収集**: 全Reduce出力をK2でソートして最終結果を生成

### Word Count例

```python
# Map関数
def map(document_name, document_content):
    for word in document_content.split():
        emit(word, 1)

# Reduce関数
def reduce(word, partial_counts):
    total = sum(partial_counts)
    emit(word, total)
```

**処理フロー**:
1. ドキュメントを単語に分割
2. 各単語に対して `(word, 1)` を出力
3. フレームワークが同じwordを持つペアをグループ化
4. Reduce関数が各wordの出現回数を合計

### 平均値計算例

```python
# 11億人のソーシャルネットワークから年齢別の平均コンタクト数を算出

def Map(batch_id):  # K1 = バッチID (1-1100、各100万レコード)
    for person in batch:
        age = person.age
        contacts = person.num_contacts
        emit(age, (contacts, 1))  # K2 = 年齢

def Reduce(age, values):  # K2 = 年齢
    total_contacts = 0
    total_count = 0
    for (contacts, count) in values:
        total_contacts += contacts * count
        total_count += count
    average = total_contacts / total_count
    emit(age, (average, total_count))
```

**注意**: カウント情報を含めないと、複数回のReduce実行時に平均値が誤って計算される。

### 性能考慮事項

| 要素 | 説明 |
|------|------|
| **シャッフルコスト** | Map出力をReducerに転送する際のネットワークコストが支配的 |
| **パーティション関数** | データを均等に分散しないとReducerの負荷が偏る（遅いReducerがボトルネック） |
| **データローカリティ** | 処理をデータが存在するノードで実行することでネットワークトラフィックを削減 |
| **コンバイナ** | Map出力を事前集約してシャッフルデータ量を削減 |

### 適用場面と制限

**適用場面**:
- 分散パターン検索、分散ソート
- Webリンクグラフ反転、特異値分解
- Webアクセスログ統計、転置インデックス構築
- ドキュメントクラスタリング、機械学習

**制限**:
- **反復アルゴリズムには不向き**: 同じデータセットに対する反復クエリが困難
- **低レベルインターフェース**: CODASYL並の低レベル操作が必要
- **ステートレス要件**: MapperとReducerは状態を持てない
- **バッチ処理専用**: リアルタイムストリーム処理には不適

### 批判と代替技術

**批判**:
- 2005年以前に存在したTeradata等の並列データベースと本質的に同じ
- スキーマサポート不足によりB-tree、ハッシュパーティショニング等のDB最適化が利用不可

**代替技術**:
- **Apache Spark**: インメモリ処理により高速化
- **Google Percolator, FlumeJava, MillWheel**: ストリーミング処理とリアルタイム更新をサポート

---

## Apache Hadoop

### 概要

Apache Hadoopは、MapReduceプログラミングモデルを使用して大量データの分散ストレージ・処理を実現するオープンソースフレームワーク。コモディティハードウェアで構成されたクラスタ上で動作し、ハードウェア障害を自動的に処理する。

### アーキテクチャ

**コアモジュール**:

| モジュール | 説明 |
|-----------|------|
| **Hadoop Common** | 他のHadoopモジュールで使用されるライブラリとユーティリティ |
| **HDFS** | 分散ファイルシステム（コモディティマシン上で高集約帯域幅を提供） |
| **Hadoop YARN** | クラスタのコンピューティングリソース管理とジョブスケジューリング |
| **Hadoop MapReduce** | 大規模データ処理のためのMapReduce実装 |
| **Hadoop Ozone** | オブジェクトストア（2020年導入） |

### HDFS（Hadoop Distributed File System）

**アーキテクチャ**:
- **NameNode（1台）**: メタデータ管理、ファイルシステムツリー、ブロック位置情報
- **DataNode（複数）**: 実データをブロック単位で格納
- **Secondary NameNode**: NameNodeのチェックポイント作成（バックアップではない）

**主要特性**:

| 特性 | 説明 |
|------|------|
| **レプリケーション** | デフォルトで3重複（同一ラック2台、別ラック1台） |
| **ブロックサイズ** | 64-128MB（大きいファイルに最適化） |
| **ラック認識** | ネットワークトポロジを考慮したデータ配置 |
| **データローカリティ** | ジョブをデータが存在するノードで実行 |

**制限事項**:
- POSIX完全準拠ではない（スループット優先のトレードオフ）
- 小ファイルに不向き（多数のファイルでNameNodeがボトルネック）
- 並行書き込み不可（イミュータブルファイル設計）

### Hadoopエコシステム

| ツール | 用途 |
|--------|------|
| **Apache Pig** | データフロー言語（高レベルスクリプティング） |
| **Apache Hive** | SQLライクなクエリ言語（HiveQL） |
| **Apache HBase** | 列指向NoSQLデータベース |
| **Apache Spark** | インメモリ並列処理エンジン |
| **Apache ZooKeeper** | 分散調整サービス |
| **Cloudera Impala** | 低レイテンシSQLエンジン |
| **Apache Flume** | ログ収集・集約 |
| **Apache Sqoop** | RDBMSとHadoop間のデータ転送 |
| **Apache Oozie** | ワークフローエンジン |

### 他のファイルシステムとの互換性

- **file://** URL: ローカルファイルシステムを直接マウント可能（ただしローカリティ喪失）
- **FTP File System**: リモートFTPサーバー上のデータを使用
- **Amazon S3**: オブジェクトストレージ統合

---

## BigQuery

### 概要

BigQueryは、ペタバイト規模のデータ分析を可能にする**フルマネージド・サーバーレスデータウェアハウス**。GoogleのDremel技術を基盤とし、ANSI SQL対応、機械学習機能内蔵。

### Dremel技術

Dremelは、Googleのスケーラブルな対話型アドホッククエリシステム。**入れ子構造データ（Nested Data）**の分析に最適化されている。

### 主要機能

| 機能 | 説明 |
|------|------|
| **データ管理** | テーブル、ビュー、UDF（ユーザー定義関数）の作成・削除 |
| **インポート** | Google StorageからCSV/Parquet/Avro/JSON形式でインポート |
| **クエリ** | ANSI SQL標準、結果は最大128MBまたは無制限サイズ（Large Query Results有効時） |
| **統合** | Google Apps Script、REST API、各種クライアントライブラリから利用可能 |
| **アクセス制御** | データセットを個人、グループ、全体に共有 |
| **機械学習** | SQLクエリによるMLモデル作成・実行（BigQuery ML） |

### ユースケース

| ユースケース | 理由 |
|-------------|------|
| ペタバイト規模の分析クエリ | サーバーレス・自動スケーリング |
| リアルタイムダッシュボード | 低レイテンシクエリ |
| アドホック探索的分析 | SQL標準対応で学習コスト低 |
| 機械学習パイプライン | BigQuery ML統合 |

---

## AoS / SoA / AoSoA

### 概要

メモリレイアウトの設計パターン。SIMD（Single Instruction Multiple Data）最適化とキャッシュ効率に直接影響する。

### Array of Structures (AoS)

**定義**: 構造体の配列。各構造体のフィールドがインターリーブ（交互配置）される。

**C/C++例**:
```c
struct point3D {
    float x, y, z;
};
struct point3D points[N];
float get_point_x(int i) { return points[i].x; }
```

**メモリレイアウト**:
```
[x0 y0 z0][x1 y1 z1][x2 y2 z2]...
```

**長所**:
- 直感的な設計（オブジェクト指向と自然に対応）
- 単一オブジェクトの全フィールドへの高速アクセス
- ほとんどのプログラミング言語で直接サポート

**短所**:
- SIMD命令で特定フィールドのみを処理する場合に非効率
- キャッシュラインの無駄（全フィールドを使わない場合）

### Structure of Arrays (SoA)

**定義**: 各フィールドを独立した配列として格納。

**C/C++例**:
```c
struct pointlist3D {
    float x[N];
    float y[N];
    float z[N];
};
struct pointlist3D points;
float get_point_x(int i) { return points.x[i]; }
```

**メモリレイアウト**:
```
[x0 x1 x2 ... xN-1][y0 y1 y2 ... yN-1][z0 z1 z2 ... zN-1]
```

**長所**:
- SIMD命令で同種データを効率的に処理
- 特定フィールドのみのアクセス時にキャッシュ効率が高い
- 幅広い内部データパス（128bit等）を活用可能

**短所**:
- 複数キャッシュウェイを消費
- インデックスアドレッシングが非効率
- 単一オブジェクトの全フィールドアクセス時に複数の配列を走査

### Array of Structures of Arrays (AoSoA)

**定義**: AoSとSoAのハイブリッド。タイル/ブロック単位でSoAレイアウトを使用。

**C/C++例（SIMDレジスタ幅=8）**:
```c
struct point3Dx8 {
    float x[8];
    float y[8];
    float z[8];
};
struct point3Dx8 points[(N+7)/8];
float get_point_x(int i) { return points[i/8].x[i%8]; }
```

**メモリレイアウト**:
```
[x0-7 y0-7 z0-7][x8-15 y8-15 z8-15]...
```

**長所**:
- SoAのメモリスループット
- キャッシュローカリティとロードポートアーキテクチャに優しい
- 最新プロセッサで高性能

**短所**:
- 直感的でない（実装複雑度が上がる）

### 選択判断基準

| 条件 | 推奨レイアウト | 理由 |
|------|--------------|------|
| オブジェクト全体への頻繁なアクセス | AoS | 1回のキャッシュロードで全フィールド取得 |
| 特定フィールドのみのバッチ処理 | SoA | 不要なフィールドを読まない |
| SIMD最適化が必須 | SoA or AoSoA | ベクトル演算に最適 |
| ゲーム物理演算（位置ベクトル処理） | SoA or AoSoA | x, y, z座標を個別に処理 |
| データベースレコードのような完全なオブジェクト操作 | AoS | 自然なデータモデル |
| 最新プロセッサでの最高性能 | AoSoA | キャッシュとSIMDの両立 |

### 4Dベクトルの特殊ケース

GPU等の4レーンSIMDハードウェアでは、4D（x, y, z, w）ベクトルをAoSで扱うことが自然（1ベクトル=1 SIMDレジスタ）。ただし、最新のGPUはスカラーSIMTパイプラインに移行しており、SoAの方がメモリコアレシング（coalescing）により高性能。

---

## 選択マトリックス：システム別推奨用途

| データアクセスパターン | OLTP | OLAP | データウェアハウス | ストリーム処理 |
|---------------------|------|------|----------------|-------------|
| 単一レコード読み書き | Row-store | - | - | - |
| 列単位集計 | - | Column-store | Star Schema + Column-store | - |
| リアルタイム更新 | Row-store | - | - | Apache Kafka + Flink |
| バッチ分析 | - | RCFile/Parquet | BigQuery | - |
| 階層データ | - | - | Star Schema（ディメンション正規化） | - |
| ペタバイト規模 | - | Hadoop + HDFS | BigQuery | - |
| 低レイテンシクエリ | Row-store | Columnar (in-memory) | BigQuery | - |

---

## まとめ

### ストレージ戦略の選択

1. **OLTP（トランザクション処理）**: Row-store（行ストア）
2. **OLAP（分析クエリ）**: Column-store（列ストア）またはRCFile/Parquet
3. **データウェアハウス**: Star Schema + Column-store
4. **大規模分散処理**: Hadoop (HDFS + MapReduce)
5. **サーバーレス分析**: BigQuery

### メモリレイアウトの選択

1. **オブジェクト全体操作が主**: AoS
2. **SIMD最適化が必須**: SoA
3. **最新プロセッサでの最高性能**: AoSoA

### 性能最適化の原則

- **測定ファースト**: ベンチマークなしに選択しない
- **データローカリティ**: 処理をデータの近くで実行
- **圧縮**: 特に列ストアでは圧縮率が高い
- **パーティショニング**: データを論理的・物理的に分割
- **キャッシュ効率**: アクセスパターンに応じたレイアウト選択
