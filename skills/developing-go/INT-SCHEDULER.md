# Goスケジューラーの内部構造

Goランタイムが採用するワークスティーリング戦略、G-M-Pモデル、継続スティーリングの利点を解説。goroutineがどのようにOSスレッドへマルチプレキシングされ、効率的にスケジュールされるかを理解する。

---

## ワークスティーリングアルゴリズム

### フェアスケジューリングの問題

単純な負荷分散（各プロセッサーにタスクを均等に分配）では、以下の問題が発生：

- **プロセッサーのアイドル時間**: あるタスクが長時間実行されると、他のプロセッサーが待機
- **依存関係**: タスクが他のタスクの結果を待つ場合、ブロック
- **キャッシュ局所性の欠如**: 関連タスクが異なるプロセッサーに分散

```
時刻     P1       P2
-------------------------
t0       T1       T2
t1       T3       T2  (T2が長時間実行)
t2      (idle)    T4  (P1がアイドル)
```

### 分散デックの構造

各OSスレッド（M）に専用のデック（両端キュー）を持たせる：

```
[Thread 1]          [Thread 2]
  Deque               Deque
┌────────┐          ┌────────┐
│  T1    │          │  T3    │
│  T2    │          │  T4    │
└────────┘          └────────┘
   ↑ tail             ↑ tail
   ↓ head             ↓ head
```

利点：
- **集中的キューの競合を排除**: 各スレッドが専用デックを持つ
- **キャッシュ局所性**: 関連タスクが同じスレッドに残る
- **柔軟なスティーリング**: アイドルスレッドが他から仕事を盗む

### 4つの基本ルール

1. **分岐（fork）時**: タスクを自スレッドのデックの**最後尾（tail）に追加**
2. **アイドル時**: 他スレッドのデックの**先頭（head）から盗む**
3. **未達の合流地点（join）**: 自スレッドのデックの**最後尾から取り出す**
4. **デックが空**: (a) 合流地点で停止、または (b) 他スレッドから盗む

実行例（フィボナッチ計算）：

```go
// fib(4) の並行実行
go func() {
    result := <-fib(n-1) + <-fib(n-2)
}()

// T1のデック状態の遷移:
// [fib(4) の継続]
// [fib(4) の継続, fib(3) の継続]
// [fib(4) の継続, fib(3) の継続, fib(2) の継続] → fib(2) を最後尾から取得
```

最後尾のタスクの利点：
- **親の合流を早く完了**: デッドロック回避、メモリ効率化
- **キャッシュヒット率向上**: 最近処理したタスクの関連データがキャッシュに残る

---

## 継続スティーリング vs タスクスティーリング

### タスクスティーリング（チャイルドスティーリング）

**goroutineそのもの**をデックに入れる：

```
T1: fib(4) 実行
  → goroutine fib(3) をデックに追加
  → goroutine fib(2) をデックに追加
T2: fib(3) を盗む
```

問題点：
- 親の合流地点で**ストール（停止）** が発生しやすい
- goroutineが順不同に実行される

### 継続スティーリング（Goの採用手法）

**関数実行後の継続（続き）** をデックに入れる：

```
T1: fib(4) 実行
  → fib(3) を即座に実行開始
  → 「fib(4) の継続」をデックに追加
T2: 「fib(4) の継続」を盗む
```

利点：
- **直列実行のように動作**: T1が fib(4) → fib(3) → fib(2) → ... と順に実行
- **合流地点でストールしない**: 継続が先に盗まれても、親goroutineは進行可能
- **シングルスレッドと同じ動作**: スレッドが1つの場合、通常の関数呼び出しと同じフロー

### Goが継続スティーリングを採用する理由

```
継続スティーリングの優位性:

デックサイズ     : 上限あり（継続のみ）  vs  上限なし（全子タスク）
実行順序        : 直列（DFS的）         vs  順不同
合流地点        : ストールしない         vs  ストールする
```

**実行例の比較**（fib(4)）：

| ステップ数 | デック最大長 | ストール数 | コールスタック深さ |
|-----------|-------------|-----------|------------------|
| 継続スティーリング | 14 | 2（すべてアイドル） | 2 |
| タスクスティーリング | 15 | 3（ビジー中） | 3 |

### コンパイラサポートの必要性

継続スティーリングの実装要件：

```go
// コンパイラがこの変換を自動生成
func fib(n int) <-chan int {
    result := make(chan int)
    go func() {
        // ← ここが継続の開始地点
        if n <= 2 {
            result <- 1
            return
        }
        result <- <-fib(n-1) + <-fib(n-2)
    }()
    return result  // ← 継続: resultチャネルを返す
}

// 内部的には以下のように継続を表現（概念的）
type Continuation struct {
    PC     uintptr       // プログラムカウンター
    SP     uintptr       // スタックポインター
    State  interface{}   // 状態（変数等）
}
```

Goコンパイラがgoroutine起動時に継続情報（PC等）を保存し、スケジューラーがそれをデックで管理する。

---

## G-M-Pモデル

### 3つの概念

```
G (Goroutine)
├─ 状態（Running, Runnable, Waiting, Dead）
├─ プログラムカウンター（PC）
├─ スタックポインター（SP）
└─ 関連するチャネル、Mutex等

M (Machine / OSスレッド)
├─ OSスレッドのハンドル
├─ 現在実行中のG
└─ 割り当てられたP

P (Processor / Context)
├─ ローカルランキュー（デック）
├─ 実行統計
└─ mcache（メモリアロケーター）
```

### 関係性

```
┌─────────────────────────────────────────────┐
│  Goランタイム                               │
│                                             │
│  ┌──────┐    ┌──────┐    ┌──────┐         │
│  │  P0  │    │  P1  │    │  P2  │         │
│  │ Deque│    │ Deque│    │ Deque│         │
│  └───┬──┘    └───┬──┘    └───┬──┘         │
│      │           │           │             │
│  ┌───▼───┐   ┌──▼────┐  ┌──▼────┐         │
│  │  M0   │   │  M1   │  │  M2   │         │
│  │OS Thd │   │OS Thd │  │OS Thd │         │
│  └───┬───┘   └───┬───┘  └───┬───┘         │
│      │           │           │             │
│  ┌───▼───┐   ┌──▼────┐  ┌──▼────┐         │
│  │  G1   │   │  G3   │  │  G5   │         │
│  └───────┘   └───────┘  └───────┘         │
│                                             │
│  Global Run Queue: [G2, G4, G6, ...]       │
└─────────────────────────────────────────────┘
```

- **M**が起動され、**P**を管理し、PがGをスケジュールする
- 各Pは専用のローカルランキュー（デック）を持つ
- グローバルランキューは補助的（ブロック解除されたG等を一時保管）

### GOMAXPROCS

```go
import "runtime"

// 同時実行可能なP（コンテキスト）の数を設定
runtime.GOMAXPROCS(4)  // 4つのP

// デフォルトは論理CPUコア数
runtime.GOMAXPROCS(runtime.NumCPU())
```

- **P**の数 = `GOMAXPROCS`
- **M**の数は可変（必要に応じてGoランタイムが作成）
- **G**の数は制限なし（数千〜数百万個も可能）

---

## ブロッキング時の最適化

### コンテキストの引き離しと再割り当て

goroutineがI/O等でブロックすると、MもブロックされるがPは別のMに移動：

```
Before (Gがブロック):
┌──────┐
│  P   │
│ Deque│
└───┬──┘
    │
┌───▼───┐
│  M1   │ ← ブロック中
│OS Thd │
└───┬───┘
    │
┌───▼───┐
│  G1   │ ← I/O待ち
└───────┘

After (Pを引き離し):
┌──────┐              ┌──────┐
│  P   │              │ M1   │ ← ブロック中
│ Deque│              │OS Thd│
└───┬──┘              └───┬──┘
    │                     │
┌───▼───┐             ┌──▼───┐
│  M2   │ ← 新しいM   │  G1  │ ← I/O待ち
│OS Thd │              └──────┘
└───┬───┘
    │
┌───▼───┐
│  G2   │ ← Pのデックから取得
└───────┘
```

手順：
1. GがブロックすることをGoランタイムが検知
2. Pを現在のM（M1）から引き離す
3. Pを新しいM（M2）に割り当て
4. M2がPのデックから次のG（G2）を実行
5. G1がブロック解除されたら、M1が再開するか、グローバルキューに戻す

### グローバルコンテキスト

ブロック解除されたGが元のPに戻れない場合、グローバルランキューに配置：

```go
// 疑似コード
if goroutine.IsUnblocked() {
    if originalP.IsFree() {
        originalP.PushLocal(goroutine)
    } else {
        globalQueue.Push(goroutine)
    }
}
```

定期的にPはグローバルキューをチェック：
```go
// 疑似コード
if localDeque.IsEmpty() {
    g := globalQueue.Pop()
    if g != nil {
        execute(g)
    } else {
        // ワークスティーリング
        g = stealFrom(otherP)
    }
}
```

### CPU稼働率の維持

利点：
- ブロックされたMがCPUを占有しない
- 常に`GOMAXPROCS`個のCPUが稼働
- I/O待ちgoroutineが他の処理を妨げない

---

## 割り込み可能性

### 関数呼び出しごとの割り込み

Goランタイムは**関数呼び出し時にプリエンプションポイント**を設ける：

```go
func longRunning() {
    for i := 0; i < 1000000; i++ {
        heavyComputation()  // ← ここで割り込み可能
    }
}

// コンパイラが以下のコードを挿入（概念的）
func heavyComputation() {
    runtime.CheckPreempt()  // スケジューラーに制御を渡す機会
    // 実際の処理
}
```

利点：
- 長時間実行goroutineがCPUを占有しない
- 公平なスケジューリング

### 無限ループ問題（Issue #10958）

**関数呼び出しがないループ**は割り込み不可：

```go
// Bad: 割り込みポイントがない
func busyLoop() {
    for {
        // 関数呼び出しなし
        counter++
    }
}
```

問題点：
- このgoroutineがCPUを独占
- 他のgoroutineが実行されない
- GCがブロックされる（STW時にこのgoroutineが止まらない）

**回避策**：

```go
// Good: 定期的にruntime.Gosched()で明示的に譲歩
func busyLoop() {
    for {
        counter++
        if counter%1000 == 0 {
            runtime.Gosched()  // 他のgoroutineに実行機会を与える
        }
    }
}

// Better: チャネルやI/Oで自然に割り込みポイントを作る
func betterLoop(ctx context.Context) {
    ticker := time.NewTicker(time.Millisecond)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:  // ← ブロッキング操作なので割り込み可能
            counter++
        }
    }
}
```

**Issue #10958の現状**：
- Go 1.14で**非協調的プリエンプション**が一部導入
- ガベージコレクションのSTW時に強制的に停止可能
- 完全な解決は将来のバージョンで予定

---

## スケジューリングの実例

### goroutine起動から実行まで

```go
go func() {
    fmt.Println("Hello")
}()

// 内部動作（概念）:
// 1. Gオブジェクトを作成（スタック、PC等を初期化）
// 2. 現在のPのローカルデックの最後尾に追加
// 3. 現在のgoroutineは続行
// 4. 次の割り込みポイントで、Pがデックから新しいGを取得して実行
```

### ワークスティーリングの動作

```
P0のデック: [G1, G2, G3]
P1のデック: []  ← アイドル

P1の動作:
1. 自デックをチェック → 空
2. グローバルキューをチェック → 空
3. ワークスティーリング:
   - P0のデック先頭からG1を盗む
   - P0のデック: [G2, G3]
   - P1のデック: [G1]
4. G1を実行
```

### ブロッキング最適化の実例

```go
result, err := http.Get("https://example.com")
// ↑ ネットワークI/O → Gがブロック

// 内部動作:
// 1. GoランタイムがI/Oブロックを検知
// 2. 現在のPをMから引き離す
// 3. Pを別のM（またはスレッドプールから取得）に割り当て
// 4. 新しいMがPのデックから次のGを実行
// 5. I/O完了時:
//    - 元のMが再開
//    - Gをグローバルキューに戻す
//    - 別のPがグローバルキューからGを取得して実行
```

---

## まとめ

Goスケジューラーの内部構造の理解：

| 概念 | 説明 | 重要ポイント |
|-----|------|-------------|
| **ワークスティーリング** | アイドルスレッドが他から仕事を盗む | デックの先頭/最後尾の違い |
| **継続スティーリング** | 継続をデックに入れる | タスクスティーリングより効率的 |
| **G-M-Pモデル** | Goroutine/Machine/Processor | PがローカルランキューとMを管理 |
| **ブロッキング最適化** | Pを引き離して別のMに | CPU稼働率維持 |
| **割り込み可能性** | 関数呼び出し時にプリエンプション | 無限ループは注意 |

**開発者が知るべきこと**：
- goroutineは軽量（2KB〜）で大量生成可能
- `GOMAXPROCS`でP（並列度）を制御
- I/Oでブロックしても他のgoroutineに影響しない
- 関数呼び出しのないループは`runtime.Gosched()`で譲歩
- **`go`キーワードだけで、これら全てが自動的に最適化される**
