# AI開発セキュリティ戦略

## 概要

AI駆動型ソフトウェア開発の時代において、組織は**速度**と**セキュリティ**のバランスを取る必要があります。本スキルは、AIコーディングアシスタントやエージェントシステムを安全に採用するための組織的戦略を提供します。

**対象範囲:**
- AIコーディングアシスタント（GitHub Copilot、Google Gemini、Amazon CodeWhisperer等）
- エージェントAI（自律的な意思決定・API呼び出し・ワークフロー実行）
- AI加速型SDLC全般

**関連スキル:**
- コードレベルのセキュリティ → `securing-code` スキル参照
- AI開発手法（プロンプト、コンテキスト設計）→ `developing-with-ai` スキル参照

---

## AIコード・エージェントのリスクサマリー

### AIコーディングアシスタントの主要リスク

| リスク分類 | 具体的内容 | 影響 |
|-----------|----------|------|
| **脆弱性の混入** | 約50%のAI生成コードスニペットに脆弱性が含まれる | CWE Top 25の8種類を含む38種のCWEが検出 |
| **ハルシネーション依存** | 最大21%のAI生成依存関係が存在しないパッケージ | 攻撃者による悪意あるパッケージの投入リスク |
| **データ漏洩** | プロンプトへの機密情報含有 | 社内ドキュメント・コード流出の可能性 |
| **スピードの罠** | 従来のレビューサイクルを上回る速度 | 未検証コードの本番環境混入 |

### エージェントAIの固有リスク

エージェントAI（自律型AIシステム）は、コード生成を超えて**意思決定・API呼び出し・ワークフロー実行**を行います。

| リスク分類 | 脅威内容 | 対策の方向性 |
|-----------|---------|-------------|
| **メモリシステム汚染** | エージェントの記憶に悪意ある情報を注入 | サンドボックス化、メモリ検証 |
| **権限昇格** | エージェント連鎖による権限拡大 | 信頼境界の明確化、最小権限の原則 |
| **エージェント間通信ポイズニング** | エージェント間通信への攻撃 | 通信監視、ログ記録 |
| **プロンプトインジェクション** | 外部入力によるエージェント挙動改変 | 入力検証、出力サニタイズ |
| **モデル汚染** | 改ざんモデルの配布 | モデルプロベナンス追跡（AI-BOM） |

**OWASP Agentic AI - Threats and Mitigations** で15の脅威カテゴリが定義されています。

---

## 信頼ベースセキュリティフレームワーク

AI開発の信頼構築は**3つのE（Early, Explainable, Experience）**を基盤とします。

### 判断基準テーブル

| 原則 | 実装要件 | 評価基準 | ツール例 |
|-----|---------|---------|---------|
| **Early（早期検出）** | IDE、PR、リポジトリの3層でスキャン実施 | - MTTR 60%改善<br>- スキャンカバレッジ100% | SAST、SCA、リアルタイムスキャナ |
| **Explainable（説明可能性）** | CWE参照を含む脆弱性説明と修正理由の提示 | - 開発者がエラー理解可能<br>- AI提案の検証可能性 | コンテキスト型ツール、CWE参照システム |
| **Experience（開発者体験）** | IDE・SCM内でのネイティブ統合 | - 開発者がツールを離れない<br>- オンデマンド＋自動スキャン | IDE統合、MCP連携 |

### 3つのEの詳細

#### Early（早期検出）
**シフトレフトの実践:** コード生成時点でセキュリティを組み込む

- **IDE統合**: リアルタイムでのSAST/SCAスキャン、AI生成コードの即時検証
- **PR段階**: 自動スキャン、AI支援レビュー（但し人間のコンテキスト判断が必須）
- **リポジトリ**: 継続的な全コードスキャン、累積脆弱性の検出

**注意点:**
- AIによるAI生成コードのレビューは「異なるシステムによる検証」が必要
- 同一モデルによる自己検証は信頼性が低い
- 人間による最終確認、または事前承認済み修正パターンの使用を推奨

#### Explainable（説明可能性）
**透明性の確保:** 「なぜこの脆弱性が問題か」「なぜこの修正が最適か」を説明

- **CWE参照**: 標準的な脆弱性分類との紐付け
- **修正理由の明示**: 例：SQLインジェクション → パラメータ化クエリ/ストアドプロシージャ推奨
- **教育効果**: 開発者がパターンを学習し、将来的なミスを削減

**生成AI全般の説明可能性の課題:**
- LLMは数十億のパラメータによる統計的予測であり、論理的因果関係の追跡は困難
- 非決定的（同一質問でも異なる回答）
- セキュリティ特化ツールでは「参照パターン」「限定的な解決策」により説明可能性を実現

#### Experience（開発者体験）
**摩擦の排除:** セキュリティツールが開発ワークフローの一部となる

- **ネイティブ統合**: IDE、GitHub/GitLab等のSCM環境内で完結
- **オンデマンド + 自動**: 開発者主導のスキャン + PR/commit時の自動実行
- **フィードバック速度**: リアルタイム提案、即座の修正提示

**採用率への影響:**
- 摩擦が大きいツールは使われない
- 開発者体験を優先しないセキュリティ施策は失敗する

---

## クリティカルコントロールポイント

AI生成コードの脆弱性は**IDE / PR / リポジトリ**の3層で検出・修正が可能です。

| レイヤー | 検出タイミング | リスク内容 | 対策 | 成功指標 |
|---------|-------------|----------|------|---------|
| **IDE（開発時）** | コード生成時 | 開発者個人環境で脆弱性が混入 | リアルタイムSAST/SCA、IDE統合スキャナ | - 脆弱性の即時修正<br>- 下流への流出防止 |
| **PR（レビュー時）** | コードレビュー時 | 約17%のPRに重大脆弱性（CVSS 9-10） | 自動PR スキャン、AI支援レビュー（人間確認必須） | - レビューの質向上<br>- 81%の品質改善 |
| **リポジトリ（マージ後）** | 本番コード化後 | 潜在的脆弱性の蓄積、攻撃者による発見リスク | 継続的全コードスキャン、100%カバレッジ | - MTTR 60%短縮<br>- 100%スキャンカバレッジ |

**重要な教訓:**
- **単一レイヤーでは不十分**: 3層すべてにガードレールが必要
- **AI による AI レビューの限界**: 人間のコンテキスト理解が不可欠（特にPR段階）
- **データ**: 統合スキャンで60%早いMTTR、AI支援レビューで81%の品質改善

---

## AI信頼プラットフォーム成熟度モデル

組織の成熟度を3段階で評価し、段階的な導入を推進します。

### 成熟度レベルテーブル

| レベル | 特徴 | 実装内容 | 達成指標 |
|-------|-----|---------|---------|
| **基本** | AI導入初期、部分的スキャン | - 一部プロジェクトでのSAST/SCA<br>- 手動レビュー中心<br>- AI利用の可視化開始 | - スキャンカバレッジ < 50%<br>- AI利用把握率 < 70% |
| **中間** | IDE統合、PR自動化 | - IDE統合スキャン<br>- PR自動スキャン<br>- AI-BOM初期構築<br>- ポリシー定義開始 | - スキャンカバレッジ 50-80%<br>- MTTR 30-50%改善 |
| **先進** | 完全統合、リアルタイム防御 | - 3層（IDE/PR/Repo）完全統合<br>- リアルタイム修正提案<br>- AI-SPM運用<br>- エージェント監視<br>- 動的ポリシー適用 | - スキャンカバレッジ 100%<br>- MTTR 60%改善<br>- 開発者信頼度 > 70% |

**成熟度向上の鍵:**
1. **段階的導入**: 一部チームでパイロット → 全社展開
2. **メトリクス駆動**: カバレッジ、MTTR、開発者信頼度を継続測定
3. **フィードバックループ**: 開発者の声を反映したツール改善

---

## 適応型ガバナンス

従来の静的ポリシーでは、AI開発のスピードに対応できません。**適応型ガードレール**が必要です。

### 動的ポリシーの特徴

| 従来型（静的ポリシー） | 適応型（動的ポリシー） |
|-------------------|-------------------|
| 固定ルール、一律適用 | コンテキスト型、リスクスコアリング |
| 定期レビュー（数ヶ月単位） | リアルタイム更新 |
| 人間による判断・承認 | AI支援＋人間監視 |
| ツール導入が中心 | 統合プラットフォーム |

### AI-BOM（AI Bill of Materials）

AI資産の追跡とプロベナンス管理を実現します。

**記録対象:**
- 使用中のLLMモデル（GPT-4、Claude、Gemini等）
- ファインチューンアダプター
- プロンプトライブラリ
- エージェントシステム
- 学習データセット（可能な範囲で）
- モデルの改変履歴

**目的:**
- サプライチェーン透明性
- モデル汚染の検出
- コンプライアンス対応（EU CRA、NIST SSDF）

### AI-SPM（AI Security Posture Management）

AI固有のリスクを管理する新しいカテゴリのツールです。

**機能:**
- ポリシー適用の自動化
- エージェント挙動の監視
- コンテキスト型リスクスコアリング
- 監査トレイル生成
- モデルドリフト検出
- 敵対的入力への対応

**AI-SPMの範囲:**
- 不安全なモデル出力の検出
- モデルドリフト（性能劣化）の監視
- 敵対的入力の検出
- 広範なソフトウェアシステムとの統合管理

---

## クロスファンクショナル所有権

AI開発セキュリティは単一チームでは実現できません。組織横断的な協力が必要です。

| チーム/役割 | 主な責任 | 具体的アクション | 成功指標 |
|-----------|---------|---------------|---------|
| **開発者** | セキュアなコード作成、ツール利用 | - IDE統合ツールの使用<br>- リアルタイムスキャン実施<br>- 修正提案の適用 | - ツール利用率 > 80%<br>- 脆弱性修正率 |
| **セキュリティチーム** | ポリシー策定、リスク評価、監査 | - AI利用ポリシー定義<br>- AI-BOM管理<br>- インシデント対応計画 | - ポリシー遵守率<br>- インシデント対応時間 |
| **Platform/DevOps** | インフラ統合、CI/CD自動化 | - CI/CDパイプラインへのスキャン統合<br>- AI-SPM導入<br>- ログ収集・分析 | - スキャンカバレッジ<br>- パイプライン速度維持 |
| **リーダーシップ** | 戦略策定、予算確保、文化醸成 | - AI信頼戦略の承認<br>- リソース配分<br>- AI信頼チャンピオンの指名 | - 組織全体の採用率<br>- ROI測定 |
| **AI信頼チャンピオン** | 推進役、ベストプラクティス共有 | - 各チームへの啓蒙<br>- 成功事例の共有<br>- ツール評価・選定支援 | - チーム間連携度<br>- ナレッジ共有頻度 |

**クロスファンクショナル協力のポイント:**
- **共通言語**: AI-BOM、AI-SPM等の用語統一
- **定期的なレビュー**: 四半期ごとのポリシー・ツール見直し
- **フィードバックループ**: 開発者 ⇄ セキュリティチーム ⇄ Platform/DevOps

---

## メトリクスと測定

AI信頼プラットフォームの効果を定量的に評価します。

### 主要KPI

| メトリクス | 定義 | 目標値 | 測定方法 |
|----------|-----|-------|---------|
| **MTTR（Mean Time To Remediate）** | 脆弱性検出から修正までの平均時間 | 60%短縮（従来比） | スキャンツール・チケットシステム統合 |
| **スキャンカバレッジ** | セキュリティスキャン対象コード/全コードの割合 | 100% | リポジトリ分析、CI/CD統計 |
| **開発者信頼度** | AI生成コードの信頼度（アンケート） | > 70% | 定期的な開発者サーベイ |
| **AI利用率** | AI コーディングツール利用開発者の割合 | 組織目標に応じる | テレメトリデータ |
| **脆弱性検出率** | AI生成コード内の脆弱性検出割合 | ベースライン比較 | SAST/SCA統計 |

### ベンチマーク（成功事例）

業界トップパフォーマーの達成値:
- **統合スキャンでMTTR 60%改善**
- **100%スキャンカバレッジ達成**
- **AI支援レビューで81%の品質改善**

**測定の重要性:**
- データなしでは改善不可
- 継続的な測定でトレンド把握
- 経営層への報告材料

---

## ユーザー確認の原則（AskUserQuestion）

AI開発セキュリティ戦略の実装では、**組織固有の判断が必要**な場面が多数存在します。

### 確認が必要な判断ポイント

| 判断項目 | 選択肢例 | 確認タイミング |
|---------|---------|-------------|
| **成熟度レベルの評価** | 基本/中間/先進 | 初期アセスメント時 |
| **優先スキャン対象** | IDE/PR/リポジトリのいずれを優先するか | 導入計画策定時 |
| **AI-BOM対象範囲** | モデルのみ/プロンプト含む/データセット含む | ガバナンス設計時 |
| **ポリシー適用範囲** | 全プロジェクト/重要プロジェクトのみ | ポリシー策定時 |
| **インシデント対応優先度** | モデル汚染/プロンプトインジェクション/データ漏洩 | IR計画作成時 |

### AskUserQuestion使用例

```python
AskUserQuestion(
    questions=[{
        "question": "組織の現在のAI信頼プラットフォーム成熟度レベルを選択してください",
        "header": "成熟度評価",
        "options": [
            {
                "label": "基本レベル",
                "description": "AI導入初期、部分的スキャン、手動レビュー中心"
            },
            {
                "label": "中間レベル",
                "description": "IDE統合、PR自動化、AI-BOM初期構築"
            },
            {
                "label": "先進レベル",
                "description": "3層完全統合、リアルタイム防御、AI-SPM運用"
            }
        ],
        "multiSelect": False
    }]
)
```

---

## 詳細ドキュメント

より詳細な情報は以下のリファレンスを参照してください:

- **[RISK-LANDSCAPE.md](references/RISK-LANDSCAPE.md)**: AIコード・エージェントの脆弱性パターン、データ分析、業界調査結果
- **[TRUST-PLATFORM.md](references/TRUST-PLATFORM.md)**: 信頼プラットフォームのアーキテクチャ詳細、スケーラビリティ設計、ガバナンスフレームワーク
- **[IMPLEMENTATION.md](references/IMPLEMENTATION.md)**: ガバナンスプログラム形成手順、規制対応、CI/CDセキュリティ拡張、インシデントレスポンス

---

## まとめ

AI開発セキュリティ戦略の成功は以下の要素にかかっています:

1. **3つのE（Early, Explainable, Experience）** を基盤とした信頼構築
2. **3層防御（IDE/PR/リポジトリ）** による多層的なガードレール
3. **適応型ガバナンス（AI-BOM、AI-SPM）** による動的リスク管理
4. **クロスファンクショナル所有権** による組織全体の協力
5. **データ駆動型改善（MTTR、カバレッジ、信頼度）** による継続的進化

AI開発の速度とセキュリティは二者択一ではありません。適切な戦略とツールにより、**生産性向上とリスク低減の両立**が可能です。
