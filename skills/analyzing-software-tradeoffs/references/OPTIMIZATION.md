# 早すぎる最適化 vs ホットパスの最適化

## 概要

「早すぎる最適化は諸悪の根源」という格言は、**データなき最適化を戒める**言葉だ。必要なのは全コードパスを最適化することではなく、正しいコードパスを正しいタイミングで最適化することだ。

トラフィック量とSLAという客観的なデータがあれば、最適化は「早すぎる」ことにならない。重要なのは「どこを」最適化するかを定量的に判断することであり、パレートの法則とSLAを組み合わせることで、少ない労力で最大の効果を得られる。

## トレードオフ分析

### 最適化判断マトリクス

| 状況 | 推奨アクション |
|------|--------------|
| データなし・要件未定義 | 最適化しない。まずシンプルな実装から始める |
| SLAあり・ホットパス未特定 | ベンチマークテストでホットパスを測定・特定する |
| SLAあり・ホットパス特定済み | マイクロベンチマークで最適化効果を検証してから実施する |
| 本番トラフィックデータあり | メトリクスから実際のホットパスを確認・最適化する |

### 最適化アプローチ別比較

| アプローチ | 適用タイミング | 期待効果 | 複雑性増加 |
|-----------|--------------|--------|-----------|
| コード可読性優先（最適化なし） | 初期実装時 | - | 低 |
| アルゴリズム改善（O(n)→O(1)等） | ホットパス特定後 | 大 | 中 |
| キャッシュ導入 | ホットパス特定後 | 非常に大（100倍も可能） | 中〜高 |
| 並列処理 | 大量データ・ベンチマーク検証後 | ケースバイケース | 高 |

### パレートの法則による最適化優先度計算

```
# 最適化インパクトの計算式
impact(endpoint) = requests_per_second × p99_latency

# 例: 2つのエンドポイント
# /process-request : 10,000 req/s × 200ms = 2,000,000
# /modify-user     :     10 req/s × 500ms =     5,000

# 比率: /process-request が全体の99.75% を占める
# → /process-request を 10% 改善 = 200,000ms/s の削減
# → /modify-user を 2倍改善      =   2,500ms/s の削減
# → ホットパス最適化の効果は 80 倍
```

## よくある誤り

### 1. 仮定に基づいて最適化する

```
// ❌ データなしに「並列処理が速いはず」と思い込む
def find_account(accounts, id):
    # parallelで探索すれば速いはず...
    return parallel_find(accounts, id)

// ✅ ベンチマークで検証してから判断する
# ベンチマーク結果: N=10,000 で両者の差は0.003ms
# → 並列化のオーバーヘッドが利益を上回っている
# → 最適化不要と判断
```

### 2. レイテンシーだけでホットパスを判断する

```
// ❌ 「遅いエンドポイント = 最適化すべき対象」と誤解する
# /slow-endpoint   : p99 = 500ms, リクエスト数 = 10/s
# /fast-endpoint   : p99 = 200ms, リクエスト数 = 10,000/s

// ✅ リクエスト数 × レイテンシー でインパクトを計算する
# /slow-endpoint   : 500 × 10      = 5,000
# /fast-endpoint   : 200 × 10,000  = 2,000,000
# → /fast-endpoint を最適化すべき
```

### 3. キャッシュの性能テストが不十分

```
// ❌ 少数の固定単語でキャッシュ効果をテストする
words_to_test = ["make", "ask", "find"]  # 常にキャッシュヒットする
# → キャッシュが劇的に効果を出しているように見えるだけ

// ✅ 現実的な分布の単語数でテストする
# テスト期間中の想定リクエスト数と同等の単語種類を使用する
# 例: 1,200回のリクエストに対し100種類の単語をランダムに使用
```

### 4. 測定なしで根本原因を特定しようとする

処理全体が遅いとわかっていても、どのステップが原因かを測定せずに最適化しても意味がない。

```
# wordExists() が遅い → なぜ？
# ① ファイルロード: 0.7ms （問題なし）
# ② ファイルスキャン: 4,860ms （← 問題の根本原因）

# ② を最適化して 80 倍の性能向上を達成した
```

## 実践ガイドライン

### ホットパスの検出フロー

```
Step 1: SLA を定義する
         └─ 期待リクエスト数/秒、許容レイテンシー

Step 2: 負荷テストツールで現状を測定する
         └─ 各エンドポイントのリクエスト数 × p99 レイテンシー

Step 3: パレートの法則で優先度を計算する
         └─ impact = rps × latency で最大のものを特定

Step 4: 特定のコードパスをタイマーで計測する
         └─ ファイルI/O・DBクエリ・アルゴリズムなど処理単位で計測

Step 5: マイクロベンチマークで最適化案を検証する
         └─ ベースラインと改善版を比較して効果を確認

Step 6: エンドツーエンドの負荷テストで最終確認する
```

### SLAから並列ユーザー数を計算する方法

```
# 公式
concurrent_threads = rps_target / rps_per_thread
rps_per_thread     = 1000ms / avg_latency_ms

# 例: SLA = 10,000 req/s, 平均レイテンシー = 50ms
rps_per_thread     = 1000 / 50 = 20 req/s/thread
concurrent_threads = 10,000 / 20 = 500 threads

# 外れ値対策: 1.5倍の余裕を持たせる
safe_threads = 500 × 1.5 = 750 threads
```

### キャッシュ導入の判断基準

| 条件 | キャッシュ設計 |
|------|--------------|
| データが静的（変化しない） | 無制限キャッシュ（エビクションなし）も可能 |
| データが変化する可能性あり | TTLベースのエビクションを設定する |
| データ量が大きい | 遅延初期化（Lazy Loading）でメモリ使用を抑える |
| トラフィック分布が不明 | 短いTTLから始め、本番データでチューニングする |

### エビクション時間の設定方法

```
# トラフィックログから計算する場合
1. 同じキーへのリクエスト間隔の分布を計算する
2. p90 または p99 の間隔をエビクション時間に設定する
3. これにより、リクエストの 90〜99% がキャッシュヒットする

# データがない場合
1. 保守的な短い値（5分など）からスタート
2. 本番稼働後にキャッシュヒット率を監視する
3. ミス率が高ければTTLを延ばす
```

## まとめ

- **測定が前提**：「遅そう」という感覚ではなく、ベンチマークと測定に基づいて最適化対象を決める
- **パレートの法則を活用**：システムの価値の80%はコードの20%が生み出す。ホットパスを見つければ少ない労力で大きな改善が得られる
- **インパクト計算式**：`impact = rps × latency` でどのコードパスを最優先すべきかを定量的に判断する
- **キャッシュは強力**：適切なコードパスへの適用で100倍の性能改善も可能。ただし現実的なトラフィック分布でテストすること
- **最適化後に再計算**：ホットパスの最適化後はボトルネックが移動する。計算式で新たなホットパスを特定して継続的に改善する
- **SLAは最適化の羅針盤**：SLAと期待トラフィックが定まれば「早すぎる最適化」は「根拠ある最適化」になる
