# é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³

Google ADKã®é«˜åº¦ãªé–‹ç™ºãƒ‘ã‚¿ãƒ¼ãƒ³ã€æ„æ€æ±ºå®šãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã‚ªãƒ–ã‚¶ãƒ¼ãƒãƒ“ãƒªãƒ†ã‚£ã€æœ¬ç•ªé‹ç”¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã€‚

---

## 1. YAMLè¨­å®šãƒ™ãƒ¼ã‚¹Agentå®šç¾©

### 1.1 YAMLæ§‹æ–‡ã¨ã‚¹ã‚­ãƒ¼ãƒ

Agentã®å®šç¾©ã‚’ã‚³ãƒ¼ãƒ‰ã§ã¯ãªãYAMLãƒ•ã‚¡ã‚¤ãƒ«ã§å®£è¨€çš„ã«è¨˜è¿°ã§ãã‚‹ã€‚

**åŸºæœ¬æ§‹æ–‡:**

```yaml
name: my_agent          # å¿…é ˆ: Agentè­˜åˆ¥å­
model: gemini-2.0-flash # å¿…é ˆ: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«
description: "Agent purpose"
instruction: |
  Multi-line instructions
  for the agent behavior
generate_content_config:
  temperature: 0.7
  max_output_tokens: 2048
  top_p: 0.95
  top_k: 40
tools:
  - name: tool_name
    type: function
sub_agents:
  - name: specialized_agent
    model: gemini-2.0-flash
    description: "Specialized task handler"
    instruction: "Handle specific domain tasks"
```

**ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰èª¬æ˜:**

| ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ | å¿…é ˆ | èª¬æ˜ |
|-----------|------|------|
| `name` | âœ… | Agentè­˜åˆ¥å­ï¼ˆè‹±æ•°å­—ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ï¼‰ |
| `model` | âœ… | ä½¿ç”¨ã™ã‚‹Geminiãƒ¢ãƒ‡ãƒ«ID |
| `description` | æ¨å¥¨ | Agentã®ç›®çš„ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”¨ï¼‰ |
| `instruction` | æ¨å¥¨ | Agentã®æŒ¯ã‚‹èˆã„æŒ‡ç¤ºï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›¸å½“ï¼‰ |
| `generate_content_config` | ä»»æ„ | ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ |
| `tools` | ä»»æ„ | åˆ©ç”¨å¯èƒ½ãªToolãƒªã‚¹ãƒˆ |
| `sub_agents` | ä»»æ„ | éšå±¤åŒ–Agentã®å­å®šç¾© |

### 1.2 Pythonã‹ã‚‰ã®èª­ã¿è¾¼ã¿

**åŸºæœ¬èª­ã¿è¾¼ã¿:**

```python
from google.adk.agents import config_agent_utils

# YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Agentç”Ÿæˆ
agent = config_agent_utils.from_config('root_agent.yaml')

# Runnerèµ·å‹•
from google.adk.runners import InMemoryRunner
runner = InMemoryRunner(agent=agent, app_name="YAMLApp")
```

**âš ï¸ æ³¨æ„:** `AgentConfig.from_yaml_file()` ã¨ã„ã†ãƒ¡ã‚½ãƒƒãƒ‰ã¯å­˜åœ¨ã—ãªã„ã€‚å¿…ãš `config_agent_utils.from_config()` ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚

### 1.3 ç’°å¢ƒåˆ¥è¨­å®šç®¡ç†

**ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ:**

```
config/
â”œâ”€â”€ dev/
â”‚   â””â”€â”€ root_agent.yaml       # é–‹ç™ºç’°å¢ƒè¨­å®š
â”œâ”€â”€ staging/
â”‚   â””â”€â”€ root_agent.yaml       # ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°è¨­å®š
â””â”€â”€ prod/
    â””â”€â”€ root_agent.yaml       # æœ¬ç•ªè¨­å®š
```

**ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹åˆ‡ã‚Šæ›¿ãˆ:**

```python
import os
from pathlib import Path

def load_agent_for_environment() -> Agent:
    env = os.getenv("ENV", "dev")
    config_path = Path(f"config/{env}/root_agent.yaml")

    if not config_path.exists():
        raise FileNotFoundError(f"Config not found: {config_path}")

    return config_agent_utils.from_config(str(config_path))
```

### 1.4 ç’°å¢ƒå¤‰æ•°å‚ç…§ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¿…é ˆï¼‰

**æ©Ÿå¯†æƒ…å ±ã®å‚ç…§:**

```yaml
name: secure_agent
model: gemini-2.0-flash
tools:
  - name: api_client
    type: function
    config:
      api_key: "${API_KEY}"        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰æ³¨å…¥
      endpoint: "${API_ENDPOINT}"
```

**ç’°å¢ƒå¤‰æ•°è¨­å®š:**

```bash
export API_KEY="sk-..."
export API_ENDPOINT="https://api.example.com"
```

**âŒ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ç¦æ­¢ä¾‹:**

```yaml
# çµ¶å¯¾ã«ã“ã‚Œã‚’ã—ã¦ã¯ãªã‚‰ãªã„
tools:
  - name: api_client
    config:
      api_key: "sk-1234567890abcdef"  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯
```

### 1.5 è¨­å®šãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

**ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°:**

```python
from google.adk.agents import config_agent_utils

def validate_config(yaml_path: str) -> tuple[bool, str]:
    """YAMLè¨­å®šã®æ¤œè¨¼"""
    try:
        agent = config_agent_utils.from_config(yaml_path)

        # åŸºæœ¬æ¤œè¨¼
        assert agent.name, "Agent name is required"
        assert agent.model, "Model specification is required"

        # Toolæ¤œè¨¼
        if agent.tools:
            for tool in agent.tools:
                assert hasattr(tool, 'name'), "Tool must have name"

        return True, "Validation passed"

    except FileNotFoundError:
        return False, f"File not found: {yaml_path}"
    except yaml.YAMLError as e:
        return False, f"YAML syntax error: {e}"
    except AssertionError as e:
        return False, f"Validation failed: {e}"
    except Exception as e:
        return False, f"Unexpected error: {e}"

# ä½¿ç”¨ä¾‹
is_valid, message = validate_config("config/prod/root_agent.yaml")
if not is_valid:
    print(f"âŒ {message}")
    exit(1)
```

### 1.6 ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

YAMLå®£è¨€çš„å®šç¾©ã¨Pythonå‹•çš„ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã®çµ„ã¿åˆã‚ã›ã€‚

**ãƒ‘ã‚¿ãƒ¼ãƒ³:**

```python
# YAMLã§åŸºæœ¬æ§‹é€ ã‚’å®šç¾©
base_agent = config_agent_utils.from_config('base_agent.yaml')

# Pythonã§å‹•çš„ã«Toolã‚’è¿½åŠ 
from google.adk.tools import FunctionTool

def runtime_tool(query: str) -> str:
    """Runtime-added tool"""
    return f"Processed: {query}"

dynamic_tool = FunctionTool(
    name="runtime_tool",
    function=runtime_tool
)

# Toolã‚’çµåˆ
base_agent.tools = [*base_agent.tools, dynamic_tool]
```

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:**
- é–‹ç™ºç’°å¢ƒã§ã¯ãƒ¢ãƒƒã‚¯Toolã‚’è¿½åŠ 
- æœ¬ç•ªç’°å¢ƒã§ã¯å®Ÿéš›ã®APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ³¨å…¥
- A/Bãƒ†ã‚¹ãƒˆç”¨ã®å®Ÿé¨“çš„Toolå·®ã—æ›¿ãˆ

---

## 2. æ„æ€æ±ºå®šãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

### 2.1 Agentç¨®é¡é¸æŠ

| Agentç¨®é¡ | æœ€é©ç”¨é€” | ä¾‹ | è¤‡é›‘åº¦ |
|-----------|---------|-----|--------|
| `LlmAgent` | å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¹ã‚¯ã€ç´”ç²‹æ¨è«– | Q&Aã€æ–‡ç« è¦ç´„ã€åˆ†é¡ã€åˆ†æ | â­ |
| `SequentialAgent` | ä¾å­˜é–¢ä¿‚ã®ã‚ã‚‹é †åºä»˜ããƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ | ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‡¦ç†â†’åˆ†æâ†’ãƒ¬ãƒãƒ¼ãƒˆ | â­â­ |
| `ParallelAgent` | ç‹¬ç«‹ã—ãŸä¸¦è¡Œã‚¿ã‚¹ã‚¯ | ãƒãƒ«ãƒã‚½ãƒ¼ã‚¹æƒ…å ±åé›†ã€ä¸¦åˆ—åˆ†æ | â­â­ |
| `LoopAgent` | åå¾©çš„æ”¹å–„ã‚µã‚¤ã‚¯ãƒ« | ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç·¨é›†ã€å“è³ªãƒã‚§ãƒƒã‚¯ | â­â­â­ |

**é¸æŠåŸºæº–:**

```python
def recommend_agent_type(task_description: str) -> str:
    """ã‚¿ã‚¹ã‚¯ç‰¹æ€§ã‹ã‚‰æ¨å¥¨Agentç¨®é¡ã‚’è¿”ã™"""

    # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    has_dependencies = any([
        "then" in task_description,
        "after" in task_description,
        "based on" in task_description
    ])

    # ä¸¦è¡Œæ€§ãƒã‚§ãƒƒã‚¯
    is_parallel = any([
        "simultaneously" in task_description,
        "at the same time" in task_description,
        "multiple sources" in task_description
    ])

    # åå¾©æ€§ãƒã‚§ãƒƒã‚¯
    is_iterative = any([
        "improve" in task_description,
        "refine" in task_description,
        "until" in task_description
    ])

    if is_iterative:
        return "LoopAgent"
    elif is_parallel:
        return "ParallelAgent"
    elif has_dependencies:
        return "SequentialAgent"
    else:
        return "LlmAgent"
```

### 2.2 Toolç¨®é¡é¸æŠ

| åˆ¤æ–­è¦ç´  | FunctionTool | OpenAPITool | MCPTool |
|---------|-------------|-------------|---------|
| **é–‹ç™ºé€Ÿåº¦** | æœ€é€Ÿï¼ˆæ•°åˆ†ï¼‰ | ä¸­é€Ÿï¼ˆæ•°æ™‚é–“ï¼‰ | æœ€é…ï¼ˆ1æ—¥ä»¥ä¸Šï¼‰ |
| **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è² æ‹…** | æœ€é«˜ï¼ˆæ‰‹å‹•æ›´æ–°ï¼‰ | ä¸­ï¼ˆã‚¹ã‚­ãƒ¼ãƒåŒæœŸï¼‰ | æœ€ä½ï¼ˆã‚µãƒ¼ãƒãƒ¼å´ç®¡ç†ï¼‰ |
| **æŸ”è»Ÿæ€§** | æœ€å¤§ï¼ˆä»»æ„ã®Pythonå‡¦ç†ï¼‰ | é™å®šçš„ï¼ˆREST APIã®ã¿ï¼‰ | ä¸­ï¼ˆãƒ—ãƒ­ãƒˆã‚³ãƒ«åˆ¶ç´„å†…ï¼‰ |
| **ç›¸äº’é‹ç”¨æ€§** | ãªã—ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ï¼‰ | é™å®šçš„ï¼ˆOpenAPIæ¨™æº–ï¼‰ | æœ€å¤§ï¼ˆMCPæ¨™æº–ï¼‰ |
| **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒ«** | ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…å¿…é ˆ | APIã‚­ãƒ¼ãƒ™ãƒ¼ã‚¹ | çµ„ã¿è¾¼ã¿ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ |
| **ãƒ‡ãƒãƒƒã‚°é›£æ˜“åº¦** | ä½ï¼ˆç›´æ¥å®Ÿè¡Œï¼‰ | ä¸­ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è€ƒæ…®ï¼‰ | é«˜ï¼ˆã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹åˆ†é›¢ï¼‰ |

**é¸æŠæ±ºå®šæœ¨:**

```
ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—é–‹ç™ºï¼Ÿ
â”œâ”€ Yes â†’ FunctionTool
â””â”€ No
    â†“
å¤–éƒ¨APIé€£æºï¼Ÿ
â”œâ”€ Yes â†’ OpenAPIä»•æ§˜ã‚ã‚Šï¼Ÿ
â”‚         â”œâ”€ Yes â†’ OpenAPITool
â”‚         â””â”€ No â†’ FunctionToolï¼ˆãƒ©ãƒƒãƒ‘ãƒ¼å®Ÿè£…ï¼‰
â””â”€ No
    â†“
è¤‡æ•°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…±æœ‰ï¼Ÿ
â”œâ”€ Yes â†’ MCPTool
â””â”€ No â†’ FunctionTool
```

### 2.3 ãƒ¢ãƒ‡ãƒ«é¸æŠã‚¬ã‚¤ãƒ‰

| ç”¨é€” | æ¨å¥¨ãƒ¢ãƒ‡ãƒ« | ä¸»ãªåˆ©ç‚¹ | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | ã‚³ã‚¹ãƒˆ |
|------|----------|---------|----------|--------|
| é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ | `gemini-2.0-flash` | é€Ÿåº¦æœ€é©åŒ–ã€ä½ã‚³ã‚¹ãƒˆ | æœ€ä½ | æœ€å®‰ |
| è¤‡é›‘ãªæ¨è«– | `gemini-2.0-flash-thinking` | çµ„ã¿è¾¼ã¿Chain-of-Thought | ä¸­ | ä¸­ |
| ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ | `gemini-2.0-flash` | å¼·åŠ›ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ› | ä½ | å®‰ |
| ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« | `gemini-2.0-flash` | Visionã€Audioã€Videoå¯¾å¿œ | ä½ | å®‰ |
| ãƒ©ã‚¤ãƒ–å¯¾è©± | `gemini-2.0-flash-live` | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° | æœ€ä½ | ä¸­ |

**é¸æŠåŸºæº–ï¼ˆSLAè¦ä»¶ãƒ™ãƒ¼ã‚¹ï¼‰:**

```python
from dataclasses import dataclass

@dataclass
class ModelRequirement:
    max_latency_ms: int
    multimodal: bool
    reasoning_complexity: str  # "simple" | "complex"
    budget_tier: str  # "low" | "medium" | "high"

def select_model(req: ModelRequirement) -> str:
    """è¦ä»¶ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""

    if req.max_latency_ms < 500:
        if req.multimodal:
            return "gemini-2.0-flash"  # é«˜é€Ÿï¼‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«
        elif req.reasoning_complexity == "complex":
            return "gemini-2.0-flash-thinking"  # é«˜é€Ÿï¼‹æ¨è«–
        else:
            return "gemini-2.0-flash"  # æœ€é«˜é€Ÿ

    elif req.reasoning_complexity == "complex":
        return "gemini-2.0-flash-thinking"

    else:
        return "gemini-2.0-flash"
```

### 2.4 ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒé¸æŠ

| è¦ç´  | ãƒ­ãƒ¼ã‚«ãƒ« | Cloud Run | Agent Engine | GKE |
|------|---------|----------|-------------|-----|
| **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ™‚é–“** | æœ€é€Ÿï¼ˆæ•°åˆ†ï¼‰ | é€Ÿã„ï¼ˆæ•°æ™‚é–“ï¼‰ | ä¸­ï¼ˆåŠæ—¥ï¼‰ | æœ€é…ï¼ˆæ•°æ—¥ï¼‰ |
| **è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°** | æ‰‹å‹•ï¼ˆãƒ—ãƒ­ã‚»ã‚¹èµ·å‹•ï¼‰ | è‡ªå‹•ï¼ˆ0â†’Nï¼‰ | è‡ªå‹•ï¼ˆã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ï¼‰ | è‡ªå‹•ï¼ˆK8s HPAï¼‰ |
| **ã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«** | ç„¡æ–™ï¼ˆé–‹ç™ºãƒã‚·ãƒ³ï¼‰ | å¾“é‡èª²é‡‘ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰ | å¾“é‡èª²é‡‘ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰ | ã‚¤ãƒ³ãƒ•ãƒ©èª²é‡‘ï¼ˆå¸¸æ™‚ï¼‰ |
| **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º** | æœ€å¤§ï¼ˆä»»æ„ã®è¨­å®šï¼‰ | é™å®šï¼ˆDockerã‚³ãƒ³ãƒ†ãƒŠï¼‰ | é™å®šï¼ˆADKãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼‰ | æœ€å¤§ï¼ˆK8sãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆï¼‰ |
| **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶å¾¡** | ãªã—ï¼ˆlocalhostï¼‰ | VPC Connector | ãƒãƒãƒ¼ã‚¸ãƒ‰VPC | å®Œå…¨åˆ¶å¾¡ |
| **æœ€å¤§åŒæ™‚å®Ÿè¡Œæ•°** | CPUã‚³ã‚¢æ•°ä¾å­˜ | 1000ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ | è‡ªå‹•æœ€é©åŒ– | ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºä¾å­˜ |

**é¸æŠãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ:**

```
é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚ºï¼Ÿ
â”œâ”€ Yes â†’ ãƒ­ãƒ¼ã‚«ãƒ«
â””â”€ No
    â†“
ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯äºˆæ¸¬å¯èƒ½ï¼Ÿ
â”œâ”€ Noï¼ˆã‚¹ãƒ‘ã‚¤ã‚­ãƒ¼ï¼‰ â†’ Cloud Run
â””â”€ Yes
    â†“
VPCçµ±åˆå¿…é ˆï¼Ÿ
â”œâ”€ Yes â†’ GKE
â””â”€ No â†’ Agent Engine
```

### 2.5 ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ—é¸æŠ

| ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ†ã‚´ãƒª | ã‚¹ã‚³ãƒ¼ãƒ— | ä¿æŒæœŸé–“ | æš—å·åŒ– | ä¾‹ |
|-------------|---------|---------|--------|-----|
| **ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š** | `user:` | æ°¸ç¶š | å¿…é ˆ | ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€è¨€èªè¨­å®š |
| **ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ** | `session:` | ã‚»ãƒƒã‚·ãƒ§ãƒ³æœŸé–“ | æ¨å¥¨ | ä¼šè©±å±¥æ­´ã€ä¸€æ™‚çš„çŠ¶æ…‹ |
| **ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿** | `temp:` | ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã¿ | ä»»æ„ | ä¸­é–“è¨ˆç®—çµæœ |
| **ã‚¢ãƒ—ãƒªè¨­å®š** | `app:` | æ°¸ç¶š | å¿…é ˆ | API keysã€è¨­å®šãƒ•ãƒ©ã‚° |
| **PIIï¼ˆå€‹äººè­˜åˆ¥æƒ…å ±ï¼‰** | `user:` | æ°¸ç¶š | å¿…é ˆ | æ°åã€ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ |

**ã‚¹ã‚³ãƒ¼ãƒ—é¸æŠãƒ«ãƒ¼ãƒ«:**

```python
def determine_scope(data_type: str, retention_needed: bool, is_pii: bool) -> str:
    """ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã‹ã‚‰ã‚¹ã‚³ãƒ¼ãƒ—ã‚’æ±ºå®š"""

    if is_pii:
        # PII ã¯å¿…ãš user: ã‚¹ã‚³ãƒ¼ãƒ—
        return "user:"

    elif retention_needed:
        # æ°¸ç¶šåŒ–ãŒå¿…è¦
        if data_type in ["config", "settings", "preferences"]:
            return "app:"
        else:
            return "user:"

    elif data_type in ["conversation", "context"]:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æœŸé–“ã®ã¿ä¿æŒ
        return "session:"

    else:
        # ä¸€æ™‚çš„è¨ˆç®—çµæœ
        return "temp:"

# ä½¿ç”¨ä¾‹
scope = determine_scope("email_address", retention_needed=True, is_pii=True)
# â†’ "user:"

scope = determine_scope("intermediate_result", retention_needed=False, is_pii=False)
# â†’ "temp:"
```

---

## 3. é«˜åº¦ãªã‚ªãƒ–ã‚¶ãƒ¼ãƒãƒ“ãƒªãƒ†ã‚£

### 3.1 MetricsCollectorPlugin

ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«å…¨ä½“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã€‚

**å®Ÿè£…ä¾‹:**

```python
from google.adk.plugins import Plugin
from collections import defaultdict
import time

class MetricsCollectorPlugin(Plugin):
    def __init__(self):
        self.request_count = 0
        self.success_count = 0
        self.failure_count = 0
        self.latencies = []
        self.token_usage = defaultdict(int)
        self.tool_calls = defaultdict(int)

    def before_agent_callback(self, context):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²"""
        context.custom_data["start_time"] = time.time()
        self.request_count += 1

    def after_agent_callback(self, context):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Œäº†æ™‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†ç´„"""
        elapsed = time.time() - context.custom_data["start_time"]
        self.latencies.append(elapsed)

        if context.error:
            self.failure_count += 1
        else:
            self.success_count += 1

    def after_model_callback(self, context):
        """ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²"""
        if hasattr(context, 'usage_metadata'):
            self.token_usage['input'] += context.usage_metadata.prompt_token_count
            self.token_usage['output'] += context.usage_metadata.candidates_token_count

    def after_tool_callback(self, context):
        """Toolå‘¼ã³å‡ºã—å›æ•°ã‚’è¨˜éŒ²"""
        tool_name = context.tool_call.name
        self.tool_calls[tool_name] += 1

    def get_summary(self) -> dict:
        """é›†ç´„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿”ã™"""
        import statistics

        return {
            "total_requests": self.request_count,
            "success_count": self.success_count,
            "failure_count": self.failure_count,
            "success_rate": self.success_count / self.request_count if self.request_count > 0 else 0,
            "latency": {
                "mean": statistics.mean(self.latencies) if self.latencies else 0,
                "p50": statistics.median(self.latencies) if self.latencies else 0,
                "p95": statistics.quantiles(self.latencies, n=20)[18] if len(self.latencies) > 20 else 0,
                "p99": statistics.quantiles(self.latencies, n=100)[98] if len(self.latencies) > 100 else 0,
            },
            "tokens": dict(self.token_usage),
            "tool_calls": dict(self.tool_calls),
        }

# ä½¿ç”¨ä¾‹
metrics = MetricsCollectorPlugin()
agent = LlmAgent(
    model="gemini-2.0-flash",
    plugins=[metrics]
)

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†å¾Œ
print(metrics.get_summary())
# {
#   "total_requests": 100,
#   "success_count": 98,
#   "failure_count": 2,
#   "success_rate": 0.98,
#   "latency": {
#     "mean": 1.234,
#     "p50": 1.100,
#     "p95": 2.300,
#     "p99": 3.450
#   },
#   "tokens": {"input": 12000, "output": 8000},
#   "tool_calls": {"search": 45, "calculate": 23}
# }
```

### 3.2 PerformanceProfilerPlugin

Toolå®Ÿè¡Œæ™‚é–“ã®è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã€‚

**å®Ÿè£…ä¾‹:**

```python
from google.adk.plugins import Plugin
from collections import defaultdict
from dataclasses import dataclass, field
from typing import Dict, List
import time

@dataclass
class ToolStats:
    call_count: int = 0
    total_time: float = 0.0
    min_time: float = float('inf')
    max_time: float = 0.0
    times: List[float] = field(default_factory=list)

    def add_call(self, duration: float):
        self.call_count += 1
        self.total_time += duration
        self.min_time = min(self.min_time, duration)
        self.max_time = max(self.max_time, duration)
        self.times.append(duration)

    @property
    def avg_time(self) -> float:
        return self.total_time / self.call_count if self.call_count > 0 else 0

class PerformanceProfilerPlugin(Plugin):
    def __init__(self):
        self.tool_stats: Dict[str, ToolStats] = defaultdict(ToolStats)
        self.active_calls: Dict[str, float] = {}

    def before_tool_callback(self, context):
        """Toolå‘¼ã³å‡ºã—é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²"""
        call_id = f"{context.tool_call.name}_{id(context)}"
        self.active_calls[call_id] = time.time()

    def after_tool_callback(self, context):
        """Toolå®Ÿè¡Œæ™‚é–“ã‚’é›†è¨ˆ"""
        call_id = f"{context.tool_call.name}_{id(context)}"
        start_time = self.active_calls.pop(call_id, None)

        if start_time:
            duration = time.time() - start_time
            self.tool_stats[context.tool_call.name].add_call(duration)

    def get_profile(self) -> Dict[str, dict]:
        """Toolåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒª"""
        return {
            tool_name: {
                "call_count": stats.call_count,
                "total_time": round(stats.total_time, 3),
                "avg_time": round(stats.avg_time, 3),
                "min_time": round(stats.min_time, 3),
                "max_time": round(stats.max_time, 3),
            }
            for tool_name, stats in self.tool_stats.items()
        }

    def print_report(self):
        """è¦‹ã‚„ã™ã„ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›"""
        print("\n=== Performance Profile ===")
        for tool_name, stats in sorted(
            self.tool_stats.items(),
            key=lambda x: x[1].total_time,
            reverse=True
        ):
            print(f"\n{tool_name}:")
            print(f"  Calls:     {stats.call_count}")
            print(f"  Total:     {stats.total_time:.3f}s")
            print(f"  Avg:       {stats.avg_time:.3f}s")
            print(f"  Min/Max:   {stats.min_time:.3f}s / {stats.max_time:.3f}s")

# ä½¿ç”¨ä¾‹
profiler = PerformanceProfilerPlugin()
agent = LlmAgent(
    model="gemini-2.0-flash",
    plugins=[profiler]
)

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†å¾Œ
profiler.print_report()
# === Performance Profile ===
#
# search_web:
#   Calls:     45
#   Total:     12.345s
#   Avg:       0.274s
#   Min/Max:   0.120s / 1.230s
#
# calculate:
#   Calls:     23
#   Total:     3.456s
#   Avg:       0.150s
#   Min/Max:   0.080s / 0.450s
```

### 3.3 AlertingPlugin

é–¾å€¤ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ©ãƒ¼ãƒˆç›£è¦–ã€‚

**å®Ÿè£…ä¾‹:**

```python
from google.adk.plugins import Plugin
from dataclasses import dataclass
from typing import Callable
import time

@dataclass
class AlertConfig:
    latency_threshold_ms: int = 3000
    error_threshold: int = 5
    critical_error_threshold: int = 10
    on_alert: Callable[[str], None] = lambda msg: print(f"ğŸš¨ ALERT: {msg}")

class AlertingPlugin(Plugin):
    def __init__(self, config: AlertConfig = AlertConfig()):
        self.config = config
        self.consecutive_errors = 0

    def before_agent_callback(self, context):
        context.custom_data["request_start"] = time.time()

    def after_agent_callback(self, context):
        """ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨ã‚¨ãƒ©ãƒ¼é–¾å€¤ãƒã‚§ãƒƒã‚¯"""
        elapsed_ms = (time.time() - context.custom_data["request_start"]) * 1000

        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚¢ãƒ©ãƒ¼ãƒˆ
        if elapsed_ms > self.config.latency_threshold_ms:
            self.config.on_alert(
                f"High latency: {elapsed_ms:.0f}ms (threshold: {self.config.latency_threshold_ms}ms)"
            )

        # ã‚¨ãƒ©ãƒ¼ã‚¢ãƒ©ãƒ¼ãƒˆ
        if context.error:
            self.consecutive_errors += 1

            if self.consecutive_errors >= self.config.critical_error_threshold:
                self.config.on_alert(
                    f"ğŸ”´ CRITICAL: {self.consecutive_errors} consecutive errors"
                )
            elif self.consecutive_errors >= self.config.error_threshold:
                self.config.on_alert(
                    f"âš ï¸  WARNING: {self.consecutive_errors} consecutive errors"
                )
        else:
            self.consecutive_errors = 0  # æˆåŠŸæ™‚ã¯ãƒªã‚»ãƒƒãƒˆ

# ä½¿ç”¨ä¾‹
def send_to_pagerduty(message: str):
    """æœ¬ç•ªç’°å¢ƒã§ã¯PagerDutyç­‰ã«é€ä¿¡"""
    print(f"ğŸ“Ÿ Sending to PagerDuty: {message}")
    # requests.post("https://events.pagerduty.com/v2/enqueue", ...)

alert_config = AlertConfig(
    latency_threshold_ms=2000,
    error_threshold=3,
    critical_error_threshold=5,
    on_alert=send_to_pagerduty
)

alerting = AlertingPlugin(config=alert_config)
agent = LlmAgent(
    model="gemini-2.0-flash",
    plugins=[alerting]
)
```

### 3.4 Cloud Traceãƒ‡ãƒ—ãƒ­ã‚¤çµ±åˆ

ADK CLIã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚³ãƒãƒ³ãƒ‰ã« `--trace_to_cloud` ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€Google Cloud Traceã«è‡ªå‹•çš„ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’é€ä¿¡ã€‚

**Cloud Runãƒ‡ãƒ—ãƒ­ã‚¤:**

```bash
adk deploy cloud_run \
  --agent_file agent.py \
  --trace_to_cloud
```

**Agent Engineãƒ‡ãƒ—ãƒ­ã‚¤:**

```bash
adk deploy agent_engine \
  --agent_file agent.py \
  --trace_to_cloud
```

**ãƒ­ãƒ¼ã‚«ãƒ«Webã‚µãƒ¼ãƒãƒ¼:**

```bash
adk web \
  --agent_file agent.py \
  --trace_to_cloud
```

**Cloud Traceã§ã®ç¢ºèª:**

1. Google Cloud Console â†’ Trace â†’ Trace List
2. ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã®ã‚¹ãƒ‘ãƒ³è©³ç´°ã‚’ç¢ºèª
3. Toolå‘¼ã³å‡ºã—ã€ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ã®æ™‚é–“åˆ†å¸ƒã‚’å¯è¦–åŒ–

---

## 4. æœ¬ç•ªãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 4.1 ã‚³ãƒ¼ãƒ‰æ§‹æˆ

#### ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼Toolè¨­è¨ˆ

**å˜ä¸€è²¬ä»»åŸå‰‡:**

```python
# âŒ æ‚ªã„ä¾‹: 1ã¤ã®ToolãŒè¤‡æ•°è²¬å‹™ã‚’æŒã¤
@google.genai.function_declaration
def do_everything(query: str) -> str:
    """Search, process, and format"""
    data = search_api(query)
    processed = process_data(data)
    return format_output(processed)

# âœ… è‰¯ã„ä¾‹: Tool ã‚’åˆ†é›¢
@google.genai.function_declaration
def search(query: str) -> str:
    """Search for information"""
    return search_api(query)

@google.genai.function_declaration
def process_data(data: str) -> str:
    """Process raw data"""
    return process_logic(data)

@google.genai.function_declaration
def format_output(data: str) -> str:
    """Format data for presentation"""
    return format_logic(data)
```

**ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥æ•´ç†:**

```
tools/
â”œâ”€â”€ search/
â”‚   â”œâ”€â”€ web_search.py
â”‚   â””â”€â”€ document_search.py
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ text_processor.py
â”‚   â””â”€â”€ data_transformer.py
â””â”€â”€ formatting/
    â”œâ”€â”€ json_formatter.py
    â””â”€â”€ markdown_formatter.py
```

#### Agentã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥

```python
from functools import lru_cache
from google.adk.agents import LlmAgent

@lru_cache(maxsize=1)
def get_agent() -> LlmAgent:
    """Agentã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼ˆåˆæœŸåŒ–ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰"""
    return LlmAgent(
        model="gemini-2.0-flash",
        instruction="..."
    )

# FastAPIä¾‹
from fastapi import FastAPI
app = FastAPI()

@app.post("/chat")
async def chat(query: str):
    agent = get_agent()  # åˆå›ã®ã¿åˆæœŸåŒ–
    return await agent.run_async(query)
```

#### ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ç®¡ç†

```python
from google.adk.agents import LlmAgent

class SessionManager:
    def __init__(self, max_history: int = 10):
        self.max_history = max_history

    def prune_history(self, agent: LlmAgent):
        """å±¥æ­´ã‚’æœ€æ–°Nä»¶ã«åˆ¶é™"""
        if len(agent.state.history) > self.max_history:
            # å¤ã„å±¥æ­´ã‚’å‰Šé™¤
            agent.state.history = agent.state.history[-self.max_history:]

    def summarize_and_prune(self, agent: LlmAgent):
        """å¤ã„å±¥æ­´ã‚’è¦ç´„ã—ã¦ã‹ã‚‰å‰Šé™¤ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿æŒï¼‰"""
        if len(agent.state.history) > self.max_history:
            old_history = agent.state.history[:-self.max_history]
            summary = self._summarize(old_history)

            # è¦ç´„ã‚’æ–°ã—ã„å±¥æ­´ã®å…ˆé ­ã«é…ç½®
            agent.state.history = [
                {"role": "system", "content": f"Previous context: {summary}"},
                *agent.state.history[-self.max_history:]
            ]

    def _summarize(self, history: list) -> str:
        """å±¥æ­´ã®è¦ç´„ç”Ÿæˆï¼ˆåˆ¥ã®LLMå‘¼ã³å‡ºã—ã§å®Ÿè£…ï¼‰"""
        # å®Ÿè£…çœç•¥
        return "Summary of previous conversation..."

# ä½¿ç”¨ä¾‹
manager = SessionManager(max_history=10)

async def handle_request(query: str, agent: LlmAgent):
    manager.summarize_and_prune(agent)  # å±¥æ­´ç®¡ç†
    response = await agent.run_async(query)
    return response
```

### 4.2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

#### ç°¡æ½”ã§æ§‹é€ åŒ–ã•ã‚ŒãŸInstruction

```python
# âŒ æ‚ªã„ä¾‹: å†—é•·ã§æ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„
instruction = """
You are a helpful assistant. You should always be polite and respectful.
When users ask questions, you should try your best to answer them accurately.
If you don't know something, you should say so. Also, remember to be concise.
You have access to various tools that you can use to help answer questions.
Make sure to use them when appropriate. Don't forget to format your responses nicely.
Always double-check your work before responding. Be friendly and professional.
"""

# âœ… è‰¯ã„ä¾‹: ç°¡æ½”ã§æ§‹é€ åŒ–
instruction = """
Role: Technical support assistant

Rules:
1. Answer accurately; admit unknowns
2. Use tools when needed
3. Be concise and professional

Format: Markdown
"""
```

**åŠ¹æœ:** ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ç´„70%å‰Šæ¸›ï¼ˆ237 tokens â†’ 71 tokensï¼‰

#### ãƒãƒƒãƒå‡¦ç†

```python
import asyncio
from google.adk.agents import LlmAgent

async def process_batch(queries: list[str], agent: LlmAgent) -> list[str]:
    """è¤‡æ•°ã‚¯ã‚¨ãƒªã‚’ä¸¦è¡Œå‡¦ç†"""
    tasks = [agent.run_async(q) for q in queries]
    results = await asyncio.gather(*tasks)
    return results

# ä½¿ç”¨ä¾‹
queries = [
    "Summarize document 1",
    "Summarize document 2",
    "Summarize document 3",
]

agent = LlmAgent(model="gemini-2.0-flash")
results = await process_batch(queries, agent)

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:
# - é€æ¬¡å‡¦ç†: 3 Ã— 1.5s = 4.5s
# - ä¸¦è¡Œå‡¦ç†: max(1.5s, 1.5s, 1.5s) = 1.5s
# â†’ 3å€é«˜é€ŸåŒ–
```

#### ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†

```python
from google.adk.agents import LlmAgent

def manage_context_window(agent: LlmAgent, max_messages: int = 20):
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®è‡ªå‹•ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°"""
    history = agent.state.history

    if len(history) > max_messages:
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿æŒ
        system_messages = [m for m in history if m.get("role") == "system"]
        recent_messages = history[-max_messages:]

        # çµåˆ
        agent.state.history = system_messages + recent_messages

        print(f"Pruned {len(history) - len(agent.state.history)} messages")

# ä½¿ç”¨ä¾‹
agent = LlmAgent(model="gemini-2.0-flash")

for i in range(50):
    await agent.run_async(f"Query {i}")
    manage_context_window(agent, max_messages=20)
```

#### ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚£ã‚¢ãƒªãƒ³ã‚°

```python
from google.adk.agents import LlmAgent

class TieredAgentRouter:
    def __init__(self):
        self.lite_agent = LlmAgent(model="gemini-2.0-flash-lite")
        self.standard_agent = LlmAgent(model="gemini-2.0-flash")
        self.pro_agent = LlmAgent(model="gemini-2.0-flash-thinking")

    async def route(self, query: str) -> str:
        """ã‚¯ã‚¨ãƒªè¤‡é›‘åº¦ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""
        complexity = self._analyze_complexity(query)

        if complexity == "simple":
            return await self.lite_agent.run_async(query)
        elif complexity == "complex":
            return await self.pro_agent.run_async(query)
        else:
            return await self.standard_agent.run_async(query)

    def _analyze_complexity(self, query: str) -> str:
        """ã‚¯ã‚¨ãƒªã®è¤‡é›‘åº¦ã‚’åˆ¤å®š"""
        # ç°¡æ˜“ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯
        word_count = len(query.split())

        if word_count < 10:
            return "simple"
        elif word_count > 50 or "analyze" in query or "compare" in query:
            return "complex"
        else:
            return "standard"

# ä½¿ç”¨ä¾‹
router = TieredAgentRouter()

# ã‚·ãƒ³ãƒ—ãƒ«ãªåˆ†é¡ â†’ lite
result1 = await router.route("Is this positive or negative?")

# æ¨™æº–QA â†’ flash
result2 = await router.route("What is the capital of France?")

# è¤‡é›‘ãªåˆ†æ â†’ thinking
result3 = await router.route("Analyze the trade-offs between microservices and monolithic architecture")
```

**ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœ:**
- Liteä½¿ç”¨ç‡40% â†’ ã‚³ã‚¹ãƒˆ30%å‰Šæ¸›
- Proä½¿ç”¨ç‡10%ï¼ˆå¿…è¦æ™‚ã®ã¿ï¼‰ â†’ éå‰°ã‚¹ãƒšãƒƒã‚¯å›é¿

### 4.3 ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

#### ãƒ†ã‚¹ãƒˆãƒ”ãƒ©ãƒŸãƒƒãƒ‰æ§‹é€ 

```
     /\
    /  \  Evaluation (5-10%)
   /____\
  /      \  Integration (20-30%)
 /________\
/__________\  Unit (70-80%)
```

**Unit Testï¼ˆToolå˜ä½“ãƒ†ã‚¹ãƒˆï¼‰:**

```python
import pytest
from tools.search import web_search

def test_web_search_basic():
    result = web_search("Python ADK")
    assert "ADK" in result
    assert len(result) > 0

def test_web_search_empty_query():
    with pytest.raises(ValueError):
        web_search("")
```

**Integration Testï¼ˆAgent + Toolçµ±åˆãƒ†ã‚¹ãƒˆï¼‰:**

```python
import pytest
from google.adk.agents import LlmAgent
from tools.search import web_search_tool

@pytest.mark.asyncio
async def test_agent_with_search_tool():
    agent = LlmAgent(
        model="gemini-2.0-flash",
        tools=[web_search_tool]
    )

    response = await agent.run_async("Search for Python ADK")

    # Tool ãŒå‘¼ã°ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
    assert any(
        call.name == "web_search"
        for call in agent.state.tool_calls
    )

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    assert "ADK" in response
```

**Evaluation Testï¼ˆå“è³ªè©•ä¾¡ãƒ†ã‚¹ãƒˆï¼‰:**

```python
from google.adk.agents import LlmAgent

async def evaluate_accuracy(test_cases: list[dict]) -> float:
    """æ­£è§£ç‡è©•ä¾¡"""
    agent = LlmAgent(model="gemini-2.0-flash")
    correct = 0

    for case in test_cases:
        response = await agent.run_async(case["query"])
        if case["expected_keyword"] in response:
            correct += 1

    return correct / len(test_cases)

# ä½¿ç”¨ä¾‹
test_cases = [
    {"query": "What is 2+2?", "expected_keyword": "4"},
    {"query": "Capital of France?", "expected_keyword": "Paris"},
]

accuracy = await evaluate_accuracy(test_cases)
print(f"Accuracy: {accuracy * 100:.1f}%")
```

#### ãƒ¢ãƒƒã‚¯Toolæ¤œè¨¼

```python
from unittest.mock import AsyncMock
from google.adk.agents import LlmAgent
from google.adk.tools import FunctionTool

@pytest.mark.asyncio
async def test_agent_with_mock_tool():
    # ãƒ¢ãƒƒã‚¯Toolä½œæˆ
    mock_search = AsyncMock(return_value="Mocked result")
    search_tool = FunctionTool(
        name="search",
        function=mock_search
    )

    agent = LlmAgent(
        model="gemini-2.0-flash",
        tools=[search_tool]
    )

    response = await agent.run_async("Search for something")

    # Tool ãŒå‘¼ã°ã‚ŒãŸã“ã¨ã‚’æ¤œè¨¼
    mock_search.assert_called_once()

    # å¼•æ•°ã‚’æ¤œè¨¼
    args = mock_search.call_args[0]
    assert "something" in args[0].lower()
```

### 4.4 é‹ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³

#### SLIç›£è¦–

```python
from dataclasses import dataclass
from typing import List

@dataclass
class SLI:
    """Service Level Indicator"""
    name: str
    current_value: float
    target: float
    unit: str

    @property
    def is_meeting_target(self) -> bool:
        return self.current_value <= self.target

class SLIMonitor:
    def __init__(self):
        self.slis: List[SLI] = []

    def track(self, name: str, value: float, target: float, unit: str):
        sli = SLI(name, value, target, unit)
        self.slis.append(sli)

        if not sli.is_meeting_target:
            print(f"âš ï¸  SLI breach: {name} = {value}{unit} (target: {target}{unit})")

    def report(self):
        print("\n=== SLI Report ===")
        for sli in self.slis:
            status = "âœ…" if sli.is_meeting_target else "âŒ"
            print(f"{status} {sli.name}: {sli.current_value}{sli.unit} (target: {sli.target}{sli.unit})")

# ä½¿ç”¨ä¾‹
monitor = SLIMonitor()

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å¾Œ
monitor.track("p50_latency", 850, 1000, "ms")
monitor.track("p95_latency", 2100, 2000, "ms")  # é–¾å€¤è¶…é
monitor.track("p99_latency", 3200, 3000, "ms")  # é–¾å€¤è¶…é
monitor.track("error_rate", 0.02, 0.05, "%")
monitor.track("tool_success_rate", 0.98, 0.95, "%")

monitor.report()
# === SLI Report ===
# âœ… p50_latency: 850ms (target: 1000ms)
# âŒ p95_latency: 2100ms (target: 2000ms)
# âŒ p99_latency: 3200ms (target: 3000ms)
# âœ… error_rate: 0.02% (target: 0.05%)
# âœ… tool_success_rate: 0.98% (target: 0.95%)
```

#### ã‚¨ãƒ©ãƒ¼åˆ†é¡

```python
from enum import Enum

class ErrorCategory(Enum):
    RETRYABLE = "retryable"
    PERMANENT = "permanent"
    RATE_LIMIT = "rate_limit"

def classify_error(error: Exception) -> ErrorCategory:
    """ã‚¨ãƒ©ãƒ¼ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
    error_msg = str(error).lower()

    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼
    if "rate limit" in error_msg or "quota" in error_msg:
        return ErrorCategory.RATE_LIMIT

    # ä¸€æ™‚çš„ã‚¨ãƒ©ãƒ¼ï¼ˆãƒªãƒˆãƒ©ã‚¤å¯èƒ½ï¼‰
    if any(keyword in error_msg for keyword in [
        "timeout", "connection", "temporary", "503", "429"
    ]):
        return ErrorCategory.RETRYABLE

    # æ°¸ç¶šçš„ã‚¨ãƒ©ãƒ¼
    return ErrorCategory.PERMANENT

async def retry_with_backoff(func, max_retries: int = 3):
    """ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸãƒªãƒˆãƒ©ã‚¤"""
    import asyncio

    for attempt in range(max_retries):
        try:
            return await func()
        except Exception as e:
            category = classify_error(e)

            if category == ErrorCategory.PERMANENT:
                raise  # ãƒªãƒˆãƒ©ã‚¤ã—ãªã„

            elif category == ErrorCategory.RATE_LIMIT:
                wait_time = 60 * (2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆ60ç§’, 120ç§’, 240ç§’ï¼‰
                print(f"Rate limit hit, waiting {wait_time}s...")
                await asyncio.sleep(wait_time)

            elif category == ErrorCategory.RETRYABLE:
                wait_time = 2 ** attempt  # 1ç§’, 2ç§’, 4ç§’
                print(f"Retryable error, waiting {wait_time}s...")
                await asyncio.sleep(wait_time)

    raise Exception(f"Failed after {max_retries} retries")
```

#### ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼

```python
from enum import Enum
from dataclasses import dataclass
import time

class CircuitState(Enum):
    CLOSED = "closed"      # æ­£å¸¸å‹•ä½œ
    OPEN = "open"          # é®æ–­ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆæ‹’å¦ï¼‰
    HALF_OPEN = "half_open"  # å›å¾©ãƒ†ã‚¹ãƒˆä¸­

@dataclass
class CircuitBreakerConfig:
    failure_threshold: int = 5
    timeout_seconds: int = 60
    success_threshold: int = 2

class CircuitBreaker:
    def __init__(self, config: CircuitBreakerConfig = CircuitBreakerConfig()):
        self.config = config
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None

    async def call(self, func):
        """ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼çµŒç”±ã§ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""

        # OPENçŠ¶æ…‹ï¼ˆé®æ–­ä¸­ï¼‰
        if self.state == CircuitState.OPEN:
            if self._should_attempt_reset():
                self.state = CircuitState.HALF_OPEN
                print("ğŸ”„ Circuit HALF_OPEN: Testing recovery")
            else:
                raise Exception("Circuit breaker is OPEN")

        try:
            result = await func()
            self._on_success()
            return result

        except Exception as e:
            self._on_failure()
            raise

    def _on_success(self):
        """æˆåŠŸæ™‚ã®å‡¦ç†"""
        self.failure_count = 0

        if self.state == CircuitState.HALF_OPEN:
            self.success_count += 1
            if self.success_count >= self.config.success_threshold:
                self.state = CircuitState.CLOSED
                self.success_count = 0
                print("âœ… Circuit CLOSED: Recovered")

    def _on_failure(self):
        """å¤±æ•—æ™‚ã®å‡¦ç†"""
        self.failure_count += 1
        self.last_failure_time = time.time()

        if self.failure_count >= self.config.failure_threshold:
            self.state = CircuitState.OPEN
            print(f"ğŸ”´ Circuit OPEN: {self.failure_count} consecutive failures")

        if self.state == CircuitState.HALF_OPEN:
            self.state = CircuitState.OPEN
            self.success_count = 0
            print("ğŸ”´ Circuit OPEN: Recovery failed")

    def _should_attempt_reset(self) -> bool:
        """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆçµŒéå¾Œã«ãƒªã‚»ãƒƒãƒˆè©¦è¡Œ"""
        if self.last_failure_time is None:
            return False

        elapsed = time.time() - self.last_failure_time
        return elapsed >= self.config.timeout_seconds

# ä½¿ç”¨ä¾‹
breaker = CircuitBreaker(
    CircuitBreakerConfig(
        failure_threshold=5,
        timeout_seconds=60,
        success_threshold=2
    )
)

async def unreliable_service():
    """ä¸å®‰å®šãªå¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹"""
    import random
    if random.random() < 0.3:
        raise Exception("Service unavailable")
    return "Success"

async def protected_call():
    try:
        result = await breaker.call(unreliable_service)
        print(f"Result: {result}")
    except Exception as e:
        print(f"Error: {e}")

# é€£ç¶šå®Ÿè¡Œ
for _ in range(20):
    await protected_call()
    await asyncio.sleep(1)
```

---

## ã¾ã¨ã‚

### ä¸»è¦ãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠã‚¬ã‚¤ãƒ‰

| ã‚·ãƒŠãƒªã‚ª | æ¨å¥¨ãƒ‘ã‚¿ãƒ¼ãƒ³ |
|---------|------------|
| ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—é–‹ç™º | FunctionTool + InMemoryRunner + ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ |
| å°è¦æ¨¡æœ¬ç•ªï¼ˆ<100 req/dayï¼‰ | YAMLè¨­å®š + Cloud Run + MetricsCollector |
| ä¸­è¦æ¨¡æœ¬ç•ªï¼ˆ100-10k req/dayï¼‰ | YAMLè¨­å®š + Agent Engine + PerformanceProfiler + Alerting |
| å¤§è¦æ¨¡æœ¬ç•ªï¼ˆ>10k req/dayï¼‰ | Pythonæ§‹æˆ + GKE + Cloud Trace + ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ |
| ãƒãƒ«ãƒç’°å¢ƒç®¡ç† | YAMLç’°å¢ƒåˆ¥è¨­å®š + ç’°å¢ƒå¤‰æ•°å‚ç…§ |

### é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

**ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—:**
- [ ] FunctionToolã§é«˜é€Ÿå®Ÿè£…
- [ ] InMemoryRunnerã§å‹•ä½œç¢ºèª
- [ ] åŸºæœ¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°:**
- [ ] YAMLè¨­å®šã«ç§»è¡Œ
- [ ] MetricsCollectorPluginè¿½åŠ 
- [ ] Integration Testå®Ÿè£…
- [ ] Cloud Run/Agent Engineã«ãƒ‡ãƒ—ãƒ­ã‚¤

**æœ¬ç•ª:**
- [ ] PerformanceProfilerPluginè¿½åŠ 
- [ ] AlertingPluginè¨­å®š
- [ ] Cloud Traceæœ‰åŠ¹åŒ–
- [ ] ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼å®Ÿè£…
- [ ] SLIç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ§‹ç¯‰
- [ ] Evaluation Testï¼ˆå“è³ªè©•ä¾¡ï¼‰å®Ÿè£…
