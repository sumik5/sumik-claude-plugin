# Guardrails ã¨ Streaming è©³ç´°ã‚¬ã‚¤ãƒ‰

> **ğŸ“Œ Plugin Systemæ¨å¥¨ï¼ˆADKæœ€æ–°ï¼‰**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã‚„ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªå‰å¾Œå‡¦ç†ã«ã¯Plugin Systemã®ä½¿ç”¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚Pluginã¯Runnerå…¨ä½“ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã§é©ç”¨ã•ã‚Œã€Agent-localãªCallbacksã‚ˆã‚Šåºƒç¯„ãªåˆ¶å¾¡ãŒå¯èƒ½ã§ã™ã€‚è©³ç´°ã¯ [PLUGINS-AND-GROUNDING.md](PLUGINS-AND-GROUNDING.md) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚Callbacksã¯å¼•ãç¶šãæœ‰åŠ¹ã§ã€Agentå›ºæœ‰ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã«ã¯æœ€é©ã§ã™ã€‚

## ç›®æ¬¡

1. [Callbackå®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](#callbackå®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹)
2. [ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³](#ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³)
3. [PIIãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°](#piiãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°)
4. [SSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°](#sseã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)
5. [Live API éŸ³å£°å‡¦ç†](#live-api-éŸ³å£°å‡¦ç†)

---

## Callbackå®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### 6ç¨®é¡ã®Callback

ADKã¯6ã¤ã®Callbackãƒã‚¤ãƒ³ãƒˆã‚’æä¾›ã—ã€Agentå®Ÿè¡Œã®å„ãƒ•ã‚§ãƒ¼ã‚ºã§ä»‹å…¥å¯èƒ½ã€‚

#### Agent Lifecycle Callbacks

##### before_agent_callback

```python
from typing import Optional
from google.adk.agents.callback_context import CallbackContext
from google.genai.types import Content

def before_agent_callback(context: CallbackContext) -> Optional[Content]:
    """
    Agentå®Ÿè¡Œå‰ã«å‘¼ã°ã‚Œã‚‹ã€‚Contentã‚’è¿”ã™ã¨Agentå…¨ä½“ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚

    æˆ»ã‚Šå€¤:
        - Content: ã“ã®ContentãŒAgentã®æœ€çµ‚çµæœã¨ã—ã¦è¿”ã•ã‚Œã‚‹
        - None: Agentå®Ÿè¡Œã‚’ç¶™ç¶š
    """
    user_id = context.metadata.get("user_id")
    if not has_permission(user_id):
        return Content(parts=[Part.from_text("æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")])
    return None
```

##### after_agent_callback

```python
def after_agent_callback(
    context: CallbackContext,
    content: Content
) -> Optional[Content]:
    """
    Agentå®Œäº†å¾Œã«å‘¼ã°ã‚Œã‚‹ã€‚ä¿®æ­£ã—ãŸContentã§å‡ºåŠ›ã‚’ç½®æ›ã§ãã‚‹ã€‚

    å¼•æ•°:
        content: AgentãŒç”Ÿæˆã—ãŸå…ƒã®Content
    æˆ»ã‚Šå€¤:
        - Content: ã“ã®Contentã§Agentã®å‡ºåŠ›ã‚’ç½®æ›
        - None: å…ƒã®contentã‚’ãã®ã¾ã¾ä½¿ç”¨
    """
    # æœ€çµ‚å‡ºåŠ›ã®æ¤œè¨¼
    if contains_sensitive_data(content):
        return Content(parts=[Part.from_text("ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãŸã‚å‡ºåŠ›ã§ãã¾ã›ã‚“")])
    return None
```

#### LLM Interaction Callbacks

##### before_model_callback

```python
from google.genai import GenerateContentRequest, GenerateContentResponse

def before_model_callback(
    context: CallbackContext,
    request: GenerateContentRequest
) -> Optional[GenerateContentResponse]:
    """
    LLM APIå‘¼ã³å‡ºã—å‰ã«å‘¼ã°ã‚Œã‚‹ã€‚Responseã‚’è¿”ã™ã¨LLMå‘¼ã³å‡ºã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚

    å¼•æ•°:
        request: LLMã«é€ä¿¡äºˆå®šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    æˆ»ã‚Šå€¤:
        - GenerateContentResponse: LLMå‘¼ã³å‡ºã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã“ã®Responseã‚’ä½¿ç”¨
        - None: LLMå‘¼ã³å‡ºã—ã‚’ç¶™ç¶š
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    cache_key = hash_request(request)
    if cached := get_from_cache(cache_key):
        return cached

    # ä¸é©åˆ‡ãªå…¥åŠ›ã‚’ãƒ–ãƒ­ãƒƒã‚¯
    user_message = request.contents[-1].parts[0].text
    if contains_blocked_words(user_message):
        return GenerateContentResponse(
            candidates=[Candidate(
                content=Content(parts=[Part.from_text("ä¸é©åˆ‡ãªå…¥åŠ›ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")])
            )]
        )
    return None
```

##### after_model_callback

```python
def after_model_callback(
    context: CallbackContext,
    response: GenerateContentResponse
) -> Optional[GenerateContentResponse]:
    """
    LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡å¾Œã«å‘¼ã°ã‚Œã‚‹ã€‚ä¿®æ­£ã—ãŸResponseã§ç½®æ›ã§ãã‚‹ã€‚

    å¼•æ•°:
        response: LLMã‹ã‚‰è¿”ã•ã‚ŒãŸå…ƒã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    æˆ»ã‚Šå€¤:
        - GenerateContentResponse: ä¿®æ­£ã—ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ç½®æ›
        - None: å…ƒã®responseã‚’ãã®ã¾ã¾ä½¿ç”¨
    """
    # PIIãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    original_text = response.candidates[0].content.parts[0].text
    filtered_text = redact_pii(original_text)

    if filtered_text != original_text:
        return GenerateContentResponse(
            candidates=[Candidate(
                content=Content(parts=[Part.from_text(filtered_text)])
            )]
        )
    return None
```

#### Tool Execution Callbacks

##### before_tool_callback

```python
from typing import Dict, Any

def before_tool_callback(
    context: CallbackContext,
    tool_name: str,
    tool_args: Dict[str, Any]
) -> Optional[Dict[str, Any]]:
    """
    Toolå®Ÿè¡Œå‰ã«å‘¼ã°ã‚Œã‚‹ã€‚dictã‚’è¿”ã™ã¨Toolå®Ÿè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚

    å¼•æ•°:
        tool_name: å®Ÿè¡Œäºˆå®šã®Toolå
        tool_args: Toolã«æ¸¡ã•ã‚Œã‚‹å¼•æ•°
    æˆ»ã‚Šå€¤:
        - Dict: Toolå®Ÿè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã“ã®çµæœã‚’ä½¿ç”¨
        - None: Toolå®Ÿè¡Œã‚’ç¶™ç¶š
    """
    # å¼•æ•°ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if tool_name == "get_user_data":
        user_id = tool_args.get("user_id")
        if not is_valid_user_id(user_id):
            return {"error": "ç„¡åŠ¹ãªãƒ¦ãƒ¼ã‚¶ãƒ¼IDã§ã™"}

    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
    if exceed_rate_limit(tool_name, context.metadata.get("user_id")):
        return {"error": "ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸ"}

    return None
```

##### after_tool_callback

```python
def after_tool_callback(
    context: CallbackContext,
    tool_name: str,
    tool_result: Dict[str, Any]
) -> Optional[Dict[str, Any]]:
    """
    Toolå®Œäº†å¾Œã«å‘¼ã°ã‚Œã‚‹ã€‚ä¿®æ­£ã—ãŸçµæœã§ç½®æ›ã§ãã‚‹ã€‚

    å¼•æ•°:
        tool_name: å®Ÿè¡Œã•ã‚ŒãŸToolå
        tool_result: ToolãŒè¿”ã—ãŸå…ƒã®çµæœ
    æˆ»ã‚Šå€¤:
        - Dict: ä¿®æ­£ã—ãŸçµæœã§ç½®æ›
        - None: å…ƒã®tool_resultã‚’ãã®ã¾ã¾ä½¿ç”¨
    """
    # ãƒ­ã‚°è¨˜éŒ²
    log_tool_execution(tool_name, tool_result)

    # çµæœã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if "internal_data" in tool_result:
        filtered_result = {k: v for k, v in tool_result.items() if k != "internal_data"}
        return filtered_result

    return None
```

### Callbacké¸æŠåŸºæº–ãƒ†ãƒ¼ãƒ–ãƒ«

| ç›®çš„ | æœ€é©Callback | ç†ç”± |
|------|------------|------|
| ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨©é™ãƒã‚§ãƒƒã‚¯ | `before_agent` | æœ€ã‚‚æ—©ã„æ™‚ç‚¹ã§Agentå…¨ä½“ã‚’ã‚¹ã‚­ãƒƒãƒ—å¯èƒ½ |
| ä¸é©åˆ‡å…¥åŠ›ãƒ–ãƒ­ãƒƒã‚¯ | `before_model` | LLMã«ä¸é©åˆ‡å†…å®¹ã‚’é€ä¿¡ã—ãªã„ã€APIã‚³ã‚¹ãƒˆå‰Šæ¸› |
| å¼•æ•°ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ | `before_tool` | ç„¡åŠ¹ãªToolå®Ÿè¡Œã‚’é˜²æ­¢ |
| APIå‘¼ã³å‡ºã—è¿½è·¡ | `before/after_model` | ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã«ã‚¢ã‚¯ã‚»ã‚¹ |
| PIIãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° | `after_model` | LLMå‡ºåŠ›ã®å¾Œå‡¦ç† |
| Toolçµæœãƒ­ã‚° | `after_tool` | å®Œå…¨ãªå®Ÿè¡Œè©³ç´°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ |
| ãƒ¬ãƒ¼ãƒˆåˆ¶é™ | `before_tool` | Toolå˜ä½ã®ã‚¯ã‚ªãƒ¼ã‚¿å¼·åˆ¶ |
| æœ€çµ‚å‡ºåŠ›æ¤œè¨¼ | `after_agent` | ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å±Šãå‰ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯ |

### åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ãƒ«ãƒ¼ãƒ«

- **ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™**: ãã®æ“ä½œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€è¿”ã•ã‚ŒãŸå€¤ã‚’çµæœã¨ã—ã¦ä½¿ç”¨
- **Noneã‚’è¿”ã™**: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œã‚’ç¶™ç¶š

---

## ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³

### 1. ä¸é©åˆ‡å…¥åŠ›ãƒ–ãƒ­ãƒƒã‚¯

```python
BLOCKED_WORDS = ["æš´åŠ›çš„", "ä¸é©åˆ‡", "é•æ³•"]

def input_guard_callback(
    context: CallbackContext,
    request: GenerateContentRequest
) -> Optional[GenerateContentResponse]:
    user_message = request.contents[-1].parts[0].text.lower()

    for word in BLOCKED_WORDS:
        if word in user_message:
            return GenerateContentResponse(
                candidates=[Candidate(
                    content=Content(parts=[Part.from_text(
                        "ä¸é©åˆ‡ãªå†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€å‡¦ç†ã§ãã¾ã›ã‚“ã€‚"
                    )])
                )]
            )
    return None

agent = Agent(
    name="safe_agent",
    model="gemini-2.0-flash",
    instruction="å®‰å…¨ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
    before_model_callback=input_guard_callback
)
```

### 2. Toolå¼•æ•°ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

```python
def validate_tool_args_callback(
    context: CallbackContext,
    tool_name: str,
    tool_args: Dict[str, Any]
) -> Optional[Dict[str, Any]]:
    if tool_name == "process_order":
        quantity = tool_args.get("quantity", 0)
        if not (1 <= quantity <= 100):
            return {
                "success": False,
                "error": "æ•°é‡ã¯1ã‹ã‚‰100ã®é–“ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            }

    if tool_name == "access_database":
        user_id = context.metadata.get("user_id")
        if not has_database_permission(user_id):
            return {
                "success": False,
                "error": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“"
            }

    return None

agent = Agent(
    name="validated_agent",
    model="gemini-2.0-flash",
    tools=[process_order_tool, access_database_tool],
    before_tool_callback=validate_tool_args_callback
)
```

### 3. å®‰å…¨æŒ‡ç¤ºæ³¨å…¥

```python
from google.adk.agents import InstructionProvider

class SafetyInstructionProvider(InstructionProvider):
    def get_instruction(self, context: ReadonlyContext) -> str:
        base_instruction = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
        safety_rules = """

        å®‰å…¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³:
        - å€‹äººæƒ…å ±ã‚’è¦æ±‚ã—ãªã„
        - é•æ³•è¡Œç‚ºã‚’åŠ©é•·ã—ãªã„
        - åŒ»ç™‚ãƒ»æ³•å¾‹ãƒ»é‡‘èã«é–¢ã™ã‚‹å°‚é–€çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¯æä¾›ã—ãªã„
        - ä¸ç¢ºå®Ÿãªæƒ…å ±ã¯ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã‚‹
        """
        return base_instruction + safety_rules

agent = Agent(
    name="safe_agent",
    model="gemini-2.0-flash",
    instruction=SafetyInstructionProvider()
)
```

### 4. å‡ºåŠ›ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

```python
import re

SENSITIVE_PATTERNS = [
    r'\b\d{3}-\d{2}-\d{4}\b',  # SSN
    r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b',  # ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰
]

def output_filter_callback(
    context: CallbackContext,
    response: GenerateContentResponse
) -> Optional[GenerateContentResponse]:
    original_text = response.candidates[0].content.parts[0].text

    for pattern in SENSITIVE_PATTERNS:
        if re.search(pattern, original_text):
            return GenerateContentResponse(
                candidates=[Candidate(
                    content=Content(parts=[Part.from_text(
                        "ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚ŒãŸãŸã‚ã€å‡ºåŠ›ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚"
                    )])
                )]
            )

    return None

agent = Agent(
    name="filtered_agent",
    model="gemini-2.0-flash",
    after_model_callback=output_filter_callback
)
```

---

## PIIãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

### æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³

```python
import re
from typing import Dict, Pattern

PII_PATTERNS: Dict[str, Pattern] = {
    "email": re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'),
    "phone": re.compile(r'\b(?:\+?1[-.]?)?\(?\d{3}\)?[-.]?\d{3}[-.]?\d{4}\b'),
    "ssn": re.compile(r'\b\d{3}-\d{2}-\d{4}\b'),
    "credit_card": re.compile(r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b'),
    "ip_address": re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b'),
}

def redact_pii(text: str) -> str:
    """PIIã‚’æ¤œå‡ºã—ã¦ãƒã‚¹ã‚­ãƒ³ã‚°ã™ã‚‹"""
    redacted = text

    for pii_type, pattern in PII_PATTERNS.items():
        matches = pattern.finditer(redacted)
        for match in matches:
            original = match.group()
            # ã‚¿ã‚¤ãƒ—ã”ã¨ã«ç•°ãªã‚‹ãƒã‚¹ã‚­ãƒ³ã‚°å½¢å¼
            if pii_type == "email":
                masked = f"[EMAIL-REDACTED]"
            elif pii_type == "phone":
                masked = f"[PHONE-REDACTED]"
            elif pii_type == "ssn":
                masked = f"[SSN-REDACTED]"
            elif pii_type == "credit_card":
                masked = f"[CC-REDACTED]"
            elif pii_type == "ip_address":
                masked = f"[IP-REDACTED]"
            else:
                masked = f"[REDACTED]"

            redacted = redacted.replace(original, masked)

    return redacted
```

### after_model_callbackã§ã®å®Ÿè£…

```python
def pii_filter_callback(
    context: CallbackContext,
    response: GenerateContentResponse
) -> Optional[GenerateContentResponse]:
    """LLMå‡ºåŠ›ã‹ã‚‰PIIã‚’å‰Šé™¤"""
    original_text = response.candidates[0].content.parts[0].text
    filtered_text = redact_pii(original_text)

    # PIIãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ã¿ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç½®æ›
    if filtered_text != original_text:
        # ãƒ­ã‚°è¨˜éŒ²
        log_pii_detection(context.metadata.get("session_id"), original_text)

        return GenerateContentResponse(
            candidates=[Candidate(
                content=Content(parts=[Part.from_text(filtered_text)])
            )]
        )

    return None

agent = Agent(
    name="pii_safe_agent",
    model="gemini-2.0-flash",
    instruction="ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’æ‰±ã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
    after_model_callback=pii_filter_callback
)
```

### æ¤œè¨¼ã¨ãƒ†ã‚¹ãƒˆ

```python
def test_pii_redaction():
    test_cases = [
        ("ç§ã®ãƒ¡ãƒ¼ãƒ«ã¯john@example.comã§ã™", "ç§ã®ãƒ¡ãƒ¼ãƒ«ã¯[EMAIL-REDACTED]ã§ã™"),
        ("é›»è©±ç•ªå·ã¯555-123-4567ã§ã™", "é›»è©±ç•ªå·ã¯[PHONE-REDACTED]ã§ã™"),
        ("SSNã¯123-45-6789ã§ã™", "SSNã¯[SSN-REDACTED]ã§ã™"),
        ("ã‚«ãƒ¼ãƒ‰ç•ªå·: 1234 5678 9012 3456", "ã‚«ãƒ¼ãƒ‰ç•ªå·: [CC-REDACTED]"),
    ]

    for original, expected in test_cases:
        result = redact_pii(original)
        assert result == expected, f"Failed: {original} -> {result} (expected {expected})"

    print("âœ… ã™ã¹ã¦ã®PIIãƒ†ã‚¹ãƒˆãŒæˆåŠŸ")

test_pii_redaction()
```

---

## SSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°

### RunConfigè¨­å®š

```python
from google.adk.agents import RunConfig
from google.adk.agents.streaming_mode import StreamingMode

# SSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–
run_config = RunConfig(streaming_mode=StreamingMode.SSE)

# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ
for event in runner.run(query="æ±äº¬ã®å¤©æ°—ã¯ï¼Ÿ", run_config=run_config):
    if event.content and event.content.parts:
        chunk = event.content.parts[0].text
        print(chunk, end="", flush=True)
```

### Pythonã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³

#### 1. ãƒ¬ã‚¹ãƒãƒ³ã‚¹é›†ç´„ã—ãªãŒã‚‰è¡¨ç¤º

```python
def stream_with_aggregation(query: str, agent: Agent):
    """ãƒãƒ£ãƒ³ã‚¯ã‚’é›†ç´„ã—ãªãŒã‚‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°"""
    run_config = RunConfig(streaming_mode=StreamingMode.SSE)

    full_response = ""
    for event in runner.run(query, agent=agent, run_config=run_config):
        if event.content and event.content.parts:
            chunk = event.content.parts[0].text
            full_response += chunk
            print(chunk, end="", flush=True)

    print()  # æ”¹è¡Œ
    return full_response
```

#### 2. ãƒãƒ«ãƒå‡ºåŠ›å…ˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

```python
from typing import Callable, List

def stream_to_multiple_outputs(
    query: str,
    agent: Agent,
    outputs: List[Callable[[str], None]]
):
    """è¤‡æ•°ã®å‡ºåŠ›å…ˆã«åŒæ™‚é…ä¿¡"""
    run_config = RunConfig(streaming_mode=StreamingMode.SSE)

    for event in runner.run(query, agent=agent, run_config=run_config):
        if event.content and event.content.parts:
            chunk = event.content.parts[0].text
            for output_fn in outputs:
                output_fn(chunk)

# ä½¿ç”¨ä¾‹
def console_output(chunk: str):
    print(chunk, end="", flush=True)

def file_output(chunk: str):
    with open("stream_log.txt", "a") as f:
        f.write(chunk)

stream_to_multiple_outputs(
    "AIã®æœªæ¥ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„",
    agent,
    [console_output, file_output]
)
```

#### 3. ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼

```python
import sys

def stream_with_progress(query: str, agent: Agent):
    """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºä»˜ãã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°"""
    run_config = RunConfig(streaming_mode=StreamingMode.SSE)

    spinner = ['â ‹', 'â ™', 'â ¹', 'â ¸', 'â ¼', 'â ´', 'â ¦', 'â §', 'â ‡', 'â ']
    idx = 0

    print("ç”Ÿæˆä¸­: ", end="")
    for event in runner.run(query, agent=agent, run_config=run_config):
        if event.content and event.content.parts:
            chunk = event.content.parts[0].text
            sys.stdout.write(f"\rç”Ÿæˆä¸­: {spinner[idx % len(spinner)]} ")
            sys.stdout.flush()
            idx += 1
            # å®Ÿéš›ã®ãƒãƒ£ãƒ³ã‚¯ã¯ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°

    print("\râœ… ç”Ÿæˆå®Œäº†")
```

### FastAPI SSEã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import json
import asyncio

app = FastAPI()

async def generate_stream(query: str, agent: Agent):
    """éåŒæœŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    run_config = RunConfig(streaming_mode=StreamingMode.SSE)

    try:
        async for event in runner.run_async(query, agent=agent, run_config=run_config):
            if event.content and event.content.parts:
                chunk = event.content.parts[0].text
                # SSEå½¢å¼ã§é€ä¿¡
                yield f"data: {json.dumps({'text': chunk})}\n\n"
                await asyncio.sleep(0)  # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã«åˆ¶å¾¡ã‚’è¿”ã™

        # ã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†ãƒãƒ¼ã‚«ãƒ¼
        yield "data: [DONE]\n\n"

    except Exception as e:
        yield f"data: {json.dumps({'error': str(e)})}\n\n"

@app.post("/stream")
async def stream_endpoint(query: str):
    return StreamingResponse(
        generate_stream(query, agent),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Nginxç”¨
        }
    )
```

### JavaScript EventSource ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰

```javascript
// SSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¶ˆè²»
function streamQuery(query) {
    const eventSource = new EventSource(`/stream?query=${encodeURIComponent(query)}`);

    eventSource.onmessage = (event) => {
        if (event.data === '[DONE]') {
            eventSource.close();
            console.log('âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒ å®Œäº†');
            return;
        }

        const data = JSON.parse(event.data);
        if (data.error) {
            console.error('ã‚¨ãƒ©ãƒ¼:', data.error);
            eventSource.close();
            return;
        }

        // ãƒãƒ£ãƒ³ã‚¯ã‚’è¡¨ç¤º
        document.getElementById('response').textContent += data.text;
    };

    eventSource.onerror = (error) => {
        console.error('SSEã‚¨ãƒ©ãƒ¼:', error);
        eventSource.close();
    };
}

// ä½¿ç”¨ä¾‹
document.getElementById('submit').addEventListener('click', () => {
    const query = document.getElementById('query').value;
    document.getElementById('response').textContent = '';
    streamQuery(query);
});
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
import asyncio
from datetime import datetime, timedelta

async def resilient_stream(query: str, agent: Agent, timeout: int = 30):
    """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°"""
    run_config = RunConfig(streaming_mode=StreamingMode.SSE)

    start_time = datetime.now()
    retry_count = 0
    max_retries = 3

    while retry_count < max_retries:
        try:
            async for event in runner.run_async(query, agent=agent, run_config=run_config):
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
                if (datetime.now() - start_time).seconds > timeout:
                    raise TimeoutError("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")

                if event.content and event.content.parts:
                    chunk = event.content.parts[0].text
                    yield chunk

            break  # æˆåŠŸ

        except Exception as e:
            retry_count += 1
            if retry_count >= max_retries:
                yield f"\nâŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"
                break

            # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
            wait_time = 2 ** retry_count
            yield f"\nâš ï¸ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤...\n"
            await asyncio.sleep(wait_time)
```

### ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ãƒªã‚«ãƒãƒª

```python
from typing import Dict
import uuid

class StreamSession:
    def __init__(self, query: str, agent: Agent):
        self.session_id = str(uuid.uuid4())
        self.query = query
        self.agent = agent
        self.chunks: List[str] = []
        self.completed = False

    async def resume(self, from_chunk: int = 0):
        """ä¸­æ–­ã—ãŸã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å†é–‹"""
        run_config = RunConfig(streaming_mode=StreamingMode.SSE)

        # æ—¢ã«å–å¾—æ¸ˆã¿ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é€ä¿¡
        for chunk in self.chunks[from_chunk:]:
            yield chunk

        # ç¶šãã‚’å–å¾—
        if not self.completed:
            async for event in runner.run_async(
                self.query,
                agent=self.agent,
                run_config=run_config
            ):
                if event.content and event.content.parts:
                    chunk = event.content.parts[0].text
                    self.chunks.append(chunk)
                    yield chunk

            self.completed = True

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
sessions: Dict[str, StreamSession] = {}

@app.post("/stream/start")
async def start_stream(query: str):
    session = StreamSession(query, agent)
    sessions[session.session_id] = session

    return StreamingResponse(
        session.resume(),
        media_type="text/event-stream"
    )

@app.post("/stream/resume/{session_id}")
async def resume_stream(session_id: str, from_chunk: int = 0):
    if session_id not in sessions:
        return {"error": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

    session = sessions[session_id]
    return StreamingResponse(
        session.resume(from_chunk),
        media_type="text/event-stream"
    )
```

---

## Live API éŸ³å£°å‡¦ç†

### LiveRequestQueue

```python
from google.adk.agents import LiveRequestQueue
import pyaudio
import wave

# PCMéŸ³å£°ã‚­ãƒ¥ãƒ¼ã‚’ä½œæˆ
queue = LiveRequestQueue()

# éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ è¨­å®š
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000

p = pyaudio.PyAudio()
stream = p.open(
    format=FORMAT,
    channels=CHANNELS,
    rate=RATE,
    input=True,
    frames_per_buffer=CHUNK
)

print("ğŸ¤ éŒ²éŸ³é–‹å§‹...")

# PCMéŸ³å£°ã‚’ã‚­ãƒ¥ãƒ¼ã«é€ä¿¡
for _ in range(0, int(RATE / CHUNK * 5)):  # 5ç§’é–“
    data = stream.read(CHUNK)
    queue.put(data)

queue.close()
stream.stop_stream()
stream.close()
p.terminate()
```

### åŒæ–¹å‘ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° vs ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹

| ç‰¹æ€§ | åŒæ–¹å‘ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° | ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ |
|------|---------------------|-------------|
| **é€šä¿¡** | ç¶™ç¶šçš„ãªåŒæ–¹å‘æ¥ç¶š | ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ |
| **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | ä½ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰ | é«˜ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰ |
| **ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹** | éŸ³å£°é€šè©±ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­—å¹• | éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ–‡å­—èµ·ã“ã—ã€ä¸€æ‹¬å‡¦ç† |
| **æ¥ç¶š** | WebSocket | HTTP |
| **è¤‡é›‘æ€§** | é«˜ï¼ˆçŠ¶æ…‹ç®¡ç†å¿…è¦ï¼‰ | ä½ï¼ˆã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ï¼‰ |

```python
# åŒæ–¹å‘ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¾‹
async def bidirectional_stream(agent: Agent):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¯¾è©±"""
    queue = LiveRequestQueue()

    # é€ä¿¡ã‚¿ã‚¹ã‚¯
    async def send_audio():
        stream = pyaudio.PyAudio().open(format=pyaudio.paInt16,
                                        channels=1, rate=16000, input=True)
        while True:
            data = stream.read(1024)
            queue.put(data)

    # å—ä¿¡ã‚¿ã‚¹ã‚¯
    async def receive_response():
        async for response in runner.live_async(queue, agent=agent):
            if response.audio:
                play_audio(response.audio)

    # ä¸¦è¡Œå®Ÿè¡Œ
    await asyncio.gather(send_audio(), receive_response())

# ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ä¾‹
def turn_based_transcription(audio_file: str, agent: Agent):
    """éŒ²éŸ³æ¸ˆã¿éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
    with open(audio_file, 'rb') as f:
        audio_data = f.read()

    response = runner.run(audio_data, agent=agent)
    return response.text
```

### 5ã¤ã®ãƒ—ãƒªãƒ“ãƒ«ãƒˆãƒœã‚¤ã‚¹

```python
from google.genai import SpeechConfig

# åˆ©ç”¨å¯èƒ½ãªãƒœã‚¤ã‚¹
VOICES = {
    "Puck": "æ˜ã‚‹ãå…ƒæ°—ãªå£°",
    "Charon": "è½ã¡ç€ã„ãŸä½éŸ³",
    "Kore": "ä¸­æ€§çš„ã§ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«",
    "Fenrir": "åŠ›å¼·ãæ¨©å¨çš„",
    "Aoede": "æŸ”ã‚‰ã‹ãæ¸©ã‹ã„"
}

# éŸ³å£°è¨­å®š
speech_config = SpeechConfig(
    voice_config={"voice_name": "Puck"}  # ã¾ãŸã¯ Charon, Kore, Fenrir, Aoede
)

agent = Agent(
    name="voice_agent",
    model="gemini-2.0-flash-live-preview-04-09",
    instruction="éŸ³å£°ã§å¯¾è©±ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
    speech_config=speech_config
)
```

### ãƒ¢ãƒ‡ãƒ«è¦ä»¶

| ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  | ãƒ¢ãƒ‡ãƒ« | èª¬æ˜ |
|----------------|--------|------|
| **Vertex AI** | `gemini-2.0-flash-live-preview-04-09` | ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆ |
| **AI Studio** | `gemini-live-2.5-flash-preview` | ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆ |

```python
# Vertex AI
agent = Agent(
    name="live_vertex",
    model="gemini-2.0-flash-live-preview-04-09",
    instruction="Vertex AIã§ãƒ©ã‚¤ãƒ–å¯¾è©±"
)

# AI Studio
agent = Agent(
    name="live_ai_studio",
    model="gemini-live-2.5-flash-preview",
    instruction="AI Studioã§ãƒ©ã‚¤ãƒ–å¯¾è©±"
)
```

### å˜ä¸€ãƒ¢ãƒ€ãƒªãƒ†ã‚£åˆ¶ç´„

**é‡è¦**: Live APIã¯å˜ä¸€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®ã¿ã‚µãƒãƒ¼ãƒˆï¼ˆtextã‹audioã®ä¸€æ–¹ã®ã¿ï¼‰ã€‚

```python
# âŒ ä¸æ­£: ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ã‚’æ··åœ¨
agent = Agent(
    model="gemini-2.0-flash-live-preview-04-09",
    instruction="ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°",
    response_modalities=["text", "audio"]  # ã‚¨ãƒ©ãƒ¼
)

# âœ… æ­£: éŸ³å£°ã®ã¿
audio_agent = Agent(
    model="gemini-2.0-flash-live-preview-04-09",
    instruction="éŸ³å£°ã®ã¿",
    response_modalities=["audio"]
)

# âœ… æ­£: ãƒ†ã‚­ã‚¹ãƒˆã®ã¿
text_agent = Agent(
    model="gemini-2.0-flash-live-preview-04-09",
    instruction="ãƒ†ã‚­ã‚¹ãƒˆã®ã¿",
    response_modalities=["text"]
)
```

### max_output_tokensã®æ¨å¥¨è¨­å®š

```python
from google.genai import GenerateContentConfig

# éŸ³å£°å‡ºåŠ›ã®å ´åˆã¯150-200ãƒˆãƒ¼ã‚¯ãƒ³æ¨å¥¨
generate_config = GenerateContentConfig(
    max_output_tokens=150,  # éŸ³å£°å‡ºåŠ›ã«ã¯çŸ­ã‚ã«è¨­å®š
    temperature=0.7
)

agent = Agent(
    model="gemini-2.0-flash-live-preview-04-09",
    instruction="ç°¡æ½”ã«ç­”ãˆã‚‹éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
    response_modalities=["audio"],
    generate_content_config=generate_config
)
```

### å®Œå…¨ãªéŸ³å£°å¯¾è©±ä¾‹

```python
import asyncio
import pyaudio
from google.adk.agents import Agent, LiveRequestQueue, Runner

async def voice_conversation():
    """ãƒ•ãƒ«ãƒ‡ãƒ¥ãƒ—ãƒ¬ãƒƒã‚¯ã‚¹éŸ³å£°å¯¾è©±"""

    # Agentè¨­å®š
    agent = Agent(
        name="voice_assistant",
        model="gemini-2.0-flash-live-preview-04-09",
        instruction="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨éŸ³å£°ã§è‡ªç„¶ã«å¯¾è©±ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
        response_modalities=["audio"],
        speech_config=SpeechConfig(
            voice_config={"voice_name": "Kore"}
        ),
        generate_content_config=GenerateContentConfig(
            max_output_tokens=180,
            temperature=0.8
        )
    )

    queue = LiveRequestQueue()
    runner = Runner()

    # éŸ³å£°å…¥åŠ›è¨­å®š
    p = pyaudio.PyAudio()
    input_stream = p.open(
        format=pyaudio.paInt16,
        channels=1,
        rate=16000,
        input=True,
        frames_per_buffer=1024
    )

    # éŸ³å£°å‡ºåŠ›è¨­å®š
    output_stream = p.open(
        format=pyaudio.paInt16,
        channels=1,
        rate=24000,  # å‡ºåŠ›ã¯24kHz
        output=True
    )

    print("ğŸ¤ éŸ³å£°å¯¾è©±é–‹å§‹ï¼ˆCtrl+Cã§çµ‚äº†ï¼‰")

    async def send_audio():
        """ãƒã‚¤ã‚¯ã‹ã‚‰PCMéŸ³å£°ã‚’é€ä¿¡"""
        try:
            while True:
                data = input_stream.read(1024, exception_on_overflow=False)
                queue.put(data)
                await asyncio.sleep(0)
        except KeyboardInterrupt:
            queue.close()

    async def receive_audio():
        """éŸ³å£°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¦å†ç”Ÿ"""
        try:
            async for response in runner.live_async(queue, agent=agent):
                if response.audio_data:
                    output_stream.write(response.audio_data)
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

    # é€å—ä¿¡ã‚’ä¸¦è¡Œå®Ÿè¡Œ
    try:
        await asyncio.gather(send_audio(), receive_audio())
    finally:
        input_stream.stop_stream()
        input_stream.close()
        output_stream.stop_stream()
        output_stream.close()
        p.terminate()
        print("\nâœ… éŸ³å£°å¯¾è©±çµ‚äº†")

# å®Ÿè¡Œ
if __name__ == "__main__":
    asyncio.run(voice_conversation())
```

### ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

1. **éŸ³å£°å“è³ª**
   - å…¥åŠ›: PCM 16kHz ãƒ¢ãƒãƒ©ãƒ«
   - ãƒã‚¤ã‚ºãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ¨å¥¨
   - ãƒã‚¤ã‚¯å“è³ªãŒé‡è¦

2. **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æœ€é©åŒ–**
   - å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆ512-1024ãƒã‚¤ãƒˆï¼‰
   - ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã‚’æœ€å°åŒ–
   - `max_output_tokens`ã‚’150-200ã«åˆ¶é™

3. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**
   - æ¥ç¶šåˆ‡æ–­æ™‚ã®å†æ¥ç¶šãƒ­ã‚¸ãƒƒã‚¯
   - éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ã‚¨ãƒ©ãƒ¼ã®ã‚­ãƒ£ãƒƒãƒ
   - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ30-60ç§’ï¼‰

4. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“**
   - ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼è¡¨ç¤º
   - è©±ã—ã¦ã„ã‚‹ã¨ãã®è¦–è¦šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
   - éŸ³å£°ãƒŸãƒ¥ãƒ¼ãƒˆ/ã‚¢ãƒ³ãƒŸãƒ¥ãƒ¼ãƒˆæ©Ÿèƒ½
