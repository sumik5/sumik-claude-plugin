# A/Bテストの統計学

## 1. 統計的仮説検定の基礎

### 帰無仮説（H0）と対立仮説（H1）

A/Bテストの統計的分析は仮説検定（NHST: Null Hypothesis Significance Testing）のフレームワークに基づく。

- **帰無仮説（H0）**: コントロール群と介入群のメトリクスに差がない
- **対立仮説（H1）**: コントロール群と介入群のメトリクスに差がある

検定は「差がない」という仮定から出発し、データがこの仮定を十分に反証した場合にのみ、帰無仮説を棄却する。

### 2種類の誤り

仮説検定では2種類の判断ミスが発生し得る。

| 誤りの種類 | 別名 | 内容 | 確率記号 |
|-----------|------|------|---------|
| **第一種の誤り** | 偽陽性（Type I error） | 実際には効果がないのに「効果がある」と判定 | α |
| **第二種の誤り** | 偽陰性（Type II error） | 実際には効果があるのに「効果がない」と判定 | β |

この2つの誤りにはトレードオフがある。偽陽性を減らそうとして判定基準を厳しくすると、偽陰性（見逃し）が増える。逆に偽陰性を減らそうとすると偽陽性が増える。

### 有意水準（α = 0.05）の意味

有意水準とは、偽陽性を許容する上限確率を指す。

- 科学分野では慣習的に **α = 0.05**（5%）が用いられる
- この値は「本当に効果がない場合に、100回実験すると約5回は誤って有意と判定する」ことを意味する
- α = 0.01 を使用する場合はより保守的な判定となり、サンプルサイズを増やす必要がある
- 0.05が高すぎるという議論も存在し、0.005への引き下げを提案する研究者もいる

### 片側検定と両側検定

- **両側検定**: 介入が良くも悪くもなり得る場合に使用。A/Bテストではほとんどの場合こちらが適切
- **片側検定**: 介入が一方向にのみ影響する確信がある場合に使用。使用は慎重に

A/Bテストでは、予期しない悪影響を検出するためにも両側検定を標準とすべきである。

---

## 2. p値の正しい理解

### 定義

**p値**: 帰無仮説が真であると仮定したとき、観測データ以上に極端な結果が得られる確率。

p値が低いほど、コントロール群と介入群に差がないとする仮説との矛盾が大きい。慣習的に p < 0.05 で「統計的に有意」、p < 0.01 で「非常に有意」とみなす。

### p値への4つの誤解

| # | 誤解 | 正しい理解 |
|---|------|----------|
| 1 | p = 0.05 は帰無仮説が真である確率が5% | p値は帰無仮説が真であると **仮定して** 計算される値であり、帰無仮説の真偽の確率ではない |
| 2 | 有意でない（p >= 0.05）= 差がない | 有意でないのは検出力が不足している（サンプルサイズが足りない）可能性がある |
| 3 | p = 0.05 は5%しか起こらないデータが観測された | p値の定義上、5%には今回の観測データ以上に極端なデータも含まれる |
| 4 | p = 0.05 で棄却したら偽陽性率は5% | 偽陽性率の計算にはベイズの定理と事前確率が必要。帰無仮説が必ず真なら偽陽性率は100%になり得る |

### p値が示さないこと

p値は効果の大きさ（effect size）を示さない。統計的に有意な結果が必ずしもビジネス上意味のある結果とは限らない。

- 大規模なトラフィックがあるWebサイトでは0.01%の変化でも統計的に有意になり得る
- その変化がビジネスとして意味を持つかは別の判断（実用的有意差）が必要

### 統計的有意差 vs 実用的有意差

| 概念 | 定義 | 判断基準 |
|------|------|---------|
| **統計的有意差** | 差がゼロでない可能性が高い | p値が有意水準を下回る |
| **実用的有意差** | ビジネス的に意味のある大きさの差 | 事前に定義した閾値を超える |

**結果パターンと判断の対応**:

| パターン | 判断 |
|---------|------|
| 統計的にも実用的にも有意 | ローンチを検討 |
| 統計的に有意だが実用的に有意でない | 変化が小さすぎてローンチの価値が低い |
| 実用的に有意に見えるが統計的に有意でない | 検出力不足の可能性。より大きなサンプルで再実験 |
| 統計的にも実用的にも有意でない | 効果なしと判断、断念または方針転換 |

実験開始前に実用的有意差の閾値を設定しておくことで、結果解釈時のバイアスを防ぐ。

---

## 3. 信頼区間

### 定義と解釈

**95%信頼区間**: 繰り返し実験を行ったとき、計算された信頼区間が真の介入効果を含む割合が95%になる区間。

**よくある誤解**: 「提示された95%信頼区間が95%の確率で真の値を含む」という解釈は正しくない。特定の信頼区間に真の値が含まれる確率は100%か0%のどちらか。95%は、区間の構成方法に関する頻度論的な確率を指す。

### 信頼区間とp値の関係

95%信頼区間がゼロを含まない場合、p < 0.05 で統計的に有意と等価になる。

### 信頼区間を用いた意思決定

| 信頼区間の状態 | 解釈 |
|--------------|------|
| ゼロを含まず、実用閾値の外 | 統計的にも実用的にも有意 -- ローンチ検討 |
| ゼロを含まず、実用閾値の内 | 統計的に有意だが実用的価値が低い |
| ゼロを含み、幅が狭い | 効果なしと結論づけられる |
| ゼロを含み、幅が広い | 検出力不足 -- より大きなサンプルで再実験 |

### コントロール群と介入群の信頼区間の重なり

コントロール群と介入群の信頼区間を別々に計算し、それらの重なりで有意性を判断するのは不正確。統計的に有意な差がある場合でも、信頼区間は最大29%程度重なることがある。差の信頼区間を直接計算すべきである。

---

## 4. t検定とカイ二乗検定

### 連続量メトリクスにはt検定

**2標本t検定**は最も一般的な統計的仮説検定であり、コントロール群と介入群の平均値の差が統計的に有意かどうかを判定する。

**適用対象**: 平均セッション時間、ユーザーあたりの収益、ページ滞在時間など連続量メトリクス

**t統計量**は平均値の差を各実験群の分散の和で正規化した値であり、この値が大きいほど帰無仮説を棄却する可能性が高くなる。

**正規性の仮定について**:
- t検定では、メトリクスそのものが正規分布に従う必要はない
- 中心極限定理により、サンプルサイズが十分に大きければメトリクスの平均値が正規分布に近づく
- 経験則として、正規性を仮定するのに必要なサンプルサイズは歪度（skewness）の2乗の約355倍
- 収益メトリクスのように歪度が大きい場合、値に上限を設ける（capping）ことで歪度を下げ、必要サンプルサイズを削減できる

### 比率メトリクスにはカイ二乗検定

**適用対象**: コンバージョン率、クリック率（CTR）、離脱率など比率メトリクス

カイ二乗検定は、観測された比率の分布が期待される分布と異なるかどうかを評価する。2群間の比率比較にはカイ二乗検定の特殊ケースとして2標本比率のz検定も使用される。

### 検定の前提条件と適用条件

**t検定の前提条件**:
- 2群の観測値が独立であること
- サンプルサイズが十分に大きいこと（中心極限定理の適用のため）
- 極端な外れ値がないこと（外れ値はキャッピングで対処）

**正規性の仮定を満たすか疑わしい場合の対処**:
1. コントロール群と介入群のデータをランダムに混合して帰無分布を生成する
2. Kolmogorov-SmirnovやAnderson-Darling検定で正規性を確認する
3. 正規性が成立しない場合はパーミュテーション検定を使用する（計算コストは高いが、サンプルサイズが小さい場合に有効）

### 検定選択の指針

| メトリクスの性質 | 推奨検定 | 例 |
|----------------|---------|-----|
| 連続量の平均値 | 2標本t検定 | ユーザーあたり収益、セッション時間 |
| 比率（2値結果の割合） | カイ二乗検定 / z検定 | コンバージョン率、CTR |
| 分布が高歪度 | t検定 + キャッピング | 収益メトリクス |
| サンプルサイズが極端に小さい | パーミュテーション検定 | 特殊な実験条件 |

---

## 5. サンプルサイズの計算

### 最小検出可能効果（MDE）

**MDE（Minimum Detectable Effect）**: 実験で検出したい最小の差分。ビジネス的に意味のある最小の変化量として事前に定義する。

- 数十億ドル規模の収益があるサービスでは0.2%の変化でも実用的に重要
- スタートアップでは10%以上の改善を探し、2%の変化は小さすぎる場合もある

MDEの選択は実験のサンプルサイズと期間に直結する。MDEが小さいほど多くのサンプルが必要になる。

### 検出力（Power = 1 - β）

**検出力**: 実験群間に真の差があるときに、それを検出できる確率。

- 業界標準では **80%以上**（β = 0.20 以下）が推奨される
- より高い検出力（90%）を求める場合はサンプルサイズを増やす必要がある

### サンプルサイズの算出

コントロール群と介入群が同じサイズの場合、80%の検出力を達成するために各群に必要なサンプルサイズの近似式:

```
n ≈ 16 * sigma^2 / delta^2
```

- `sigma^2`: メトリクスの標本分散
- `delta`: 検出したい最小の差（MDE）

### サンプルサイズを減らす方法

1. **より感度の高いメトリクスを使う**: 分散が小さいメトリクスに変更する（例: 「ユーザーあたり収益」の代わりに「購入したかどうか」の2値指標）
2. **MDEの閾値を上げる**: 大きな変化だけを検出対象にする
3. **外れ値をキャッピングする**: メトリクスに上限値を設けて分散を抑える
4. **トリガー分析**: 実験の影響を受けるユーザーのみに分析対象を絞る

### 実験期間とトラフィック量の関係

- オンライン実験ではユーザーが時間の経過とともに流入するため、実験期間が長いほどサンプルサイズが増える
- ただしリピートユーザーが存在するため、ユーザー蓄積は線形より遅い
- 曜日効果を考慮し、最低1週間の実行を推奨
- 季節性（祝日等）の影響も考慮が必要

### 実験期間の決定に影響する要因

| 要因 | 考慮事項 |
|------|---------|
| **曜日効果** | 平日と週末でユーザー行動が異なる。最低1週間の実行で週のサイクルを捕捉する |
| **季節性** | 祝日、イベント、セール期間などがメトリクスに影響。グローバルサービスでは各国の祝日を考慮 |
| **プライマシー効果** | ユーザーが古い機能に慣れているため新機能の採用に時間がかかる。効果安定まで延長が必要 |
| **ノベルティ効果** | 新機能への好奇心で一時的に利用が増えるが、時間とともに効果が消える |
| **実験安全性** | 大きな変更では小割合から開始し、段階的に拡大する |
| **メトリクスの分散成長** | セッション数など蓄積型メトリクスは時間とともに分散が増大し、期間延長の効果が減衰する |

### 複数介入群がある場合

介入群が3つ以上ある場合（A/B/nテスト）、コントロール群のサイズを介入群より大きくすることで全体の検出力を最適化できる。各介入群は独立にコントロール群と比較されるため、コントロール群を大きくすることが各比較の検出力を向上させる。

---

## 6. 検出力分析（Power Analysis）

### Under-powered実験のリスク

検出力が不足した実験には以下のリスクがある。

- **見逃し率の増加**: 真の効果があるのに「効果なし」と誤って結論づける
- **符号（方向）の誤り（Type S error）**: 効果の方向を逆に結論づける確率が上がる
- **大きさの過大評価（Type M error）**: たまたま有意になった結果は、効果の大きさが過大評価される傾向がある
- **再現性の低下**: Under-poweredな実験結果は再実験で再現されにくい

ある調査では、多くの公開されたA/Bテストがほとんどの場合で検出力不足であることが示されている。

### 事前の検出力計算の重要性

実験を開始する前に検出力分析を行い、必要なサンプルサイズを確定させることが必須。

実務上のプロセス:
1. MDEを決定する（ビジネス上意味のある最小の変化量）
2. メトリクスの分散を過去データから推定する
3. サンプルサイズを算出する
4. 日次トラフィックから実験期間を見積もる
5. 実験期間が現実的でなければ、MDEの見直しまたはメトリクスの変更を検討する

---

## 7. 多重比較補正

### 多重仮説検定問題（Multiple Testing Problem）

複数の検定を同時に行うと、偽陽性が増加する。100個のメトリクスを5%有意水準で検定すると、すべてが実際には差がなくても、約5個が偽陽性として有意になり得る。

**多重比較が発生する場面**:
1. 複数のメトリクスを同時に確認する
2. p値を継続的にモニタリングする（ピーキング）
3. ユーザーをセグメント別に分析する（国、ブラウザ、新規/既存など）
4. 同じ実験を繰り返し実施する

### Bonferroni補正

最も単純で保守的な補正方法。

**方法**: 有意水準αを検定回数kで割る

```
補正後の有意水準 = α / k
```

例: 20個のメトリクスを検定する場合、各メトリクスの有意水準は 0.05 / 20 = 0.0025

**利点**: シンプルで一貫性がある
**欠点**: 検定回数が多いとしきい値が極端に小さくなり、真の効果も見逃しやすくなる（保守的すぎる）

### False Discovery Rate（FDR）

Bonferroni補正の保守性を緩和するアプローチ。

**FDR（偽発見率）**: 有意と判定した結果のうち、実際には偽陽性であるものの期待割合を制御する。

**Benjamini-Hochberg法**:
- 各検定のp値を昇順に並べ、検定ごとに異なるしきい値を適用する
- Bonferroni補正よりも多くの真の効果を検出可能

### 実務的な3グループアプローチ

大量のメトリクスを扱う場合の実用的な経験則:

1. **グループ1**: 実験の影響を受けると予想されるメトリクス -- α = 0.05
2. **グループ2**: 影響を受ける可能性のあるメトリクス -- α = 0.01
3. **グループ3**: 影響を受けそうにないメトリクス -- α = 0.001

この段階的な有意水準は、帰無仮説が真であることの事前確信度に基づくベイズ的解釈を持つ。

---

## 8. p値のピーキングと連続的モニタリング

### 実験中にp値を繰り返しチェックする危険性

オンライン実験ではデータがリアルタイムに蓄積されるため、実験中にp値を繰り返しチェックしたくなる。しかしこの行為は偽陽性率を5-10倍に増加させる。

**メカニズム**: 実験期間中にp値を何度も確認し、有意になった時点で実験を停止すると、ランダムな変動を真の効果と誤認する確率が跳ね上がる。

### 対処方法

**方法1: 固定期間法**
- 事前に決めた期間（例: 1週間）が経過するまでp値を判定に使用しない
- Google、LinkedIn、Microsoftの実験プラットフォームはこの方法を採用

**方法2: 逐次検定（Sequential Testing）**
- 実験中の連続的なモニタリングを前提とした統計手法を使用する
- Always Valid p-valuesなど、ピーキングを許容するフレームワークが存在する
- Optimizelyなど一部のプラットフォームがこの方法を実装

### どちらを選ぶか

| 方法 | 利点 | 欠点 |
|------|------|------|
| 固定期間法 | シンプル、理解しやすい | 悪い実験の早期停止が難しい |
| 逐次検定 | 早期停止が可能、柔軟 | 統計的フレームワークが複雑 |

### ピーキングと早期停止の使い分け

**安全指標のモニタリング**はピーキングとは異なる。ユーザーに深刻な悪影響を与えるクラッシュ率やエラー率など、ガードレールメトリクスのリアルタイム監視は推奨される。この場合は統計的有意性の判定ではなく、異常値の検出として扱う。

**ベイジアンアプローチ**: 頻度論的なp値の代わりにベイズファクターや事後確率を使用することで、ピーキング問題を回避する手法も存在する。データが蓄積されるたびに信念を更新する枠組みであり、連続的モニタリングとの親和性が高い。

---

## 9. セグメント分析の注意点

### シンプソンのパラドックス

実験を段階的に拡大する（例: 最初1%、次に50%）とき、各段階では介入群が優れていても、データを単純に合計すると劣って見えることがある。

**原因**: 異なるパーセンテージで収集されたデータを単純に集計すると、各段階のサンプルサイズの違いが加重平均に偏りをもたらす。

**対策**: 異なるトラフィック配分率のデータは単純に集計せず、段階ごとに分析する。

### セグメント間のユーザー移動の罠

相互排他的な2つのセグメント（例: 機能Fを利用するユーザーと利用しないユーザー）に分けて分析する場合、介入によってユーザーがセグメント間を移動すると、各セグメントのメトリクスが改善しているのに全体では悪化するという現象が起こり得る。

**例**: 機能Fの利用ユーザーの平均セッション数が20、非利用ユーザーが10の場合、介入によって平均セッション数15のユーザーがF利用をやめると、F利用セグメントの平均は上がるが、全体のセッション数は変わらないか悪化する。

### 事前定義されたセグメントのみ分析する原則

- セグメント分析は事前に定義されたセグメント（市場・国、デバイス・OS、新規/既存ユーザーなど）に限定する
- 事後的にデータを探索してセグメントを「発見」すると、多重比較問題が発生する
- セグメントの定義は実験の影響を受けない属性に基づくべき（国、デバイス種別など）

### 事後的なセグメント探索の危険性

データを多数のセグメントに分割して「有意な差があるセグメント」を探す行為は、実質的な多重検定に等しい。20個のセグメントを検定すれば、差がなくても1つは有意になり得る。

セグメント探索は将来の仮説生成（hypothesis generation）としては有用だが、その結果を確定的な結論とするには別の実験での検証が必要。

### 有用なセグメントの例

事前定義として有用なセグメントの代表例:

- **市場・国**: 特定の国で機能しない場合、ローカライゼーションの問題を示唆する
- **デバイス・プラットフォーム**: ブラウザバージョンごとのJavaScript互換性問題の発見に有効
- **時間帯・曜日**: 効果の時間的パターンを検出。プライマシー/ノベルティ効果の確認に重要
- **ユーザー種別**: 新規ユーザーと既存ユーザーで効果が異なる場合がある
- **ヘビーユーザー/ライトユーザー**: 利用頻度によって介入の影響が異なることが多い

### フィッシャーのメタアナリシス

同じ仮説を検証する複数の独立した実験のp値を統合する手法。検出力が不足している場合に、同一実験を複数回実行してp値を統合することで、検出力を高められる。

**適用場面**:
- 驚くべき結果が得られた実験の再実験（元の実験と再実験のp値を統合）
- 分散抑制やトラフィック最適化を行っても検出力が不足する場合
- 異なる市場や期間で実行された同一実験の結果統合
