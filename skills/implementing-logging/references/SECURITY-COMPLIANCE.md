# セキュリティ・コンプライアンス詳細

## セキュリティインシデント検出

### 不審なログイン試行のパターン

| 攻撃種別 | 特徴 | 検出アプローチ |
|---------|------|--------------|
| ブルートフォース攻撃 | 同一IDに対してパスワードを変えて試行 | 同一IDへの連続失敗回数が閾値超過 |
| リバースブルートフォース | パスワードを固定してIDを変えて試行 | 同一パスワードでの複数ID失敗・同一IPからの異なるID試行 |
| パスワードリスト攻撃 | 流出パスワードリストを使い、複数IPから分散試行 | 機械学習による異常パターン検出 |
| 通常外アクセス | 深夜・海外など通常と異なる時間帯・場所からのログイン | リスクベース認証・追加認証要求 |

**ブルートフォース対策の限界と補完:**
- アカウントロック（3回失敗でロック）はブルートフォースには有効だが、リバースブルートフォースには無効
- 同一IPブロックも IP ローテーションで回避される
- 対策の組み合わせが必要: 長複雑なパスワード要件 + 2要素認証 + パスキー

### DDoS・異常アクセスの検知手法

通常の人間によるWebアクセスはリクエスト間隔が長いが、攻撃は 1 秒間に数百〜数千リクエストが発生する。

```bash
# Nginx アクセスログから1秒間のリクエスト数を集計
awk '{print $4}' /var/log/nginx/access.log \
  | cut -c2-20 \
  | sort | uniq -c | sort -rn | head -20

# 特定IPからのアクセス件数を確認
awk '{print $1}' /var/log/nginx/access.log \
  | sort | uniq -c | sort -rn | head -20
```

**対策:**
- 発信元 IP のブロック（iptables / WAF）
- 国別ブロック（日本国内向けサービスは海外 IP をブロック）
- CDN を使いトラフィックを分散（攻撃負荷を軽減）

### 自動検出の仕組み

**閾値ベースの検出:**

```
ログ出力: CPU 使用率 70% 超えたら 5% ごとに出力
通知トリガー: 90% 超えで担当者に通知
→ 同じイベントでも「記録する閾値」と「通知する閾値」を分けて設定する
```

**機械学習を活用した検出:**
- 過去の正常アクセスデータを学習させ、異常パターンを自動判別
- 利用者の行動パターン（時間帯・操作種別・データ量）を学習し、逸脱を検知
- パスワードリスト攻撃のような分散型攻撃の検出に特に有効

---

## マルウェア感染の兆候検知

### イベントログでの発見（Windows）

マルウェア感染時の典型的な兆候:
- 見慣れないプロセス・サービスが起動している
- システムファイルが変更されている
- 管理者権限を要求するダイアログが予期せず表示される

**Windows 監査ポリシーの設定（プロセス追跡）:**

```
ローカルグループポリシーエディター (gpedit.msc) で設定:
コンピューターの構成
  → Windowsの設定
    → セキュリティの設定
      → ローカルポリシー
        → 監査ポリシー
          → プロセス追跡の監査 → 「成功」「失敗」を有効化
```

設定後、イベントビューアー「Windowsログ → セキュリティ」に **イベントID 4688** でプロセス起動ログが記録される（新しいプロセス名・実行ユーザーが確認できる）。

**振る舞い検知:**
- ウイルス対策ソフトのパターンファイルで検出できないゼロデイマルウェアには「振る舞い検知」が有効
- マルウェアのパターンとは一致しなくても、類似した動作（権限昇格・外部通信・ファイル暗号化等）を不審として検知

### ネットワークログでの発見

ファイアウォール・IDS/IPS のログで以下を確認する:
- 普段使われていない外部 IP への大量通信
- 一般的には使われないポートへのアクセス
- 通信量の急増（情報の外部送信）

**iptables によるログ設定とブロック:**

```bash
# 現在のポリシーとルール確認
iptables -L

# 特定 IP からの通信をログに記録してからブロック
iptables -A INPUT -s 192.168.1.1 -j LOG --log-prefix "IPTables-Dropped: " --log-level 4
iptables -A INPUT -s 192.168.1.1 -j DROP

# 特定 IP への送信をブロック（マルウェアの外部通信を遮断）
iptables -A OUTPUT -d 192.168.1.1 -j DROP

# 設定の永続化（再起動後も有効にする）
service iptables save
```

iptables のチェイン処理の流れ:
- **INPUT**: 外部→自サーバーへの通信
- **FORWARD**: 通過する通信（ルーター用途）
- **OUTPUT**: 自サーバー→外部への通信

---

## 内部不正対策

### 監視対象の操作ログ種別

| 操作種別 | ログの内容 | 不正検知のポイント |
|---------|----------|-----------------|
| ファイルコピー・移動 | いつ・誰が・どのファイルを | 大量ファイルの短時間コピー |
| USB メモリ接続 | デバイス ID・接続日時 | 未許可デバイスの接続 |
| オンラインストレージアップロード | 転送先 URL・ファイル名・サイズ | 業務外サービスへのアップロード |
| 印刷 | 印刷者・ドキュメント名・ページ数 | 大量印刷・重要文書の印刷 |
| ファイルアクセス | アクセス者・ファイルパス・操作種別 | 権限外ファイルへのアクセス |

### 異常操作の定義

```
・通常はあまり発生しない大量コピー、短時間での大量ファイル移動
・業務時間外・休日の持ち出し操作
・許可されていない外部デバイスへの書き込み
・特定の重要ファイルへの大量アクセス・コピー
```

### Windows 監査機能の設定

**ファイル操作ログの有効化:**

```
ローカルグループポリシーエディター (gpedit.msc) で設定:
コンピューターの構成
  → Windowsの設定
    → セキュリティの設定
      → ローカルポリシー
        → 監査ポリシー
          → オブジェクトアクセスの監査 → 「成功」「失敗」を有効化
```

設定後、監視したいファイル・フォルダのプロパティ → セキュリティ → 詳細設定 → 監査タブで対象ユーザー（Everyone 等）と操作種別を指定する。

**USB 接続ログの有効化:**

```
ローカルグループポリシーエディター (gpedit.msc) で設定:
コンピューターの構成
  → Windowsの設定
    → セキュリティの設定
      → 監査ポリシーの詳細な構成
        → システム監査ポリシー
          → オブジェクトアクセス
            → リムーバブル記憶域の監査 → 「成功」「失敗」を有効化
```

> 注意: 監査ログは大量に生成されるため、必要なフォルダ・操作種別に絞って設定すること。

---

## ログ改ざん検出

### 改ざんの痕跡

ログが改ざんされると以下のような異常が生じる:

- ログファイルのタイムスタンプが不自然に変更されている
- ログの連続性・一貫性の欠如（順序の乱れ、欠番）
- ハッシュ値・デジタル署名の不一致
- ログファイルのサイズや内容の異常な変化

改ざんの目的: 不正行為の証拠を消去すること。内部犯・外部攻撃者ともに、自分の操作記録を隠蔽するためにログを書き換える動機がある。

### Tripwire によるファイル整合性監視

Tripwire はファイルのハッシュ値を記録し、定期的に比較して改ざんを検出する。

```bash
# インストール（EPEL リポジトリから）
dnf install epel-release -y
dnf install tripwire -y

# 鍵の生成（サイトキー + ローカルキー）
tripwire-setup-keyfiles
# → /etc/tripwire/site.key
# → /etc/tripwire/<ホスト名>-local.key
# → /etc/tripwire/twcfg.txt（設定ファイル）
# → /etc/tripwire/twpol.txt（ポリシーファイル）

# ポリシーカスタマイズ後に再署名
twadmin --create-polfile -S /etc/tripwire/site.key /etc/tripwire/twpol.txt

# データベース初期化（監視対象のハッシュ値を記録）
tripwire --init

# 整合性チェック（改ざんがあればレポートを /var/lib/tripwire/report/ に保存）
tripwire --check
```

運用: cron で `tripwire --check` を定期実行して自動化する。

**その他の改ざん検出手法:**

| 手法 | 説明 | メリット | デメリット |
|------|------|---------|-----------|
| ファイル単位ハッシュ | ローテーション済みファイルの SHA256 を記録 | シンプルで実装が容易 | ファイル内の1行削除・順序変更は検出できない |
| レコード単位ハッシュ | 1 件ずつハッシュを計算 | CPU 負荷が低い | レコードの削除・順序入れ替えは検出できない |
| ハッシュチェーン | 前のレコードのハッシュを含めて次のハッシュを計算（ブロックチェーン類似） | 連続性を保証・削除・順序変更を検出可能 | 実装が複雑、チェーン切れで以降を検証不能 |
| syslog 転送 | 転送先サーバーのログと照合 | リアルタイムで保護 | 転送先も攻撃された場合は無効 |
| デジタル署名 | 公開鍵暗号で署名を付与 | 法的証拠として有効 | 鍵管理が必要 |

```bash
# ハッシュ値の記録と検証
sha256sum /var/log/app/app.log > /secure/app.log.sha256

# 検証（OK / FAILED で結果を確認）
sha256sum -c /secure/app.log.sha256

# 複数ファイルの一括チェック・異常のみ表示
find /var/log/app -name "*.log" -exec sha256sum {} \; > /secure/all.sha256
sha256sum -c /secure/all.sha256 2>&1 | grep -v "OK"
```

### タイムスタンプ認証（TSA）

信頼できる第三者機関（Timestamp Authority）がハッシュ値に時刻を認証スタンプする。法的証拠として有効。OSの時計に依存せず、改ざんされてもスタンプは無効化されるため信頼性が高い。

```bash
# OpenSSL での TSA リクエスト生成
openssl ts -query -data app.log -no_nonce -sha256 -out app.log.tsq

# TSA サーバーに送信
curl -H "Content-Type: application/timestamp-query" \
     --data-binary @app.log.tsq \
     https://tsa.example.com/tsa > app.log.tsr

# 検証
openssl ts -verify -data app.log -in app.log.tsr -CAfile ca.crt
```

---

## コンプライアンス

### 主要規制の保管期間

| 規制・ガイドライン | 対象 | 保管期間の目安 |
|-----------------|------|--------------|
| PCI DSS（データセキュリティ管理基準） | クレジットカード取扱事業者 | 1年以上（直近3ヶ月はオンラインアクセス可能） |
| FISC 安全対策基準 | 金融機関 | 数年〜 |
| 医療情報システム安全管理ガイドライン | 医療機関 | 数年〜 |
| GDPR | EU 個人データ取扱事業者 | 目的達成後に削除（保管期間は目的に依存） |
| J-SOX 法（内部統制） | 上場企業 | 7年 |
| ISMS / プライバシーマーク | 一般企業 | 1年程度 |

**実務的な目安:** 一般的な企業では **5〜7 年**の保管が必要と考えられる。

### NIST SP 800-92 ガイドライン準拠のポイント

```
1. ログの完全性: ハッシュ・デジタル署名による改ざん検知
2. ログの機密性: 機密情報の暗号化・アクセス制御（最小権限の原則）
3. ログの可用性: バックアップ・冗長化（3-2-1 ルール）
4. 時刻同期: NTP による正確なタイムスタンプ
5. ログの保管: 規制要件に応じた保管期間と安全な廃棄
```

### NTP 時刻同期

複数システムのログを相関分析するとき、タイムスタンプのずれは分析の信頼性を損なう。ログのタイムスタンプはシステム時計に依存するため、NTP で常に同期しておくことが必須。

```bash
# 時刻同期状態の確認
timedatectl status

# chrony 使用時の確認
chronyc tracking

# /etc/chrony.conf に日本標準時サーバーを設定
server ntp.nict.jp iburst
```

### コンプライアンス組織対応

技術的対策に加えて組織全体での取り組みが必要:
- **従業員教育**: 年1回以上のセキュリティ研修（プライバシー保護・情報管理の重要性）
- **内部監査**: ログ管理を含む対策の遵守状況を定期チェック
- **内部通報制度**: 違反が発生した場合の早期対応体制
- **規程の整備**: プライバシーポリシー・データ管理規定の最新化と各部署での遵守モニタリング

---

## フォレンジック対応

### 証拠保全手順

インシデント発生時のログ活用における証拠保全の基本ステップ:

```
1. ログの収集
   影響を受けた可能性があるすべてのシステムのログを収集する
   （単独ではなく複数システムのログを組み合わせる）

2. タイムスタンプの確認・調整
   すべてのログのタイムスタンプが正しく同期されているか確認する
   ずれがある場合はスクリプトで一括補正する

3. イベントの抽出とラベリング
   エラー・警告・重要なイベントを抽出し、
   「エラー発生」「処理遅延」「再起動」などのラベルをつけて整理する

4. 時系列での並べ替え
   抽出したイベントを時系列で並べ、システム間の時間的なつながりを確認する

5. 因果関係の推測と検証
   イベントの前後関係から因果関係を推測し、
   再現テストなどで検証する（相関 ≠ 因果に注意）

6. 証拠の保全・保管
   ハッシュ値・TSA タイムスタンプで改ざん防止の措置を講じる
   3-2-1 ルールに従い複数箇所に保管する
```

**タイムスタンプ補正スクリプト（Python）:**

```python
from datetime import datetime, timedelta
import re

time_offset = timedelta(hours=1)  # ずれの時間

with open('old.txt', 'r') as infile, open('new.txt', 'w') as outfile:
    for line in infile:
        match = re.match(r'^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})(.*)', line)
        if match:
            timestamp_str, rest = match.groups()
            dt = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
            corrected_dt = dt + time_offset
            outfile.write(corrected_dt.strftime('%Y-%m-%d %H:%M:%S') + rest + '\n')
        else:
            outfile.write(line)
```

### なぜなぜ分析テンプレート

根本原因分析（RCA: Root Cause Analysis）で使われる「なぜなぜ分析」の考え方:

```
問題: サービスがダウンした
  なぜ1: サーバーのCPUが高負荷になった
    なぜ2: 特定の処理で無限ループが発生した
      なぜ3: ループ終了条件の境界値チェックが不足していた
        なぜ4: レビュー時にエッジケースの確認が行われなかった
          なぜ5: レビューチェックリストに境界値テストが含まれていなかった
            → 根本原因: プロセスの不備（チェックリストの不備）
            → 再発防止策: チェックリストに境界値テスト項目を追加
```

**重要な原則:**
- 表面的な症状（CPU 高負荷）ではなく、なぜそうなったかを深堀りする
- 1 つのログだけでなく、複数のログを組み合わせて分析する
- 複数の原因が絡み合っている場合は、それぞれを分解して検討する

### フィッシュボーン図（特性要因図）

問題の構造と因果関係を視覚化するために使用する。

```
                人（People）            方法（Method）
                    |                       |
             ミスの多い操作           手順書が不明確
                    \                      /
                     \                    /
材料（Material）------→[ 障害（問題）]←------環境（Environment）
     /                    /\                   \
    /                    /  \                   \
パッチ未適用         設備（Machine）            深夜作業・疲労
                   老朽化したサーバー
```

4M（人・方法・材料・設備）や 4M1E（+環境）の軸で原因を整理し、根本原因を特定する。

---

## モニタリング・アラート設計

### リアルタイム検知の設計

```
ログ出力の閾値 < 通知の閾値
（例: CPU 70% 超で 5% ごとにログ出力、90% 超で担当者に通知）
```

エラーが発生していなくても問題を事前に検知するために、使用率・空き容量などのメトリクスを定期的にログに出力する設定を行う。

### 通知の緊急度分類

| 緊急度 | 通知方法 | 対象の例 |
|--------|---------|---------|
| 最高 | 警告音・警告ランプ + 電話連絡 | サービス完全停止・セキュリティインシデント |
| 高 | チャットツール / SMS | レスポンス低下・エラー率急増 |
| 中 | メール | ストレージ残量不足（余裕あり）・ログイン失敗多発 |
| 低 | 日次レポート | 通常の警告・傾向の変化 |

### 閾値調整とアラート疲れ対策

**アラート疲れ（アラート疲労）**: 誤検知が多発することで担当者が重要なアラートを見逃す状態（「オオカミ少年」効果）。

**誤検知を減らすための工夫:**
- 複数の条件を組み合わせる（CPU 使用率 + メモリ使用率 + レスポンスタイムを組み合わせてアラート）
- 瞬間値ではなく時間経過を考慮する（急増なのか、徐々に増加しているのかを判断）
- 定期的に閾値を見直し、現場担当者からフィードバックを収集する
- 誤検知が多いアラートと見逃しが多いアラートをリストアップして優先度をつけて改善する

### 連鎖障害の相関分析

連鎖障害: あるシステムの障害が他のシステムに波及し、次々と障害が発生する現象。

**典型的な連鎖例:**
```
DBのストレージ容量不足 → DB書き込み失敗
  → Webサーバーの応答遅延
    → API タイムアウト発生
      → クライアントアプリの強制終了
```

**相関分析（コリレーション分析）の流れ:**

```
1. 複数システムのログを収集（ファイアウォール・DB・Web・アプリ等）
2. タイムスタンプを NTP で同期（ずれがあれば補正スクリプトで調整）
3. エラー・警告・重要イベントを抽出してラベリング
4. 時系列に並べてシステム間の因果関係を可視化
5. 再現テストで因果関係を検証（相関 ≠ 因果）
```

> 注意: 相関があっても因果関係があるとは限らない。同じ時系列でイベントが並んでいても、偶然の一致の可能性がある。必ず再現テストで検証する。

**ログの粒度に注意:**
- 細かすぎるログ: 分析が困難になる
- 粗すぎるログ: 原因を特定できない
- 相関分析を想定してログの粒度を設計する（何を特定したいかを先に決める）

**分析ツール:**
- SIEM ツール（Splunk 等）: 大量ログの相関分析に対応
- Elastic Stack（Elasticsearch + Kibana）: ログ管理プラットフォーム

### 根本原因分析（RCA）

トラブルが起きたとき、表面的な解決ではなく根本原因を特定して再発防止策を実施する。

```
ダッシュボードで確認できる症状（CPU 高負荷）
  ↓ なぜ？
ログから原因を追う（無限ループ・負荷集中）
  ↓ 複数のログを組み合わせる
根本原因の特定（チェックリスト不備・設定ミス等）
  ↓
再発防止策の策定と実施
```

**ログを RCA に活用する際のポイント:**
- トラブル発生前後のシステムの状況・操作履歴が細かく記録されているログを使う
- 1 つのログだけでなく複数のログを組み合わせる（長期運用中のトラブルは複数原因が絡み合う）
- 「問題が発生した」事実と「なぜ発生したか」の原因を区別して分析する
