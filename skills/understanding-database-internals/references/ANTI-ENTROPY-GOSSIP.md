# アンチエントロピーと情報散布

第12章「アンチエントロピーと情報散布」のリファレンス

## 概要

本書でこれまでに議論した通信パターンの大半は、ピアツーピアか一対多、つまりコーディネータとレプリカのいずれかでした。システム全体に渡ってデータレコードを更要に伝播するには、伝送の2ノードが利用可能で、他のノードと通信ができる必要があります。しかし、これらの通信パターンでは、スループットは単一のマシンに制限されます。

高速で断続的な高い伝播は、データレコードにはあまり適用できないかもしれませんが、メンバーシップ情報（ノードの参加と離脱）、ノードの状態、障害、スキーマの変更などのクラスタ全体に渡るメタデータについては、よより重要です。この情報が含まれるメッセージは、一般的に病間であが少なく小さいものですが、可能な限り、高速で確実に伝播させる必要があります。

このような更新をクラスタ内のすべてのノードに伝播するには、一般的に以下3つのアプローチのいずれかを利用します [DEMERS87]。これらの通信パターンの概要を図に示すと、図12-1のようになります。

- a) 1つのプロセスから、その他すべてのプロセスへブロードキャストで通知します
- b) 定期的なピアツーピアの情報交換。ピアからは近いと接続し、メッセージを交換します
- c) 連携ブロードキャスト、メッセージを受信したプロセスがブロードキャストする立場となり、より高速で確実な情報の拡散に貢献します

他のすべてのプロセスにメッセージをブロードキャストすることは、もっとも単純なアプローチですが、利用可能なネット大幅に増大させます。しかし、大規模なクラスタでは、ノードの数が多いためにコストが高くなり、1つのプロセスに通信に依存することで信頼性が低くなる可能性があります。障害のプロセスは、ネットワーク上の、他のすべてのプロセスの存在を確認していないと以限りません。そのため、ブロードキャストするプロセスとそれを受信する他のプロセスの両方が、同時に正常に動作していなければなりません。これは、達成するのに困難な場合があります。

これらの制約を緩和するために、一部の更新が伝播に実敗することを前提とします。コーディネータは最善を尽くして、決時的に参加ノードにメッセージを送信し、障害があった場合には、アンチエントロピーの仕組みがノードを同期された状態に戻します。この方法では、メッセージを配信する役割はシステム内のすべてのノードで共有され、初期の配信と、定期的な間期の2段階のステップに分割されます。

アンチエントロピーは、システムの無秩序さの度合いを表す特性です。分散システムの場合、エントロピーは、ノード間の状態が異なる程度を表します。この性質は望ましいものではなく、その程度は影力小さく保つべきなので、エントロピーに対処するのに有効な技術を数多く存在します。

アンチエントロピーは、通常、初期の配信で障害が発生した場合に、ノードを最新の状態に戻すために使用されます。つまり、一部の更新が障害し、その間のノードが情報を起欠している場合に、アンチエントロピーは、クラスタ全体で情報を修正するために使用できます。システムは正常に機能し続けられます。別の言い方をすれば、アンチエントロピーは、結果整合性システムにおいて、取返しにかかる時間の削減を短縮するために使用されます。

アンチエントロピーは、ノードが前期されている状態を維持するために、欠落または破壊していいる状態、または局所バックグラウンドプロセス、またはフォアグラウンドプロセスを勤作させます。バックグラウンドのアンチエントロピープロセスでは、Merkleツリーなどの補助的な構造と更新ログを使用し、状態の不一致を検出します。フォアグラウンドのアンチエントロピープロセスでは、読み取りや書き込み要求の処理の中で、たとえばヒンテッドハンドオフや、読み取り修復などを発動させます。

レプリケートされたシステムにおいてレプリカ間に組織があり問合に、一貫性を回復し、それらを同期した状態に戻すには、レプリカの状態をペアで比較することで、欠陥しているレコードを検討し、修復する必要があります。大きなデータセットの場合、これは非常に大きなコストがかかります。なぜなら、2つのノードのデータセット全体を読み取って、また伝播されていない最新の状態の差異についてレプリカに通知する必要があるからです。このコストを削減するための対策として、レプリカがどのような方法で削題されにならか、およびデータがどのようなパターンでアクセスされるかを検討することができます。

## 読み取り修復

読み取り時にレプリカ間の不一致を修正するのは、きわめて簡単です。なぜなら、その時点でレプリカに接続してそれぞれに問い合わせを行い、それらの応答が一致するかどうかを確認できるからです。ただし、この場合でも書き込みが保存されているデータセット全体に対して問い合わせを行うのではなく、クライアントから要求されたデータのみを対象としている点、注意が必要です。

ディディーターは、分散読み取りを実行します。その際には、レプリカは同期しておらず、いずれからでも何時に情報を得るという設定が前提になります。レプリカが異なる応答を送信すると、コーディネータは、更新が欠落しているレプリカに、その欠落している更新を送信します。

この仕組みは、**読み取り修復**（read repair）と呼ばれます。多くの場合は、不整合を検出して修復を行うコーディネータノード自体において、コーディネータノードがレプリカに問い合わせて要求を行い、それらの応答を待って比較します。一部のレプリカに最新の更新が欠落していて、それらの応答が異なる場合、コーディネータは不整合を検出し、更新をレプリカに送り込しします [DECANDIA07]。

一部のクライアント必ウォールのデータベースでは、**すべてのレプリカに接続する**という要件を外し、代わりに調整可能な一貫性レベルを使用することを選択するものあります。一貫性のある結果を返すためには、すべてのレプリカに接続して修復する必要はありません。必要とされるのは、一貫性レベルを満たすノードの数だけです。クォラムの読み取りと書き込みを行う場合には、引き続き一貫性のある結果が得られますが、レプリカの中には、すべての書き込みが含まれるいものもまだ存在するかもしれません。

読み取り修復は、**ブロッキング**操作または**非同期操作**として実装できます。ブロッキングの読み取り修復中は、コーディネータがレプリカを修復するまで、新しいクライアントの要求は特えなければなりません。非同期の読み取り修復は、結果をユーザーに返された後で実行されるタスクを、単にスケジューリングします。

ブロッキングの読み取り修復では、**クォラム読み取り**のための、読み取りの申請性（https://databass.dev/links/1、p.240「11.6 セッションモデル」）が保証されます。クライアントが特定のレコードにアクセスすると、それ以降の読み取り修復のために、レプリカの状態がすでに修復されているので、に読み取ったa値と、少なくとも同程度に新しい値を即座に返すようになります。読み取りにクォラムを使用していない場合には、後続の読み取りの時点までにデータがターゲットノードに伝播されていない可能性があります。この場合には、ブロッキングの読み取り修復では、可用性が犠牲になります。これは、修復処理がターゲットとレプリカによる応答待ちをする必要があるためです。

レプリカの応答間で、どのレコードが異なっているかを正確に検出するために、一部のデータベース、たとえばApache Cassandraなどでは、マージリスクール（https://databass.dev/links/2）を備えた特殊なイテレータを使用しています。これは、マージの結果と側期の入力の間の差異を明解します。その出力は、欠落しているデータをレプリカに通知するために、コーディネータによって使用されます。

読み取り修復は、レプリカ間に違いない同期していることを前提にしており、すべての要求がブロッキング修復にフェールバックすることは想定していません。ブロッキング修復の読み取り修復のために、その間に完了した読み取り操作が含い返り、後続の要求が一貫性を削集することを期待されます。

## ダイジェスト読み取り

コーディネータは、全体を読み取る要求を、すべてのノードに発行するのではなく、そうした要求は1つのノードにだけ発行し、その他のレプリカには**ダイジェスト要求**のみを送信することができます。ダイジェストでは、レプリカにおけるローカルなデータを読み取り、要求されたデータの完全なスナップショットを送守代わりに、この応答のハッシュを計算します。次にコーディネータは、全体を読み取ったデータのハッシュを計算し、それを他のすべてのノードから受け取ったダイジェストと比較できます。すべてのダイジェストが一致すれば、レプリカ同士が同期していることを確認できます。

一致しないダイジェストがある場合、どのレプリカが進んでいて、どのレプリカが遅れているのかは、コーディネータにはわかりません。遅れているレプリカを、その他のノードと同期させるためには、コーディネータは、応答として異なるダイジェストを返送してきたすべてのレプリカに、改めて全体を読み取るように要求して、それらの応答を比較してから、データを調除し、遅れているレプリカに更新を送信する必要があります。

ダイジェストは、通常、MD5などの非暗号化ハッシュ関数を使用して計算されます。これは、ハッピーパスの性能を上げるために、高速で計算する必要があるからです。ハッシュ関数は衝突安発生する可能性があります か、その確率は、大半の現実世界のシステムでは許容可能な程度です。データベースには多数の場合、アンチエントロピーの仕組みが敗有機使用されるので、万がーハッシュ衝突が発生してもら、データは別のサブシステムで補間できることを期待できます。

## ヒンテッドハンドオフ

もう1つのアンチエントロピーのアプローチは、**ヒンテッドハンドオフ**（hinted handoff）[DECANDIA07]と呼ばれる書き込み系組の修復メカニズムです。ターゲットノードが書き込みの御接を失敗した場合、書き込みを一時的に保留します。そのあとこのレプリカの1つは、ヒントと呼ばれる特別をレコードを格納します。このレコードは、ターゲットノードが復旧するとすぐに切りプレイされます。

Apache Cassandraの場合、ANYの一貫性レベルが使用されていない限り [ELLIS11]、ヒントの書き込みはレプリケーションファクタにカウントされません（p.242「11.8 調整可能な一貫性」）。と言うのは、ヒント内のデータは、読み取り用にアクセスできず、遅れている参加ノードが消いくの全を判断されないかからです。

前のそのデータベース、たとえばDynamoでは、ヒンテッドハンドオフとともに、**スロッピークォラム**（sloppy quorum）を使用しています。スロッピークォラムでは、レプリカに障害が発生した場合に、ノードリストから正常なノードを取り出して、追加して使用できます。これらのノードは、失行された操作のデータやレプリケートするわけ要求はありません。

たとえば、ノードのリストを保持し、それらのノードを{A, B, C, D, E}とします。{A, B, C}は書き込み操作が実行されるレプリカであり、ノードBは動作を停止しています。Aは問い合わせたコーディネータなので、ノードDを選択してスロッピークォラムを充たし、Aは依々に実際したリストからノードのデータを取り出します。ここで、データが{A, D, C}にレプリケートされます。ただし、Dのレコードには、そのメタデータにヒントが含まれています。これは、書き込みが本ともともBを対象としていたからです。BがBが復旧したあたすぐに、DはヒントをBに送信してC以上に戻さうとしました。ヒントがBにリプレイされた後は、レプリカの範数を減らすことなく、それを安全に削除できます [DECANDIA07]。

同じ段階で、ネットワーク分断によってノードC{B, C}が他のクラスタから短時間切断されたときに、スロッピークォラムの書き込みが{A, D, E}に対して行われた場合、この書き込みの直後に行われる{B, C}に対する読み取りは、最新の読み取りを**認識することがありません** [DOWNEY12]。つまり、スロッピークォラムは一貫性を犠牲にして、可用性を改善します。

## Merkleツリー

読み取り修復で可能なのは、現在問い合わせの対象になっているデータの一貫性を修復することだけなので、積極的に照会されないデータの不整合を検出して修復するには、別のメカニズムを使用する必要があります。

すでに検討したように、レプリカ間でどの行に違いがあるかを正確に検出するには、データレコード全体で交換して、比較を行うことが必要です。これはまったく現実的ではなく、コストがかかります。そこで、多くのデータベースでは**Merkleツリー** [MERKLE87] を採用して、調否のコストを削減しています。

ハッシュツリー、ローカルデータのコンパクトなハッシュ構成を用いて、ハッシュのツリーを作成します。このハッシュツリーの最下位レベルは、データレコードが格納されているテーブル全体をスキャンし、レコード範囲のハッシュを計算することで作成されます。上位のツリーレベルには、そのよりり下位レベルのハッシュから計算されたハッシュが含まれています。こうして構築された開階構造では、ハッシュツリーのルート、つまりハッシュのツリーの再上段的にどころとサブツリーを交換することで、比較を行うことが可能になります。このような処理は、レベルごとにサブツリーを交換して比較を行うか、ツリー全体を交換して比較を行うことで可能になります。

図12-2は、Merkleツリーの構成を示しています。最下位レベルは、データレコードの範囲のハッシュで構成されています。それより上位の各レベルのハッシュは、その下位レベルのハッシュから計算されます。このプロセスが、ツリーのルートに達するまで再帰的に繰り返されます。

2つのレプリカの間に不整合が存在するかどうかを判断するために必要なのは、Merkleツリーからルートハッシュを取り出して比較することだけです。最上位から成下位までハッシュを交換することで、ノード間で相違のある範囲を特定し、それらに含まれるデータレコードを修復することが可能になります。

Merkleツリーでは、最下位から最上位まで的階層的に計算が行われるので、データに変更があると、サブツリー全体の計算が再構成されます。さらに、ツリーのサイズ、つまり交換されたメッセージのサイズとその情報（データ範囲がいかに小さく正確であるか）の間のトレードオフを存在します。

## ビットマップバージョンベクトル

このテーマに関する最近の研究において、ビットマップバージョンベクトル [GONCALVES15] が紹介されています。これは、**最新性**に基づいて、データの欠陥を解決するために使用できます。

ノードは、ローカルにクライアントからの書き込みをリードしたレプリケートされた操作のピア全体に送えロッグを保持しています。アンチエントロピーの処理の際に、ログが比較され、欠落しているデータがターゲットノードにレプリケートされます。

各書き込みは、ノードによって調整されると、dot (i,n)によって表されます。これは、ノードローカルなシーケンス番号iを持つイベントが、ノードnによって調整されたことを意味します。

シーケンス番号iは1から始まり、ノードが書き込み操作を実行するたびに、インクリメントされます。

レプリカの状態を追跡するには、ノードローカルな論理クロックを使用します。各クロックは1セットのdotを表します。これらのdotは、このノードの履歴、そのノード自体によって調整されて見た、あるいは積極的に、他のノードによって調整およびレプリケートされて見た書き込みを表します。

ノードの論理クロックでは、そのノード自体によって調整されたイベントではギャップが生じません。他のノードからレプリケートされていない書き込みがある場合には、クロックにギャップが含まれます。また、2つのノードのどちらか一方にまだ伝播していないdotによって表されるギャップを特定してから、それらに関連付けられたデータレコードをレプリケートします。これを行う際には、それぞれのdotが参照するデータレコードを再構築する必要があります。この情報は、Dotted Causal Container（DCC）に格納されます。このコンテナは、拡定とそれぞれの因果関係依存を対定して、dotをマッピングします。このようにして、競合解決にょって書き込み間の因果関係を提えています。

図12-3（[GONCALVES15]から転用）は、システム内の3つのノード、P₁、P₂、およびP₃の状態の表現とP₂の観点から見て、異期した値を追跡する場合の例を示しています。P₂は、書き込みを行うか、またはレプリケートされた値を受け取るたびに、このテーブルを更新します。

レプリケーション時には、P₂はその状態のコンパクトな表現を作成し、ノードのIDから最新の値のペアまでマップを作成します。その値まで追跡した書き込みを目撃しており、ビットマップ内では、目撃された他の書き込みは1としてエンコードされます。この場合の(3, 01101₂)は、ノードP₃が追跡した定義範囲を3とし、およびP₃と関連性のある2番目、3番目、および5番目の位置の値を目撃したこと、つまりシーケンス番号が、6、およびδの値を目撃したことを意味します。

他のノードとの交換時には、他のノードが日譲した欠落している更新を受け取ります。システム内のすべてのノードが、追跡した値をインデックス1まで目撃し終わるとすぐに、バージョンベクトルは、このインデックスまで切り捨てることができます。

このアプローチの長所は、他の書き込み時間の因果関係を捉え、他のノードに欠落しているデータポイントを、ノードが正確に識別することを可能にすることです。短所は、ノードが長時間に渡って副作を停止していた場合に、ビアノードは0を幾り詰めることができないことです。これは、そのノードの世界が遅延しているので、そのノードが復旧したら、データをレプリケートしなければならないからです。

## ゴシップの散布

大衆は、いつでも情報的な伝染病の温床です。

—— カール ユング

他のノードを巻き込んで、ブロードキャストの**到達範囲**とアンチエントロピーの**信頼性**を確保しながら更新を伝播するには、ゴシッププロトコルを使用します。

ゴシッププロトコルは、確率的な通信手順であり、人間社会においてエとどのように巨がるかを、医学的情報の伝播方式を擬似しています。噂と伝染病は、これらのプロトコルの動作を説明するうえで、具体的なイメージを喚起してくれます。噂は、人々がそれらを聞くことに関心を持っている間に広まします。病気は、感染しやすい人が集団の中にいなくなるまで伝染します。

ゴシッププロトコルの主要な目的は、協調的な伝播を用いて、あるプロセスからクラスタの残りのプロセスに情報を伝めることです。ウイルスが、集団の中で個人から個人につつることを全体に拡がるのと同じように、おそらくはステップごとに範囲を広げながら、情報がシステム内で伝達され、より多くのプロセスを巻き込んでいきます。

一般的に広められる情報を選り、受け取る側の全体のリストを管理することを避け、さらに単一のコーディネータがシステム内や他の参加ノードのそれぞれにメッセージをブロードキャストする必要性をなくすために、このクラスのアルゴリズムでは、**固心の連鎖問散**を使用して全伝性をモデル化します。このプロトコルの効率性は、元民なメッセージによって生成されるオーバーヘッドを抑えつつ、その一方で、可能な限り多くのノードにいかに到時間で伝播できるかを確立させれます。

ゴシップは、同質的な分散システムにおける、非同期メッセージの配信に使用できます。このようなシステムではメンバーシップが変動するし、メッセージ内容が常に変化してから行けなど、どのようなトポロジーを持つか、ノードが朝握して参加したり脱退したりする故なメンバーシップを持つシステムがメッシュネットワークで、有効に活用できます。

ゴシッププロトコルは正常に機能であり、分散システムに固有の障害が存在する中で、高い信頼性を達成するのに有効です。メッセージはランダムな方法で伝維されるので、開金つぶこ通信コンポーネントが障害を発生したとしても、単に別の経路を経由してそれらのメッセージを配信できます。まましく、システムが障害に適応すると言えます。

### ゴシップの仕組み

プロセスは、定期的に午個のピアをランダムに選択し（この場合のfは設定可能なパラメータで、ファンアウトと呼ばれます）、現行のホットを情報をそれらとの間で交換します。プロセスは、それぞれに新しいメッセージを受け取ると、それをさらに転送しようとします。ピアは確率論を使用して選択されいるので、常にいくらかのオーバーラップがあり、メッセージは被り返し配信されることになり、しばらくの間前時断し続けることがあります。メッセージの**冗長性**は、縦り返し配信によって引き起こされるオーバーヘッドを被える指標です。冗長性は乗常安全な特性です。冗長性のあるメッセージの中には、メッセージの宛先に到達するための助手的なフォールバックがあります。

システムが収敛するまでに必要な時間の長さは、レイテンシと呼ばれます。収敛に至る、つまりゴシッププロセスが停止するまでの時間とメッセージをすべてのピアに配信するまでの時間には、普片の違いがあります。これは、すべてのピアが通知を受け取っても、ゴシップが続行されることがあるからです。ファンアウトとレイテンシは、システムのサイズに比例して変わります。大規模なシステムでは、レイテンシを安定させておくために、ファンアウトを増加するか、あるいは大きなレイテンシを許容するかを選択しなければなりません。

収敛した時点でのシステムは、いつでも同期をリ組してデメッセージを配信するまたはメッセージの危険が続行されることがあります。厳密を測御するためには、重量をカウントすることで、レイテンシを改善し、冗長性を削減することができます [DEMERS87]。

直性の観点から見ると、ゴシッププロトコルは、**収束の一貫性**を実現します [BIRMAN07]。つまり、ノードは、過去に発生したイベントについて、同じ観点を持つ傾向があります。

### オーバーレイネットワーク

ゴシッププロトコルは重要で有用ですが、通信は欧く問題誤認に適用されます。非伝染性のアプリケーションにより的目的なメッセージを配信する一般的には少し典型的な方法でメッセージを配信できます。おそらくは明期的にノードを列挙して対応するのではなく、**一般的にはより典型的**な方法でメッセージを配信できます。

ゴシッププロトコルは重要で有用ですが、通信は欧く問題誤認に適用されます。非伝染性のアプリロケーションに関むログベースのプロトコルを使用できれば、一般的により明示的な信頼性を必要としないので、ノードが朝握に参加したり脱退したりする故なメンバーシップを持つシステムがメッシュネットワークで、有効に活用できます。

ゴシップ比、固質的な分散システムにおける、非同期メッセージの配信に使用できます。このようなシステムではメンバーシップが変動するし、メッセージ内容が常に変化するから行けなど、どのようなトポロジーで持つか、ノードが朝握して参加したり脱退したりするなど、故なメンバーシップを持つシステムがメッシュネットワークで、有効に活用できます。

ゴシップが、非完全に最古されるまでに必要な時間の長さは、レイテンシと呼ばれます。収敛に至る、つまりゴシッププロセスが停止するまでの時間とメッセージをすべてのピアに配信するまでの時間には、首片の違いがあります。これは、すべてのピアが通知を受け取っても、ゴシップが続行されることがあるからです。ファンアウトとレイテンシは、システムのサイズに比例して変わります。大規模なシステムでは、レイテンシを安定させておくために、ファンアウトを増加するか、あるいは大きなレイテンシを許容するかを選択しなければなりません。

収敛した時点でのシステムは、いつでも同期をリ組してデメッセージを配信するまたはメッセージの危険が続行されることがあります。厳密を測御するためには、重量をカウントすることで、レイテンシを改善し、冗長性を削減することができます [DEMERS87]。

システムが収敏するまでに必要な時間の長さは、レイテンシと呼ばれます。収敛に至る、つまりゴシッププロセスが停止するまでの時間とメッセージをすべてのピアに配信するまでの時間には、普片の違いがあります。これは、すべてのピアが通知を受け取っても、ゴシップが続行されることがあるからです。ファンアウトとレイテンシは、システムのサイズに比例して変わります。大規模なシステムでは、レイテンシを安定させておくために、ファンアウトを増加するか、あるいは大きなレイテンシを許容するかを選択しなければなりません。

2つのアプローチの間の折衝案としては、ゴシップシステムにおいて、**一時的な固定トポロジ**を構築します。これは、ピアのオーバーレイネットワークを作成することで達成できます。ノードはそれぞれのピアを抽出し、距離の近さに基づいて（通常はレイテンシで測られます）最後の接続ポイントを選択することができます。

システム内のノードは、**スパニングツリー**を形成できます。これは、単一方向でループのないグラフで、明確なエッジを持ち、ネットワーク全体をカバーします。このようなグラフを持つと、一定のステップ数でメッセージを配信できます。

図12-4に、スパニングツリーの例を示します（1.1）。

- a) すべてのエッジを使用することなく、ポイント間の完全な接続性を達成します
- b) 1つのリンクが切断したとしても、その先のサブツリー全体への接続性を失う可能性があります

このアプローチの潜在的な短所の1つは、お互いを優先するピアが、相互に接続された島を形成する可能性があることです。

メッセージの数を少なくするために、システムは**安定した**状態にあるときには、両方のアプローチ、つまり固定トポロジとツリーベースのブロードキャストを混合させることが可能にするし、フェールオーバーとシステムの段階のために、ゴシップにフォールバックすることもできます。

### ハイブリッドゴシップ

プッシュ/運搬プッシュマルチキャストツリー（Plumtrees）[LEITAO07]では、伝染性とツリーベースのブロードキャストツリーが生まれます。Plumtreesは、最小のオーバーヘッドで活発にメッセージを配信するために、ノードのスパニングツリーオーバーレイを作成することで勅作します。標準的な条約のもとでは、ノードは、サンプリングで指定されたビアの小さなサブセットにのみ、完全なメッセージを送信します。

各ノードは、ノードへとメッセージを送信し、それ以外のノードについては、メッセージIDのみを**適延**させて転送します。ノードがそれまでに見たことのないメッセージのIDを受け取った場合には、そのメッセージを受け取るために、ピアに問い合わせができます。この適延プッシュステップは、高い信頼性を保証し、ブロードキャストツリーを築早く正常に反映するための機構を提供します。階害を検出すると、適延プッシュステップを介してゴシップアプローチにフォールバックして、メッセージをブロードキャストし、オーバーレイを修復します。

分散システムの性質上、すべてのノードとノード間のリンクは、いつでも障害を発生する可能性があり、セグメントに到達できなくなると、ツリーをどころどころが不可能になります。適延プッシュネットワークは、ツリーを構築して修復するために、観測したメッセージについて、ピアに通知するのに役立ちます。

図12-5に示したのは、このような二重該当の例です。ノード同士は、最遠をスパニングツリー（実線）と適延ゴシップネットワーク（点線）で接続されています。このネットは、特定のネットワークトポロジを表しておらず、ノード間の検鏡のみを表しています。

ツリーの構築と修復に適延プッシュメカニズムを使用することの長所の1つは、最初に応答するノードがブロードキャストツリーに追加されるので、常に負荷的のあるネットワークでは、メッセージのレイテンシ最小にするツリーを生成する傾向があることです。

### 部分的なビュー

すべての既知のピアにメッセージをブロードキャストし、クラスタの完全なビューを管理するのは、コストがかかりすぎ、現実的ではありません。特にGKT（システム内で参加したり追出したりするノードのダイナミクスに対処するうえで必要です。これを避けるために、ゴシッププロトコルでは、多くの場合、**ピアのサンプリングサービス**を使用します。このサービスでは、クラスタの**部分的なビュー**を管理します。部分的なビューは、ゴシップを使用して定期的に更新されます。部分的なビューには直接見えますが、これはある程度の完整性の比較的がゴシッププロトコルにはあるために確実になります。ただし、冗長性が成まる可能性があることになります。

たとえば、Hybrid Partial View（HyParView）プロトコル [LEITAO07] の場合には、クラスタの小さな**アクティブビュー**と、大きな**パッシブビュー**を管理します。アクティブビューに含まれるピアは、積極的に使用できるオーバーレイを形成します。パッシブビューは、アクティブビューに含まれるノードが障害を発生したときに、その代わりに使用できるノードのリストを管理するために使用されます。

ノードは、定期的にシャッフル操作を実行し、その際、アクティブビューとパッシブビューと入れ替えます。この入れ情熱によって、ピアから受け取ったバッシブビューとアクティブビューの両方から取り出したメンバーをパッシブビューに追加し、古い備からり順番に除外して、リストサイズの上限を超えないようにします。

アクティブビューは、このビューに含まれるノードの状態を監視し、ピアからの変更に従って更新されます。プロセスP₁が、アクティブビューに含まれるピアの1つであるP₃に障害が発生した旨短い場合、P₁はアクティブビューからP₃を削除し、パッシブビューに含まれる代替プロセスP₃どの接続を確立しようとします。接続が失敗した場合、P₃はP₁のパッシブビューから削除されます。

P₁のアクティブビューに含まれるプロセスの数が応じて、そのアクティブビューがすでに一杯であ場合には、P₃は接続の拒否を選択できます。P₁のビューが空である場合には、P₃は、その現在のアクティブビューのうちいくつかがら選択して、クラスタの有効なメンバーに辛早くなることができます。

このアプローチは、アクティブビューのノードのみを成長させることで、システム内での数独のノードのためめけすぐないのです、すべてのノードのメンバーのリストを、最新の状態に維持するために高がるコストのためでもあります。部分的なビューは、優度するノードで情成される小さなサブセットのみと、ノードが活発に通信することを可能にします。

## まとめ

結果整合性のシステムでは、レプリカの状態の不一致を許容します。調整可能な一貫性では、一貫性を可用性と入れ替えたり、その逆も可能にします。レプリケーションの不一致は、以下のアンチエントロピーメカニズムのいずれかを使用して解決できます。

### ヒンテッドハンドオフ
ターゲットが動作を停止した場合に、一時的に書き込みを保留したノードに格納し、ターゲットが復旧したらすぐに、そのターゲット上でそれらをリプレイします。

### 読み取り修復
応答を返送し、欠落しているレコードを検出し、それらのレコードを更新が遅延しているレプリカに送信することで、要求されたデータ範囲を調整します。

### ダイジェスト読み取り
値を見えないレコードの読み取り前は、さそこで見た値より古い値を見られません。

### モノトニックな読み取り
同じクライアントからの書き込みは、このクライアントによって行われた順序で、他のクライアントに伝播されます。

### 読み取りに続く書き込み
書き込み操作は、同じクライアントによって実行された、前の読み取りで結果を確認された書き込みの後に順序付けられます。

これらの概念を知って理解することは、背後にあるシステムの保証を理解し、アプリケーション開発にそれらを機能を従え、データに対する操作が従う必要があるルールを説明しますが、それらの有効範囲は、特定のシステムに限定されます。より強い保証を行うシステムの上に、弱い保証を行うシステムを積み重ねたり、背後にあるシステムの一貫性の意味を無視したりすることは、因果関係が不整数とデータの相互につながらないこと必要です。

また、**結果整合性と調整可能な一貫性**の概念について議論しました。クォラムに基づくシステムでは、過半数を使用して一貫性のあるデータを提供します。ウィットネスレプリカを使用すると、ストレージのコストを削減できます。
