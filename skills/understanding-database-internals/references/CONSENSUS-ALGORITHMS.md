# 合意アルゴリズム

分散システムにおいて複数のプロセスが単一の値について合意に達するためのアルゴリズム。

## 概要

合意（consensus）は、分散システムの基盤となる問題であり、以下の特性を保証する：

- **同意性**: 決定値はすべての正常なプロセスにとって同じであること
- **妥当性**: 決定値はいずれかのプロセスから提案されたものであること
- **終了性**: すべての正常なプロセスが最終的には決定に到達すること

合意を使用すると、どの値がクライアントに見えるか同じ関係実装を失うことなく、ある値から別の値にプロセスが逸脱する可能性があるため、実行順序が異なることができます。

---

## コアコンセプト

### 合意の必要性

合意が必要となる場面：

- **リーダー選出**: 障害発生時の新リーダー選定
- **状態機械レプリケーション**: 全レプリカで同一の操作順序を保証
- **グループメンバーシップ**: クラスタ構成の変更
- **分散ロック**: 排他制御の調停

### FLP不可能性定理

非同期分散システムにおいて、たとえ1つのプロセスが故障する可能性があるだけでも、完全に同期なシステムでは合意に達することは不可能である：

- **非同期**: メッセージ配信の遅延に保証がない
- **クラッシュ故障の可能性**: プロセスが突然停止する可能性
- **影響**: 実用的な合意アルゴリズムは、いずれも特定の仮定を置くか、あるいはクラッシュしたプロセスが復帰するのを待つか、またはタイムアウトに頼らざるを得ない

### 合意とアトミックブロードキャスト

合意アルゴリズムはアトミックコミットアルゴリズムより複雑ですが、フォールトトレランスに優れておらず、決定を開始プロセスからり離し、参加プロセスが故意受け入れられるかどうかではなく、その値に対する合意を達成するシステムモデルは、以下の特性を持つことを保証する必要があります：

#### グローバルな有効性

必要な不変条件が、マージされたデータベース状態と、分散してコミットされたデータベース状態の両方で、常に満たされます。トランザクションは、無効な状態を見ることができません。

#### 可用性

すべてのノードがクライアントからアクセス可能である場合、トランザクションはコミットの決定に至る必要がありますが、コミットすることによってトランザクションの不変条件を保留することになる場合には、中断しなければなりません。

#### 収束性

ノードはそれぞれのローカルな状態を無期に管理できますが、さらなるトランザクションも、不明確なネットワーク分断も存在しない場合、それらのノードは同じ状態に到達できる。

#### 調整からの解放

ローカルなトランザクションの実行は、他のノードの代理で実行されたローカルな状態に対する操作から独立しています。

---

## ブロードキャスト

### アトミックブロードキャスト

分散システムでしばしば使用される通信の抽象化であり、以下の特性を保証：

#### 信頼性の高いブロードキャスト

- **有効性**: 信頼のあるプロセスによって送信されたメッセージは、正しいプロセス全てによって配信される
- **同意性**: メッセージを配信するとき、すべてのメッセージがすべてのプロセスに配信されるか、またはまったく配信されないかのどちらか
- **均一性**: 障害が発生していないすべてのプロセスは、メッセージを同じ順序で配信します

アトミックブロードキャストは、全順序のメッセージをプロセスが同意することを保証します。つまり、メッセージの配信順序が異なる場合には、その他のすべてのメッセージはこのメッセージの前か後に配信されます。

### Virtual Synchrony

ブロードキャストを使用した合意の調停部のフレームワークの1つとして、Virtual Synchronyと呼ばれるものがあります：

- **グループ通信**: プロセスをグループにまとめます
- **ビュー（View）**: グループのメンバーがメッセージを受け取ったとき、あるいはグループメンバーがメッセージを受け取ったときのグループの状態
- **ビュー変更**: メッセージが送信された場合、そのメッセージは同じビューでの配信を保証
- **アトミックな配信保証**: 受信されたメッセージは、配信が成功したときをプロセスが通過するまで、受信されたすべてのメッセージがビューと一変更に至る前の配信を保証します

**すべてのメッセージは特定のグループに属している**ので、ビューの変更時にグループ内のすべてのプロセスがこのメッセージを受信し続けり、いずれかのグループメンバーも、このメッセージを受信または送付した限り配信されることを意味し、その結果としてアトミックな配信の保証が得られます。

---

## Zookeeper Atomic Broadcast（ZAB）

Apache Zookeeperで使用されている階層型の複数のキーバリューストアで使用されるアトミックブロードキャストプロトコル。

### 役割とフォロワー

ZABは、リーダーとフォロワーという2つの役割があり、広く知られている実装の1つです：

- **リーダー**: 一時的な状態であり、アルゴリズムのステップを実行することで処理を進めて、メッセージをフォロワーにブロードキャストし、イベントの順序を確定します
- **フォロワー**: 書き込みをクライアントのリバリー、最新の値を投票み取り繰り返すために、クライアントは、クライアントのノードの1つにリレーしします

### プロトコルのフェーズ

#### 発見（Discovery）

リーダー候補は、他のすべてのプロセスによって認識されている最新のエポックについて情報を構築し、すべてのフォロワー現在とエポックと大きさエポックを新しいエポックを提案します。

#### 同期（Synchronization）

リーダー候補は、認めらスケたアルゴリズムのステップで読証されるのです。リーダー候補は、新しいエポックのリーダーとして自身が提案するメッセージをフォロワーに送信して、フォロワーの確認応答を収集します。

#### ブロードキャスト

フォロワーが同期した状態になると、すぐに活発なメッセージ交換が開始されます。このブロードキャストフェーズでは、リーダーがクライアントのメッセージを受け取ってそれらの順序を確定し、それらをフォロワーにブロードキャストします。

### ZABの特徴

- **エポックベースのプロトコル**: リーダーは1つだけである任意のタイミングで識別されます
- **順序保証**: クライアントは有効なリーダーの提案を見ることができます
- **確認応答等**: 投票は幽霊に増加し、順番に並んだ一意の番号で識別されます

---

## Paxos

アトミックブロードキャストは、クラッシュ障害を伴う非同期システムにおける合意に相当する課題です。おそらくもっとも広く知られている合意アルゴリズムはPaxosでしょう。

### Paxosの役割

Paxosにおける参加者は、プロポーザ（Proposers）、アクセプタ（Acceptors）、またはラーナー（Learners）という、3つの役割のいずれかになることができます：

#### プロポーザ（Proposer）

クライアントから値を受け取り、これらの値を受け入れさせ提案を作成し、アクセプタから投票の取敢を試みます。

#### アクセプタ（Acceptor）

プロポーサーが提案した値を受け入れるか、あるいは拒否するか投票します。フォールトトレランスのためには、アルゴリズムでは複数のアクセプタの存在が必要ですが、活性を受渡すある必要のは、クオラム（過半数）のアクセプタの投票だけです。

#### ラーナー（Learner）

レプリカの役割を果たし、受け入れられた投票の結果を格納します。

### クオラム

クオラムは、一部の参加ノードの障害を継続めるために使用されます：

- **定義**: 任意の2つの有効な校閲を受なすことができず、1つのプロセスがプロポーザー、アクセプタ、およびラーナーに同時になることができます
- **すべての提案は、クライアントから提案された値と連鎖関係を持ちます**: 提案の値を格納した候、それらの間のhappened-before/afterの関係を追跡するために使用されます

### Paxosアルゴリズム

Paxosアルゴリズムは、一般的に**提案フェーズ**（または提案フェーズ）と、**レプリケーションフェーズ**という2つに分割されます：

#### 提案フェーズ（Prepare Phase）

1. **プロポーザーは、クライアントとの接触の最初の接点となります**: プロポーザーは、決定すべき値を受け取り、アクセプタのクオラムから投票を取得しして、結果を確定します
2. **過半数の投票を収攻できるプロポーザーは1つだけです**: 状況によっては、投票がプロポーザーの間で分割等かかることがあり、そうなるとラウンドを選択して進述する場合、通信距離が長い場合で述べ結果を把持するようになる
3. **提案フェーズにおいて、プロポーザーは、Prepare(n) メッセージ（この場合のnは提案番号です）の提案をアクセプタに送信し、投票を収集しようとします**

**アクセプタは、Prepareの要求を受け取ると、応答しなければなりません。その際、以下の条件に従います**:

- このアクセプタがまだPrepareの要求に対してより大きなシーケンス番号で応答していない場合には、よりかさなシーケンス番号の提案を受け入れないことを約束（promise）します
- このアクセプタがすでに他の提案を受け入れ済みか、つまりAccept!(m, v_accepted) メッセージを受信している場合には、Promise(m, v_accepted) メッセージで応答して、シーケンス番号mの投票を返します（すでに受け入れ済みであることをプロポーザーに通知します）
- このアクセプタがすでにPrepareの要求に対してより大きなシーケンス番号で応答済みである場合には、より大きな番号の提案の存在についてプロポーザーに通知します
- アクセプタは、最終のPrepareの要求が大きなシーケンス番号を持つ場合に限り、複数のPrepareの要求に応答できます

#### レプリケーションフェーズ（Replication Phase）

4. **レプリケーションフェーズにおいて、プロポーザーは、過半数の投票を収集した後でレプリケーションを開始できます**: この場合には、値xでcollect実行可能がすべてあるAccept!(n, v) メッセージを送ってアクセプタに送信することができますvは、アクセプタから受け入れられた応答のIDE等が分もっとも大きな提案に関連付けられた値ですが、受け入れ済みの占い提案がない場合には、プロポーサー独自の任意の値になります
5. **アクセプタは、レプリケーションフェーズにおいてまだPrepare(m)に応答していない場合に、番号がxである提案を受け取ります**: この場合のmはよりきな番号です。アクセプタが提案を拒否する場合には、そのことをプロポーザーに通知するために、要求とともに、それまでに確認したもっとも大きなシーケンス番号を送信します。このシーケンス番号は、プロポーザーがアクセプタに追いつくのを助けるためのものです

### 障害シナリオ

#### シナリオ1: プロポーザーに障害が発生した後、新しい値に決定

アルゴリズムの状態は、複数のノードにレプリケートされるので、プロポーザーの障害は、合意に達することに対する失敗にはなりません。

- **プロポーザーP₁は、提案番号1をもって通過フェーズを通過しますが、値v₁をアクセプタA₁にのみ送信した後に障害が発生しました**: A₁において、提案を受け入れれたが後、その値についての次のプロポーザーに通知できる前に、障害が発生します
- **P₁に障害が発生した後、プロポーザーP₂がラウンドを開始し、A₁とはかかわらずに、処理を続行して自分の値をコミットします**

#### シナリオ2: プロポーザーに障害が発生し、以後は提案を破棄

もう1つの障害シナリオは、2つ以上のプロポーザーが競争を始める場合です。それぞれが提案フェーズを通過しようとしますが、他のプロポーザーが先を継続することに気付くことができます：

- **アクセプタA₁のみが値v₁を受け入れられた後で、プロポーザーP₁に障害が発生します**: A₁において、提案を受け入れられたすぐ後、その値についての次のプロポーザーに通知できる前に、障害が発生します
- **別のプロポーザーP₂がより大きな提案番号2をもって新しいラウンドを開始し、クオラムを満たすアクセプタの応答を収集します**: ただし、今回は最初にA₂とA₃が応答します。P₂は、クオラムを収集した後で、通過には注コミット済みの別の値ではなくに存在しているにもかかわらず、自分の値をコミットします
- **このラウンドの後、A₂にかかわるラウンドを開始するすべてのプロポーザーは、A₁の値を無視して、新しく受け入れられた提案を追択します**

もう1つの障害シナリオは、さらにもう1つあります：

- **アクセプタA₁のみが値V₁を受け入れられた後で、プロポーザーP₁に障害が発生します**: A₁において、提案を受け入れられたすぐ後、その値についての次のプロポーザーに通知できる前に、障害が発生します
- **P₁に障害が発生した後、プロポーザーP₂がラウンドを開始し、A₁とはかかわらずに、処理を続行して自分の値をコミットします**
- **このラウンドの後、A₂にかかわるラウンドを開始するすべてのプロポーザーは、A₁の値を無視して、新しく受け入れられた提案を追択します**

### Multi-Paxos

クラシックなPaxosのアルゴリズムについて議論してきました。このアルゴリズムでは、任意のプロポーザーを取りあげてPaxosラウンドの開始を試みました：

- **システム内でレプリケーションフェーズが発生するため**に提案フェーズが必要になることです
- **ラウンドのプロポーサーは、過半数のアクセプタがプロポーザーのPrepareに対してそれぞれの提案を確立された後でのみ開始できます**: 提案フェーズの締り送しを避け、プロポーザーがその認められた地位を再使用するものとして、Multi-Paxosがあります

**Multi-Paxosがあります**: そこではリーダーの障害分離と区別されたプロポーザーとして選書大きされています：

#### リーダー設置の利点

- リーダーを確立した場合には、提案フェーズを省略して直接レプリケーションに進み、値の配信とアクセプタの確認応答の取敢を行うことができます
- すべての値を収集するPaxosラウンドを実行することで、読み取りを実装できます。これを行わなければならないのは、最後に認知されていたプロポーザーが、最新のデータを保持していることが保証されないからです
- 相似した状況が、Multi-Paxosでも発生する可能性があります: 認知されたリーダーから読み取りを実行しようとし、それがすでに別のリーダーが選出された後の場合、古いデータを戻すことになり、そのデータは、合意の機械化可能性の保証と矛盾します

### Fast Paxos

クラシックなPaxosのアルゴリズムに対して、ラウンドトリップの回数を1回減らせる方法があります：

- **任意のプロセス数では なく、任意のプロポーザーを直接アクセプタに接続させる**という方法です
- このためには、クラシックなPaxosでは f + 1であるクオラムのサイズを、2f + 1に増加させる必要があります（この場合のfは、許容できる障害プロセス数です）
- さらに、アクセプタの合計数を3f + 1に増やします。この統治化は、Fast Paxosと呼ばれます

**Fast Paxosでは、ラウンドに2つのタイプがあります**:

- **1つはclassic**で、この場合にはクラシックなPaxosと同じ方法でアルゴリズムは処理を進めます
- **もう1つはfast**で、こちらでは、アクセプタが他の値を受け取ることを許容します

### Egalitarian Paxos（EPaxos）

特定のプロポーザーをリーダーとして使用すると、システムで障害が発生しやすくなる傾向があります：

- **リーダーに障害が発生したら、すぐにシステムは新しいリーダーを選出する必要があります**: そのままでは次のステップに進めないからです
- **もう1つの問題は、リーダーを使用すると、そこに過度に大きな負担をかけることになり、システムのパフォーマンスを損なわないことです**

EPaxosは、パーティショニングです。多くのパーティションが小さなグループに分離して、システムの一部が特定の範囲の担当しているところは、それを用途による（パーティション内に限閉線、システムの他の部分が広範する役割に比較して、システム全体の負荷を軽減しますら、また障害の（パーティションの鋭を増やすことでシステムをスケールできるため）、およびスケーラビリティ（パーティションの数を増やすことでシステムをスケールできるため）の同じに有効です。

**EPaxosの主な特徴**:

#### 依存関係（Dependencies）

現在の提案と干渉する可能性がありますが、すでにコミットされているとは限らない、すべてのコマンドです。

#### シーケンス番号

これは、依存関係間のサイクルを断ち切ります。最高の依存関係のシーケンス番号より大きな値を設定します。

### Flexible Paxos

クオラムの背景ももう少し深堀してあるると定義されます：

- **実行のステップごとに、サーバーの過半数に接続する必要があるでしょうか**
- **すべてのクオラムに共通部分は必要ですか**: 別の言い方をすれば、特定のプロポーザーを選択するために使用するクオラム（第1フェーズ）、値を決定するために使用するクオラム（第2フェーズ）、およびすべての実行インスタンス、たとえば、第2ステップの複数のインスタンスが並行して実行される場合は、共通するノードを持つ必要があるでしょうか

---

## Raft

Paxosは、10年以上に渡って合意アルゴリズムの定番でした。しかし、分散システムのコミュニティでは、論理的な説明が複雑なものとして知られてきました。2013年にRaftと呼ばれる新しいアルゴリズムが登場しました：

- **"In Search of an Understandable Consensus Algorithm"（理解可能な合意アルゴリズムを求めて）**というタイトルの論文で知られています
- 分散システムには「分すぎるほどの固有の複雑性が存在する」ので、よりシンプルなアルゴリズムの存在は望ましいことです

### Raftの参加ノード

Raftにおける参加ノードは、以下3つの役割のいずれかとなります：

#### 候補者（Candidate）

リーダーシップが一時的な状態であり、どの参加ノードもこの役割を担うことができます。ノードはリーダーになるために、最初に候補者の状態に移行して、過半数の投票を集めようとします。

#### リーダー（Leader）

クライアントの要求を処理し、レプリケートされたステートマシンと取り出りする、現在の一時的なクラスタリーダー。リーサーに選出されると、任期（term）と呼ばれる期間に渡ってその役割を果たします。

#### フォロワー（Follower）

ログエントリを永続化し、リーダーと候補者からの要求に応じる受動的な参加ノードです。Raftにおけるフォロワーは、Paxosのアクセプタおよびラーナーと類似した役割です。

### Raftのリーダーの役割

クロックの同期に依存せずにフォロワーが定主権を保証するために、時間を任期（エポックとも呼ばれます）に分割します：

- **その期間内にリーダーは1つだけであり、変わりません**: 任期は選出と呼ばれる番号が付けられ、各コマンドは、任期の番号とその任期内のメッセージ番号によって、一意に識別されます

**リーダー選出**:

- 候補者P1は、他のプロセスにRequestVoteメッセージを送信します: このメッセージには、候補者の任期、候補者が認識している最後の任期、および候補した最新のログエントリのIDが含まれます
- 過半数の投票を集めるため後で、候補者はその任期のリーダーとして選出されます。各プロセスがその投票を送信する候補者は、最大1つです

**定期的なハートビート**:

- このフィールドは、参加ノードの生存を確認するために、ハートビートの仕組みを使用します
- リーダーはすべてのフォロワーに定期的にハートビートを送信して、その任期を維持します
- 選出のタイムアウトと呼ばれる期間が過ぎても新しいハートビートがフォロワーに届かない場合には、リーダーに障害が発生したとみなされ、新しい選出が開始されます

### 障害シナリオ

複数のフォロワーが候補者となり、いずれも候補者の投票を収集できない場合、その状況は膠着状態と呼ばれます：

- Raftでは、ランダムなタイマーを使用して、後続の親数のリーダーの選出が票割れすることを減らしています
- つまり、候補者のうちの1つは、次の選出ラウンドを早期に開始するため、そのプロセスが終了してしまう場合を除き、最終的には親裁を集めることができます

**リーダーによレプリケートされたエントリは一意に識別されるので、メッセージの配信を続ける必要があります**:

- フォロワーは、Appendメッセージを受け取りることによって、レプリケートされたログに新しい値を繰り返し追証できます
- そのメッセージに含まれるのは、リーダーの任期、インデックス、および現在送信している任期の直前のログエントリの任期、さらに格納すべき1つ以上のエントリです

### Raftの特徴

| 項目 | 説明 |
|------|------|
| **ログのレプリケーション** | リーダー選出、ロールバック不要 |
| **リーダーシップ** | 強いリーダー、すべての操作がリーダー経由 |
| **メンバーシップ変更** | ジョイント合意によるクラスタ構成変更 |
| **安全性** | 選出制約（最新ログを持つノードのみリーダーになれる） |

---

## ビザンチン合意

ここまで検討してきた合意アルゴリズムでは、そのすべてにおいて非ビザンチン障害（p.199「8.7.3 任意障害」）を前提にしています。言い換えれば、ノードはアルゴリズムを誠実に実行します。それを不当に利用したり、結果を偽造したりすることはしません。

これから実際に確認するように、この前提に基づけば、利用可能な参加ノードの数を減らし、コミットに必要なラウンドトリップを少なくしても、合意を達成することが可能になります。

### Practical Byzantine Fault Tolerance（PBFT）

PBFTが安全性と活性の両方を保証するために障害があってもも許容されるレプリカの数は、(n - 1)/3のみです（この場合のnは、参加ノードの合計数です）：

- **システムがf個の障害ノードを許容するためには、少なくとも3f+1のノードが必要になります**: なぜなら、読み取りのみのノードが複数に同意する必要があるからです
- **fのレプリカには障害があるかもしれず、さらにに応答していないが障害があるわけではない（たとえば、ネットワーク分断や遅護の障害、メンテナンス等が関係かもしれません）fのレプリカが存在するかもしれません**
- **アルゴリズムは、障害のないレプリカから十分な数の応答を収集して、障害のあるレプリカからの応答の数を検査として上回ることができなければなりません**

### PBFTプロトコル

クラスタ構成を区別するために、PBFTではビューを使用します：

- **それぞれのビューでは、レプリカ群から1つのプライマリが選出されます**: すべてのノードにはビューIDそれぞれ値が割りし当てられ、プライマリのインデックスリストv mod Nになります（この場合のvはビューIDであり、N岸現在の障害においるノード数です）
- **ビューは、プライマリに障害が発生した場合に変更されます**: クライアントは、その執行をプライマリに対して実行します

#### Pre-Prepare

プライマリでは、ビューID、単調に増加する一意のID、ペイロード（クライアント要求）、およびペイロードのダイジェストを含むメッセージをブロードキャストします。

#### Prepare

バックアップは、Pre-Prepareのメッセージを受け取ると、PrepareフェーズK入り、Prepareメッセージを、他のすべてのレプリカ（プライマリも含まれます）に対してブロードキャストします。

#### Commit

次に、バックアップはCommitフェーズに進みます。このフェーズでは、Commitメッセージを他のすべてのレプリカにブロードキャストし、2f + 1の一致するCommitメッセージを、場合によっては自身のメッセージも含めて他の参加ノードから収集するのを待ちます。

### リカバリとチェックポイント

レプリカでは、受け入れたメッセージを永続的にログに保存します：

- **すべてのメッセージは、少なくともf + 1のノードで実行されるまで保持しておく必要があります**: このログは、ネットワーク分断が発生した場合、他のレプリカが期限までる状態にあるノースからきていることを保証するために使用されます
- **N個の要求の後（この場合のNは設定可能な定数です）、プライマリが安定的なチェックポイントを行います**: このチェックポイントの際に、状態に反映された最新の要求のシーケンス番号を持ちます

---

## 合意アルゴリズムの比較

| アルゴリズム | メッセージ複雑度 | リーダー必要性 | 耐障害性 | ビザンチン耐性 | 特徴 |
|------------|----------------|-------------|---------|--------------|------|
| **Paxos** | O(n²) | 任意（Multi-Paxosではリーダー） | f < n/2 | なし | 理論的基盤、柔軟性高い |
| **Multi-Paxos** | O(n) | あり | f < n/2 | なし | リーダー最適化、広く採用 |
| **Fast Paxos** | O(n²) | なし（衝突時はリーダー） | f < n/3（fast）<br>f < n/2（classic） | なし | レイテンシ削減、トレードオフあり |
| **EPaxos** | O(n²) | なし | f < n/2 | なし | 分散負荷、コマンド依存関係 |
| **Flexible Paxos** | 可変 | 任意 | クオラム設定次第 | なし | クオラム柔軟性 |
| **ZAB** | O(n) | あり | f < n/2 | なし | Zookeeper専用、順序保証 |
| **Raft** | O(n) | あり | f < n/2 | なし | 理解容易、強いリーダー |
| **PBFT** | O(n²) | あり（プライマリ） | f < n/3 | あり | ビザンチン耐性、3フェーズ |

---

## 実装時の注意点

### Paxos/Multi-Paxos

- **提案番号の生成**: 単調増加かつユニークな番号（タイムスタンプ + ノードIDなど）
- **状態の永続化**: 提案番号、受け入れた値、投票状況をログに記録
- **リーダー選出（Multi-Paxos）**: タイムアウトベースのリース機構
- **ログ圧縮**: スナップショット機構で古いエントリを削除

### Raft

- **ログのインデックス管理**: 任期番号とインデックスの組み合わせ
- **選出タイムアウト**: ランダム化で膠着状態を回避（150-300msなど）
- **コミット判定**: 過半数が複製した後、現在の任期のエントリのみコミット
- **メンバーシップ変更**: ジョイント合意またはシングルサーバー変更

### PBFT

- **ビュー変更**: プライマリ障害時のタイムアウトとビュー切り替え
- **チェックポイント**: 定期的な状態スナップショットとログ圧縮
- **認証**: メッセージ認証コード（MAC）またはデジタル署名
- **クライアント再送**: タイムアウトとリトライロジック

---

## 代表的な実装例

| システム | 採用アルゴリズム | 特徴 |
|---------|----------------|------|
| **Apache Zookeeper** | ZAB | 階層型KVストア、設定管理 |
| **etcd** | Raft | Kubernetes設定ストア、高可用性 |
| **Consul** | Raft | サービスディスカバリ、KVストア |
| **CockroachDB** | Raft（Multi-Raft） | 分散SQL、範囲ごとにRaftグループ |
| **TiKV** | Raft（Multi-Raft） | 分散KVストア、TiDB基盤 |
| **Cassandra** | なし（Gossip + Quorum） | 合意なし、最終的整合性 |
| **Spanner** | Paxos（Multi-Paxos） | グローバル分散、TrueTime |
| **Chubby（Google）** | Paxos | ロックサービス、Google内部 |
| **Hyperledger Fabric** | PBFT変種 | ブロックチェーン、許可型台帳 |

---

## まとめ

合意アルゴリズムは、分散システムにおいてもっとも興味深く、もっとも複雑なテーマの1つです。過去数年の間に、新しいアルゴリズムが登場し、さらに既有のアルゴリズムについても多くの実装が行なわれてきました。この章を見てしも、このテーマの重要性と人気が高まっていることは明白です。

この章では、クラシックなPaxosのアルゴリズムについて検討し、さらにPaxosの亜種をいくつか説明して、以下に示すように、それぞれが異なる特性を改善していることを確認してきました：

#### Multi-Paxos

プロポーザーがその役割にとどまり、1つだけではなく複数の値をレプリケートすることを可能にします。

#### Fast Paxos

確立されたリーダー以外のプロポーザーから受け取ったメッセージの処理をアクセプタが進められるときに、fastラウンドを使用してメッセージの数を削減できます。

#### EPaxos

送信されたメッセージ間の依存関係を解決することでイベントの順序を確立します。

#### Flexible Paxos

クオラムの要件を緩和します。第1フェーズ（投票）のクオラムは、第2（レプリケーション）のクオラムとの共通部分があればよいです。

Raftは、合意の説明に使用される言い調しを単純化し、リーダーシップをアルゴリズムにおける特筆すべき存在として扱います。Raftは、ログのレプリケーション、リーダー選出、および安全性を離してしまう重要です。

最後に合意された環境において合意の安全性を保証するには、ビザンチン障害でのフォールトトレランスを持つアルゴリズムを使用する必要があります。その例の1つがPBFTです。PBFTでは、参加ノードが相互の応答に対してクロスバリデーションを行い、規定されたアルゴリズムのルールに従うノードが十分に存在するとき成の、実行ステップの進展を進めます。
