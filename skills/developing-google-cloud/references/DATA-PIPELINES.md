# データパイプライン設計リファレンス

Google Cloudにおけるデータパイプラインの計画・設計・実装の包括的ガイド。

---

## データパイプラインの基本概念

### データパイプラインとは

データパイプラインは、データをソースから宛先に移動し、変換を適用しながら使いやすく関連性の高いデータに整形する自動化ワークフローです。以下のプロセスを包含します:

- **データインジェスション**: 生データの取り込み
- **データ変換**: クレンジング・エンリッチメント・構造化
- **データストレージ**: 最終目的地への保存

データパイプラインの主な目的は、クリーンで信頼性が高く実用的なデータをエンドユーザーや下流システムに提供することです。

### データエンジニアの責務

データエンジニアはパイプラインの設計者であり、以下の責務を担います:

| 責務 | 内容 |
|------|------|
| **パイプライン設計** | データインジェスション・変換・保存のシームレスなワークフローを開発 |
| **データ品質保証** | 生データを使用可能な状態に変換し、一貫性・正確性・信頼性を確保 |
| **スケーラビリティと最適化** | データ量の増加に対応しつつパフォーマンスとコストを最適化 |
| **モニタリングと自動化** | パイプラインの監視プロセスを実装し、反復タスクを自動化 |
| **セキュリティとコンプライアンス** | セキュリティ・プライバシー・規制遵守を通じたデータガバナンス管理 |

---

## コアコンポーネント

### データソース

生データの発生源:

- **Cloud Storage**: 非構造化データ用
- **Pub/Sub**: イベント駆動型データストリーム用
- **Cloud SQL / Spanner**: リレーショナルデータ、グローバル分散アプリケーション用
- **API**: サードパーティデータ入力
- **ログ**: サーバーログ、アプリケーションログ

### インジェスションツール

ソースからデータを取り込むツール:

- **Datastream**: リアルタイムデータベースレプリケーション
- **Storage Transfer Service**: スケジュール転送、クラウド間転送
- **`bq` CLI**: BigQuery へのコマンドライン転送

### ステージングエリア

取り込んだデータを一時保存し、変換エンジンによる効率的な処理を可能にする中間ストレージ:

- **Cloud Storage**: 生データ、半構造化データ
- **BigQuery ステージングテーブル**: SQL変換前の一時テーブル

### 変換エンジン

データに対してフィルタリング・集約・エンリッチメントなどの操作を適用:

- **Dataflow**: バッチおよびストリーム処理（Apache Beam）
- **Dataproc**: Hadoop および Spark ベースの変換
- **Data Fusion**: ノーコード/ローコード ETL

### データシンク

処理済みデータの最終目的地:

- **BigQuery**: 分析クエリ用のサーバーレスデータウェアハウス
- **Bigtable**: 低レイテンシトランザクションデータ用 NoSQL
- **Cloud Storage**: データレイク、長期保存
- **Dataplex**: 論理的なデータガバナンスレイヤー（BigQuery Dataset、Cloud Storage Bucket をサポート）

### オーケストレーションとスケジューリング

パイプライン内のタスク実行を調整し、依存関係を管理:

- **Cloud Composer**: Apache Airflow ベースのワークフローオーケストレーション

---

## パイプラインタイプ

### バッチパイプライン vs ストリーミングパイプライン

| 要素 | バッチ処理 | ストリーミング処理 |
|------|-----------|-------------------|
| **データ量** | 大規模データセットをチャンクで処理 | 小規模で連続的なデータストリーム |
| **データベロシティ** | 低速、時間経過で蓄積されるデータ | 高速、リアルタイムデータ |
| **データ完全性** | 完全なデータセット（静止データ）を処理 | 到着時にデータを処理（不完全でも可） |
| **レイテンシ要件** | 即座の結果が不要なユースケース | 即座またはニアリアルタイムのアクションが必要 |
| **データタイプ** | 構造化・半構造化データを効率的に処理 | センサー読取値など時間に敏感なデータ |
| **ツール** | Dataproc（バッチジョブ）、BigQuery | Pub/Sub、Dataflow（ストリーム） |
| **アプリケーション例** | 財務レポート、定期分析、バッチETL | 不正検知、IoTモニタリング、リアルタイムダッシュボード |

### 選択基準

- **バッチ**: 大量データ、即時処理不要、定期的な集約・レポート生成
- **ストリーミング**: リアルタイム分析、イベント駆動アーキテクチャ、継続的データフロー

---

## 主要パイプラインパターン

### EL (Extract and Load)

**概要**: データをソースから抽出し、ストレージシステム（データレイク等）に直接ロード。変換は後回し。

**ユースケース**:
- 探索的分析のために生データを保持する必要がある場合
- 変換を後のステージに延期できる場合

**ツール**: Datastream、BigQuery Data Transfer Service、`bq` CLI

**例**: サーバーログを分散環境から JSON/CSV 形式で抽出し、Cloud Storage バケットに直接ロード。

---

### ELT (Extract, Load, and Transform)

**概要**: 生データを先にデータウェアハウス（BigQuery等）にロードし、ウェアハウス内で変換を実行。

**ユースケース**:
- データウェアハウスの計算能力を活用して大規模変換を処理
- ロード後の変換によりデータ処理を簡素化
- 構造化データの分析とレポート作成

**ツール**: BigQuery SQL スクリプト、Dataform、Jupyter Notebooks

**例**: CloudSQL からデータを抽出し、BigQuery のステージングテーブルにロード後、SQL で結合・フィルタリング・集約を実行。

---

### ETL (Extract, Transform, and Load)

**概要**: データをターゲットシステムに到達する前に、転送中に変換。

**ユースケース**:
- データクレンジング・エンリッチメント・前処理が保存前に必要
- 複雑な変換ニーズ（バッチまたはリアルタイム処理）
- リアルタイム不正検知、機械学習モデル適用

**ツール**: Dataproc、Dataflow、Dataprep

**例**: Pub/Sub からトランザクションデータをストリーミング抽出し、Dataflow の Apache Beam パイプラインでリアルタイム変換（形式標準化、外部 API によるエンリッチメント、機械学習モデル適用）し、Bigtable または BigQuery にロード。

---

### パターン比較テーブル

| 要素 | EL | ELT | ETL |
|------|----|----|-----|
| **変換の複雑さ** | 変換不要、生データ保持 | ロード後の単純なSQL変換 | 複雑または保存前の変換が必要 |
| **データ量・ベロシティ** | バッチパイプライン、大規模データセット向き | データウェアハウスでのバッチ処理に最適 | リアルタイムまたは高速ストリーミングデータに最適 |
| **ストレージ要件** | データレイクに生データ保存 | ウェアハウス内で構造化変換 | 保存前に中間処理 |
| **ツールとプラットフォーム** | Cloud Storage、BigQuery Data Transfer Service | BigQuery、Dataform | Dataflow、Dataproc |
| **レイテンシ・パフォーマンス** | 緊急でない定期処理向き | 遅延可能でスケーラブルな変換向き | 低レイテンシ、リアルタイム変換向き |
| **規制・コンプライアンス** | 最小限のコンプライアンス要件 | ウェアハウス内でロード後にコンプライアンス処理 | 保存前のマスキングとデータ品質制御 |
| **コスト・リソース最適化** | 最小限の処理コスト | 変換コストをターゲットシステムで管理 | 中間処理により高コスト |

---

### パターン選択フロー

```
データ変換が必要か？
  ├─ No → EL
  │
  └─ Yes
      ├─ 変換はシンプルで保存後に実行可能か？
      │   └─ Yes → ELT
      │
      └─ 複雑な変換または保存前の処理が必要か？
          └─ Yes → ETL
```

---

## パイプラインアーキテクチャ設計

### 論理設計 vs プラットフォーム設計

#### 論理設計

データをソースからターゲットに処理するために必要なステップと変換を定義:

- 抽出・クレンジング・変換・ロードプロセスのデータフローを明確に理解
- プラットフォーム非依存の一貫性を確保
- モジュール化された簡潔な表現で、コラボレーションとデバッグを簡素化

#### プラットフォーム設計

特定環境（Google Cloud等）のツールとサービスを使用して論理設計を実装:

- スケーラビリティ・パフォーマンス最適化・コスト考慮などのプラットフォーム固有機能と整合
- 特定ワークロード要件に合わせたツール選択（Dataflow、Dataproc等）
- リソース割り当てとスケーラビリティを組織のデータ量とパフォーマンスニーズに整合

---

### データ特性に基づく設計

#### Volume（量）・Velocity（速度）・Variety（多様性）

| データ特性 | 設計考慮事項 |
|-----------|-------------|
| **Volume（量）** | 大量データはバッチ処理、小規模連続ストリームはストリーミング処理 |
| **Velocity（速度）** | 低速（蓄積型）はバッチ、高速（リアルタイム）はストリーミング |
| **Variety（多様性）** | 構造化データ（スキーマ・クエリ最適化）、非構造化データ（特殊処理）、時系列データ（パターン分析） |

---

## アーキテクチャ例

### データウェアハウスパイプライン

**コンポーネント**:

1. **抽出**: リレーショナルデータベース、API、ファイルシステムからデータ抽出
2. **ステージング**: Cloud Storage またはBigQuery に生データをロード
3. **変換**: SQL スクリプト、Dataflow、Dataform で生データをクレンジング・標準化・スキーマ適合（重複排除、集約、型変換、ビジネスロジック適用）
4. **ロード**: BigQuery の本番テーブルに変換済みデータをロード（BIツールでのクエリ・分析用に最適化）

**例**: 小売企業が CRM、在庫管理、販売システムからデータを収集し、BigQuery のステージングテーブルにロード後、SQL で結合・クレンジングし、レポート・分析用の本番テーブルに保存。

---

### データレイクパイプライン

**コンポーネント**:

1. **インジェスション**: IoTデバイス、ログ、外部APIから多様なデータを収集し、Cloud Storage に取り込み
2. **ストレージ**: JSON、CSV、Avro、Parquet 等の形式でデータレイクに保存（Cloud Storage は大量データの耐久性とスケーラビリティを提供）
3. **処理**: Dataflow または Dataproc で生データを処理・変換（クレンジング・正規化・エンリッチメント）
4. **利用**: 処理済みデータを機械学習モデル訓練、探索的分析、BIに活用

**例**: テクノロジー企業がウェブサイトクリックストリームやサーバーログを Cloud Storage に取り込み、Dataflow で構造化データセット生成後、BigQuery で分析または Looker Studio で可視化。

---

### データウェアハウス vs データレイク比較

| 特性 | データウェアハウスパイプライン | データレイクパイプライン |
|------|-------------------------------|-------------------------|
| **データタイプ** | 構造化データ | 構造化・半構造化・非構造化データ |
| **目的** | 分析・レポート用に最適化 | 生データの柔軟なストレージと多様なユースケース |
| **変換タイミング** | 通常ロード後（ELT） | ユースケースに応じて保存前または保存後 |
| **ツール** | BigQuery、Dataform、SQL スクリプト | Cloud Storage、Dataflow、Dataproc |
| **ストレージ形式** | 分析用最適化テーブル | 元の形式（JSON、Parquet等） |

---

### 機械学習パイプライン

**コンポーネント**:

1. **前処理**: Dataflow で生データをクレンジング・準備（欠損値処理、数値特徴量スケーリング、カテゴリ変数エンコーディング）
2. **特徴エンジニアリング**: 前処理済みデータから特徴量を抽出・作成（時系列データの集約、ユーザー行動スコア等のドメイン固有特徴量）
3. **モデル訓練**: TensorFlow、PyTorch 等で訓練。Vertex AI でハイパーパラメータチューニング・モデル評価・実験管理を統合。Feature Store またはダイレクトパイプラインにより、訓練と推論間で一貫した特徴量の利用を確保
4. **デプロイ**: Vertex AI でモデルをエンドポイントにデプロイし、リアルタイム予測またはバッチスコアリング。予測結果を BigQuery に保存して下流分析に活用

**例**: eコマース企業が製品推奨MLパイプラインを実装。Dataflow でユーザー行動データ（購買履歴、閲覧パターン）を前処理し、Vertex AI で推奨モデルを訓練・デプロイし、パーソナライズされた提案を提供。

---

## パイプライン計画

### データソース・シンクの特定

**データソース**:
- Cloud Storage（非構造化データステージング）
- Pub/Sub（リアルタイムメッセージング）
- Cloud SQL（リレーショナルDB）
- Spanner（グローバル分散DB）
- サードパーティ API

**データシンク**:
- BigQuery（分析ワークロード）
- Bigtable（低レイテンシ NoSQL）
- Cloud Storage（データレイク）
- Dataplex（論理的ガバナンスレイヤー）

### 変換ロジックの定義

適切なパターン（EL / ELT / ETL）を選択:

- データ複雑性
- 変換ニーズ
- レイテンシ要件

### ネットワーク考慮事項

- **帯域幅**: 大規模データ転送に十分な帯域幅
- **ルーティング**: リージョナルPoPを経由したエッジ接続の最適化
- **VPC（Virtual Private Cloud）**: クラウド内で分離されたネットワーキングリソースを提供する仮想化ネットワーク環境。サブネットワーク作成、IPアドレス範囲定義、リソース間通信制御が可能で、Google Cloud ネットワーキングの基盤となる
- **Private Google Access**: 外部IPアドレスを持たない VM インスタンスが Google API やサービスにアクセスできる機能。パブリックインターネットを経由せずに Google サービスにアクセスでき、セキュリティ向上とエグレス料金の削減に寄与

### セキュリティ

| セキュリティ対策 | 実装方法 |
|----------------|----------|
| **暗号化（転送中）** | TLS |
| **暗号化（保存時）** | Google管理またはCMEK（顧客管理暗号化キー） |
| **アクセス制御** | IAM（ロールベース）、ACL（Cloud Storage の細かい設定） |
| **機密情報保護** | DLP API（検出・マスキング） |
| **監視・脅威検出** | Cloud Audit Logs、Security Command Center（SCC） |

#### Cloud Audit Logs の種類

| ログ種別 | 内容 |
|---------|------|
| **Admin Activity Logs** | リソース設定を変更する操作を記録 |
| **Data Access Logs** | ユーザー提供のリソースデータを読み書きする API コールを記録 |
| **System Event Logs** | Google システムの管理アクションを記録 |
| **Policy Denied Logs** | ポリシー違反によるアクセス拒否を記録 |

#### Security Command Center（SCC）

Google Cloud の一元的セキュリティ管理プラットフォーム。組織のクラウド資産に対する包括的な可視性を提供し、脅威検出・セキュリティリスク管理を支援:

- **継続的モニタリング**: クラウド資産の常時監視
- **脆弱性スキャン**: セキュリティ脆弱性の自動検出
- **コンプライアンスレポーティング**: 規制準拠状況の報告

---

## GCPツール選択ガイド

### Dataflow vs Dataproc vs Cloud Data Fusion vs Cloud Data Prep

| ツール | 適用ケース | 主な特徴 |
|--------|-----------|---------|
| **Dataflow** | バッチ・ストリーム統合処理、リアルタイムパイプライン | Apache Beam、サーバーレス、オートスケール、統合バッチ/ストリーム処理 |
| **Dataproc** | Hadoop/Spark ワークロード、複雑なバッチ変換、MLデータ前処理 | マネージド Hadoop/Spark、エフェメラルクラスタ、BigQuery/Bigtable統合 |
| **Cloud Data Fusion** | ノーコード/ローコード ETL、ビジュアルパイプライン構築 | グラフィカルUI、プリビルドコネクタ、データ統合の簡素化 |
| **Cloud Data Prep** | インタラクティブなデータ探索・クレンジング | ビジュアルインターフェース、自動データ品質推奨、探索的データ準備 |

### 選択基準

```
リアルタイム処理が必要か？
  └─ Yes → Dataflow

既存の Hadoop/Spark コードベースがあるか？
  └─ Yes → Dataproc

ノーコード/ローコードのビジュアル設計を希望か？
  └─ Yes → Cloud Data Fusion

インタラクティブなデータ探索・クレンジングが必要か？
  └─ Yes → Cloud Data Prep
```

---

## Dataflow パイプライン計画

### 主な特徴

- **サーバーレス**: インフラ管理不要
- **オートスケール**: ワークロードに応じた自動スケーリング
- **Apache Beam**: バッチ・ストリーム統合プログラミングモデル
- **Dataflow テンプレート**: 再利用可能なパイプラインテンプレートにより、デプロイとパラメータ化を簡素化。異なるユースケースへの迅速な展開が可能

### 重要な考慮事項

| 考慮事項 | 詳細 |
|---------|------|
| **ウィンドウとトリガー** | ストリーミングデータのウィンドウとトリガー管理 |
| **パフォーマンス最適化** | Dataflow モニタリングツールでパイプライン最適化 |
| **データセキュリティ** | 暗号化（転送中・保存時）、IAM ポリシー |

### ネットワーク設定

- **プライベートIP**: VPC 内でワーカーを分離（セキュリティ向上）
- **パブリックIP無効化**: 外部リソースへのアクセス防止、VPC外からのワーカーアクセス制限
- **Private Google Access**: パブリックIP無効化時に必須（ワーカーがGoogle APIにアクセス可能）

### セキュリティ

- **暗号化**: 転送中・保存時の自動暗号化（Google管理キー）。CMEK 設定可能
- **IAM**: 最小権限原則とロールベースアクセス制御（例: `roles/dataflow.worker`、`roles/dataflow.developer`）

---

## Dataproc パイプライン計画

### 主な特徴

- **マネージド Hadoop/Spark**: オープンソースフレームワークに慣れた組織向け
- **クラスタ構成**: エフェメラルクラスタ（コスト効率）、オートスケールクラスタ（ワークロード適応）
- **Dataproc Serverless**: クラスタインフラ管理不要（Spark ワークロード簡素化）

### 適用ユースケース

- 複雑なデータ変換（ML前処理）
- データレイク管理
- バッチ ETL 処理

### 重要な考慮事項

| 考慮事項 | 詳細 |
|---------|------|
| **ジョブ依存関係** | ワークフローテンプレートで複数ステップパイプラインのオーケストレーション |
| **リソース最適化** | リソース使用の最適化 |
| **ログとモニタリング** | Dataproc のログ・モニタリング機能でパイプライン信頼性確保 |

### ネットワーク設定

- **VPC とプライベートIP**: クラスタをパブリックインターネットから分離
- **インターネットアクセス**: Dataproc VM は Dataproc Control API との通信のためインターネットアクセスが必要
- **ファイアウォールルール**: 必要なサービスのみにインバウンド・アウトバウンドトラフィックを制限
- **VPN/Interconnect**: ハイブリッド・マルチクラウド環境でオンプレミスリソースと安全に接続
- **SSH アクセス制限**: 本番環境では完全に無効化を検討

### セキュリティ

- **IAM**: 最小権限原則、事前定義ロール・カスタムロールで異なるクラスタのアクセス分離
- **Hadoop Secure Mode**: クラスタコンポーネントと外部サービス間の通信暗号化

---

## まとめ

効果的なデータパイプライン計画は以下の要素で構成されます:

1. **データソース・シンクの特定**: データの起点と終点を明確化
2. **変換ロジックの定義**: 適切なパターン（EL / ELT / ETL）選択
3. **ネットワーク考慮**: 帯域幅、ルーティング、セキュアな接続
4. **セキュリティ対策**: 暗号化、アクセス制御、監視

これらの要素を慎重に設計することで、堅牢でセキュアかつビジネス目標と整合したデータパイプラインを構築できます。
