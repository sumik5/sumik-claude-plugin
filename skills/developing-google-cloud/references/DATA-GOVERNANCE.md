# データガバナンス・処理設計リファレンス

データ処理システムの柔軟性・ポータビリティ・ガバナンスを設計するための実践ガイド。

---

## 1. ビジネス要件からアーキテクチャへのマッピング

### データソースとフォーマット

データは構造化・半構造化・非構造化の3つに分類される:

| 分類 | 特徴 | 例 |
|------|------|-----|
| **構造化データ** | 明確に定義されたスキーマに従う | リレーショナルDBのテーブル |
| **半構造化データ** | 部分的な構造を持つが厳密なスキーマはない | JSON、XML |
| **非構造化データ** | 定義済みの構造を持たない | テキストドキュメント、画像 |

### データ処理要件

| 処理タイプ | 用途 | 例 |
|-----------|------|-----|
| **バッチ処理** | 境界のあるデータセット | 1日分の販売取引を処理 |
| **ストリーム処理** | 境界のないデータセット | センサーデータの連続処理 |

**ツール選択**:
- Dataproc: Hadoop/Sparkジョブのバッチ処理
- Dataflow: バッチ・ストリーミング両方のパイプライン

### データ消費パターン

| パターン | 説明 | 主な利用者 |
|---------|------|-----------|
| **Analytics** | データからインサイトを抽出 | データアナリスト |
| **Machine Learning** | データから学習して予測 | ML エンジニア |
| **Reporting** | データを理解しやすく提示 | ビジネスユーザー |

---

## 2. ストレージ・処理ツール選択マトリクス

### ストレージソリューション選択

| フォーマット ↓ / ユースケース → | Transactional / Operational | Analytical | Staging / ML / Archival |
|--------------------------------|----------------------------|------------|------------------------|
| **非構造化** | ✗ | ✗ | Cloud Storage |
| **半構造化** | Firestore, Memorystore, Bigtable | BigQuery (JSON サポート) | Cloud Storage |
| **構造化** | Cloud SQL | BigQuery | BigQuery, Cloud Storage |

**推奨事項**:
- **非構造化データ（画像等）・低コスト重視**: Cloud Storage
- **構造化データ・低レイテンシ分析**: BigQuery（サーバーレス、自動スケール）
- **トランザクショナルデータ**: Cloud SQL（垂直スケール可能）

### データ処理ツール選択

| 処理タイプ ↓ / 実装方式 → | コードベース | GUI ベース |
|--------------------------|-------------|-----------|
| **バッチ** | Dataproc, Dataflow | Cloud Data Fusion, Cloud Data Prep |
| **ストリーミング** | Dataflow | Cloud Data Fusion |

**ツール特性**:
- **Dataflow**: サーバーレス、自動スケール、Apache Beam 対応
- **Dataproc**: Spark/Hadoop クラスター管理、既存ジョブの移行
- **Cloud Data Fusion**: ビジュアルパイプライン構築、ノーコード
- **Cloud Data Prep**: セルフサービスのデータプロファイリング・クリーニング

---

## 3. サーバーレス vs PaaS スケーラビリティ比較

### Dataflow（サーバーレス）の優位性

| 機能 | PaaS | Dataflow（サーバーレス） |
|------|------|------------------------|
| **スケーリング単位** | インスタンス（VM、コンテナ） | ワーカーインスタンス（細粒度） |
| **スケーリング制御** | 手動設定・定義済みルール | 自動・連続・ワークロード駆動 |
| **スケーリング速度** | 遅い（分単位） | 非常に速い（秒単位） |
| **リソース管理** | ユーザーがインスタンス毎に指定 | インフラ抽象化、自動管理 |
| **粒度** | 粗粒度（インスタンスレベル） | 細粒度（ワークロードレベル） |

### Dataproc Clusters vs Dataproc Serverless

| 機能 | Dataproc Clusters | Dataproc Serverless |
|------|------------------|---------------------|
| **オートスケーリング機構** | ポリシー定義によるワーカーノード追加・削除 | Spark動的リソース割り当て（デフォルト） |
| **スケーリング粒度** | ノードレベル（ワーカーノード単位） | 細粒度（タスク/ステージ単位） |
| **ユーザー設定** | ポリシー定義必須（最小/最大ワーカー数等） | 設定不要（自動管理） |
| **ユースケース** | 長時間稼働・ワークロード変動・制御重視 | バッチ処理・可変リソース要件・シンプル運用 |

### BigQuery の ELT とスロット

- **ELT パラダイム**: Extract → Load → Transform（ストレージ内変換）
- **スロット**: BigQuery の計算単位
- **自動スケーリング**: ワークロード需要に応じて自動的にスロット追加

---

## 4. 柔軟性とポータビリティの設計

### マルチクラウド戦略のメリット

| メリット | 説明 |
|---------|------|
| **ベンダーロックイン回避** | クラウドプロバイダーの切り替え・併用の自由 |
| **サービス最適化** | ワークロード毎にベストなサービスを選択 |
| **レジリエンス向上** | 地理的・プロバイダー多様化によるリスク軽減 |

### Apache Beam: 統一プログラミングモデル

**特徴**:
- **コード一度記述、複数環境実行**: Dataflow、Apache Flink、Apache Spark で同一コード実行可能
- **抽象化レイヤー**: 処理システムの違いを吸収

**主要概念**:
- **PCollection**: パイプライン内のデータ表現
- **PTransform**: データ操作（読み込み、変換、フィルタ、書き込み）

**Portability Framework**:
- **Runner API / Fn API**: SDK と Runner を分離する契約
- **Docker コンテナ化**: 各操作を独立した環境で実行
- **マルチ言語パイプライン**: 異なる言語で書かれた処理を統合（例: Python パイプラインから Java の IO コネクタ利用）

**実行環境切り替え例**:
1. ローカルマシンで Direct Runner を使用して開発・テスト
2. Google Cloud で Dataflow にデプロイ（サーバーレス実行）
3. 別クラウドで Apache Flink/Spark にデプロイ

**Dataflow Runner v2**:
- Apache Beam Portability Framework ベース
- カスタムコンテナ、マルチ言語パイプライン、クロス言語変換をサポート

### オープンソース標準の採用

**データフォーマット**:
- CSV、JSON、Avro、Parquet（広範なツール・システムでサポート）

**処理フレームワーク**:
- **Dataproc**: Spark/Hadoop クラスター（オープンソース Hadoop エコシステム活用）
- **Dataflow**: Apache Beam パイプライン実行

**メリット**:
- **ポータビリティ**: 最小限のコード変更で環境移行
- **柔軟性**: ベンダー固有機能に縛られず、タスク毎に最適ツール選択
- **コスト効率**: ベンダーロックイン回避、競争的価格活用

### Cloud Storage as HCFS

**Hadoop Compatible File System (HCFS)**:
- Cloud Storage は HCFS として機能
- Hadoop/Spark フレームワークが最小限の変更で動作

**統合機能**:
- **IAM**: セキュアなアクセス制御
- **冗長性**: 高可用性・耐久性
- **短期・長期両対応**: ステージング・アーカイブ両用途に最適

---

## 5. データガバナンスフレームワーク

### ガバナンスの4つの柱

| 柱 | 内容 |
|---|------|
| **Data Quality** | データ品質管理 |
| **Data Stewardship** | データ管理責任 |
| **Data Security and Compliance** | セキュリティ・規制遵守 |
| **Data Management** | データライフサイクル管理 |

### データガバナンスポリシー

**定義すべきルール**:
- データアクセス・保存・保持・廃棄の手順
- 機密データ（顧客情報等）の暗号化・PII マスキング
- データ主権規制への対応（地域別ストレージ・アクセス制限）

---

## 6. データカタログとディスカバリ

### メタデータリポジトリの役割

**メタデータリポジトリ**:
- データアセットの構造・ソース・利用状況を記述する情報を集約管理
- 組織全体で正確・一貫性のあるメタデータへのアクセスを提供
- 単一の真実のソース（Single Source of Truth）として機能

**データカタログ**:
- メタデータリポジトリ上に構築
- メタデータをインデックス化し、検索・発見・理解を容易化
- データリネージ、分類、アクセスポリシー、ビジネス定義を管理

### データディスカバリ

**データディスカバリ**:
- 関連するデータを効率的に検索・取得する能力
- データカタログがディスカバリプロセスを以下の機能で支援:

| 機能 | 説明 |
|------|------|
| **データアセットのインデックス化** | データセット、テーブル、ファイルの検索可能なインベントリ作成 |
| **メタデータ整理** | ソース詳細、フォーマット、更新頻度、ガバナンスポリシーを構造化 |
| **高度な検索・フィルタリング** | タグ、リネージ、利用パターンに基づくデータセット検索 |
| **データリネージ追跡** | データのライフサイクル全体（起点→変換→利用）を可視化 |

### メタデータの2つのカテゴリ

| カテゴリ | 内容 | 利用者 | 例 |
|---------|------|--------|-----|
| **Technical Metadata** | 構造・運用詳細（スキーマ、フォーマット、カラム定義、データ型、保存場所） | データエンジニア、IT チーム | BigQuery テーブルスキーマ（カラム名、データ型、パーティショニング戦略） |
| **Business Metadata** | ビジネス観点での意味・関連性（データ定義、ビジネス用語、所有権、利用ガイドライン） | 非技術系ユーザー | 「顧客取引データセット」（財務報告・不正検出に使用） |

---

## 7. Dataplex Catalog

### 概要

**Dataplex Catalog**:
- Google Cloud の Dataplex プラットフォーム内の統合メタデータ管理サービス
- Google Cloud およびオンプレミス環境全体のデータアセットインベントリを集約
- メタデータ、セキュリティポリシー、ガバナンスを標準化

> **移行情報**: Dataplex Catalog は旧 Cloud Data Catalog の後継であり、Dataplex に統合されている。Cloud Data Catalog は非推奨（deprecated）となり廃止予定。Dataplex Catalog の Aspect Type / Aspect は、旧 Cloud Data Catalog の Tag Template / Tag に対応する。

**サポートするデータソース**:
- **Google Cloud サービス**: BigQuery、Cloud Storage、Spanner、Cloud SQL、Bigtable、Pub/Sub、Vertex AI 等（自動取り込み）
- **カスタムソース**: 外部・オンプレミスシステム（カスタムエントリで統合）

### 主要コンポーネント

#### Entry と Entry Group

| コンポーネント | 説明 |
|--------------|------|
| **Entry** | データアセット（テーブル、ファイル、ストリーム）を表す単位。管理を容易にするメタデータを含む |
| **Entry Group** | 関連する Entry をビジネスドメイン単位でグループ化し、ナビゲーションを簡素化 |
| **System Entry Group** | Google Cloud リソース用に自動割り当て（例: `@bigquery` for BigQuery） |

#### Entry Type

**Entry Type**:
- データアセットのカテゴリ分類（例: BigQuery データセット、Cloud Storage ファイル）
- Google Cloud リソースには事前定義済み
- 外部・カスタムデータソースは手動定義が必要

**利点**:
- 標準化された Entry Type によりメタデータの一貫性と効率的管理を保証

#### Aspect と Aspect Type

| コンポーネント | 説明 |
|--------------|------|
| **Aspect** | Entry 内にメタデータを格納。技術詳細（スキーマ）とビジネスコンテキスト（データ分類）を保持 |
| **Aspect Type** | メタデータ収集の構造化テンプレート定義。統一的なガバナンスを保証 |

**事前定義 Aspect Type**:
- **Contacts**: データオーナー・スチュワード識別
- **Overview**: データアセット目的の要約
- **Schema**: Google Cloud データセット用に自動入力
- **Usage**: アクセス・利用パターン追跡

### 実装例: グローバル小売企業

**データソース構成**:
- BigQuery: 販売取引
- Cloud Storage: 顧客フィードバック
- オンプレミス PostgreSQL: 在庫追跡

**Entry Group とエントリ構造**:

```
Retail transactions group
├─ sales_data (BigQuery Table): 販売記録
└─ refund_data (BigQuery Table): 返金処理

Customer insights group
├─ customer_reviews (Cloud Storage Files): 顧客フィードバック
└─ support_tickets (Cloud Storage Files): カスタマーサービスログ

Inventory management group
├─ inventory_status (PostgreSQL Table): 現在の在庫レベル
└─ supplier_orders (PostgreSQL Table): サプライチェーン記録
```

**Entry Type 割り当て**:
- **システム生成** (Google Cloud リソース):
  - `sales_data`, `refund_data`: BigQuery table
  - `customer_reviews`, `support_tickets`: Cloud Storage file
- **カスタム定義** (非 Google Cloud):
  - `inventory_status`, `supplier_orders`: PostgreSQL table

**Aspect 適用例**:
- **Schema Aspect Type**: フィールド名、データ型、説明（Google Cloud リソースは自動抽出）
- **Data Quality Aspect Type**: カスタム定義（完全性スコア、データ鮮度、検証メトリクス）

---

## 8. データリネージ追跡

### データリネージの目的

データリネージ追跡により以下が可能:
- **起点の特定**: このデータはどこから来たか？
- **変換の追跡**: どのような変換が適用されたか？
- **アクセス監査**: 誰がこのデータにアクセスしたか？
- **品質評価**: このデータの品質は？

### 変換の可視化

**Cloud Data Fusion**:
- グラフィカルインターフェースでデータパイプラインを構築・監視
- ドラッグ&ドロップでコンポーネントを配置し、データフローを視覚表現
- 各ステージ（変換）をノードとして表示、ノード間の接続でデータフロー表現
- プレビューモードで各ステージのデータを検査可能

**その他のツール**:
- Dataflow、Apache Airflow もリネージ・変換可視化機能を提供

### Dataplex によるリネージ追跡

**Dataplex の機能**:
- データソース、処理ステップ、現在の場所、状態を含む包括的なリネージを可視化
- BigQuery 内の複雑な変換（クエリ、ビュー、データ操作）のリネージ追跡
- 完全な監査証跡を提供し、データ信頼性評価とデータ品質問題のルートコーズ分析を実現

**活用シーン**:
- **データ品質**: 信頼性評価、品質問題の根本原因分析
- **コンプライアンス**: 規制要件への準拠確認
- **ルートコーズ分析**: データ異常の発生源を追跡

**gcloud CLI でのリネージ確認例**:
```bash
# Dataplex API の有効化
gcloud services enable dataplex.googleapis.com

# エントリのリネージ情報を取得
gcloud dataplex entries lookup \
  --entry='projects/PROJECT_ID/locations/REGION/entryGroups/ENTRY_GROUP/entries/ENTRY_ID' \
  --aspect-types='ASPECT_TYPE'

# Dataplex Catalog でデータアセットを検索
gcloud dataplex entries search 'SEARCH_QUERY' \
  --project=PROJECT_ID
```

### データラベリングによる拡張

**データラベリング**:
- データセット、テーブル、ビューに記述的メタデータを付与
- データの目的・利用状況に関する貴重なコンテキストとインサイトを提供
- リネージ情報を補完し、データ理解を向上

---

## 9. 実装ベストプラクティス

### 将来を見据えた設計

| 設計原則 | 実装 |
|---------|------|
| **サーバーレス技術の活用** | Dataflow、BigQuery で需要変動に自動対応 |
| **スケーラブルストレージ** | BigQuery（ペタバイト規模対応）、Cloud Storage（実質無制限） |
| **データポータビリティ** | BigQuery Data Transfer Service、Storage Transfer Service、Transfer Appliance |

### データレジデンシー要件

**考慮事項**:
- 地域によるデータ保存場所の法的規制
- データ主権規制への準拠
- 適切なストレージロケーション選択

### ガバナンス統合

**高度なメタデータ管理**:
- Technical Metadata と Business Metadata の統合管理
- Dataplex Catalog による集約と標準化

**機密データ保護**:
- 暗号化、PII マスキング、アクセス制御

**明確なリネージ追跡**:
- データの完全なライフサイクル可視化
- 変換・操作の監査証跡確保

---

## 10. まとめ

### アーキテクチャ設計の鍵

1. **ビジネス要件の理解**: データソース、フォーマット、処理要件、消費パターンを明確化
2. **適切なツール選択**: ストレージとプロセッシングツールのマトリクスに基づく選定
3. **ポータビリティ確保**: Apache Beam、オープンソース標準、HCFS の活用
4. **ガバナンス実装**: Dataplex Catalog によるメタデータ管理とリネージ追跡

### 統合的なデータ管理

現代のデータ処理システムは以下を実現する必要がある:
- **柔軟性**: ビジネス要件の変化に適応
- **ポータビリティ**: マルチクラウド環境でのシームレスな移行
- **ガバナンス**: セキュア・コンプライアント・透明性のあるデータ管理
