# AI活用テスト戦略（AI-TESTING-STRATEGY.md）

AI（大規模言語モデル）をテストプロセスに統合する際の戦略的指針とマインドセット。

---

## Area of Effect モデル

### 人間とAIの協調モデル

テストにおけるAI活用は、**人間の強みとAIの強みを組み合わせる協調モデル**として捉える。

#### 人間の強み

- **目的設定**: テストの目標・優先度の決定
- **リスク判断**: ビジネス影響の評価、重要度の決定
- **批判的思考**: AIの出力に対する妥当性評価
- **コンテキスト理解**: プロジェクト固有の制約・前提条件の把握
- **探索的思考**: 予期しない問題の発見
- **倫理的判断**: セキュリティ・プライバシーに関する決定

#### AIの強み

- **パターン生成**: 大量のテストデータ、バリエーション生成
- **データ変換**: 形式変換（JSON→SQL、CSV→JSON等）の高速化
- **提案拡張**: 既存のリスクリストやテストアイデアの拡張
- **反復作業の高速化**: ボイラープレート、テンプレートコードの生成
- **多視点分析**: 複数の観点から同時に分析
- **ドキュメント化**: テストノート → 構造化レポート

### 核心原則

**人間がテストの方向性を決め、AIがそれを加速する。**

- ❌ AIにテスト戦略を丸投げ
- ✅ 人間が戦略を立て、AIが具体化を支援

### バランスの重要性

| 極端な状態 | 問題 |
|-----------|------|
| AI依存過多 | テストの方向性を失う、コンテキスト不足 |
| 人間のみ | テスト範囲の限定、時間制約による妥協 |
| **協調バランス** | **人間の判断 + AIの実行能力** |

---

## LLMの3つのテスト活用能力

| 能力 | 説明 | テストでの活用例 |
|------|------|----------------|
| **生成（Generative）** | 新しいコンテンツをゼロから生成 | • テストデータ生成<br>• リスク案のブレインストーミング<br>• テストアイデア生成<br>• 探索的テストのチャーター生成 |
| **変換（Transformation）** | データ形式・構造を変換 | • JSON ↔ XML ↔ SQL変換<br>• プログラミング言語変換<br>• テストノート → 構造化レポート<br>• 自然言語仕様 → テストケース構造 |
| **拡張（Enhancement）** | 既存材料を分析・補完 | • コードレビュー支援<br>• リスク分析の拡張<br>• コメント・ドキュメント生成<br>• 既存テストケースの網羅性チェック |

### 活用の核心

これらの能力を**具体的なコンテキストと明確な制約**とともに活用することで、テストプロセスが加速する。

---

## AI活用の判断基準

### 活用すべき場面

| シナリオ | 理由 |
|---------|------|
| **小さく具体的なタスク** | 明確な入出力、検証可能 |
| **明確なルール・仕様があるデータ生成** | JSON Schema、OpenAPI等で制約を定義 |
| **既存分析の拡張・補完** | 人間のリスク分析をAIが拡張 |
| **形式変換（データ、コード）** | 構造的な変換タスク |
| **ドキュメント・コメント生成** | 自然言語出力のブラッシュアップ |
| **リスク案のブレインストーミング** | 異なる視点からの提案 |

### 避けるべき場面

| シナリオ | 理由 |
|---------|------|
| **大きく曖昧なタスク** | 「テストを全部作って」→ コンテキスト不足 |
| **コンテキストなしの「テスト生成」** | プロジェクト固有情報の欠如 |
| **テスト戦略の丸投げ** | 目的設定は人間の責任 |
| **セキュリティクリティカルな判断** | 人間の最終判断が必須 |
| **機密データを含むプロンプト** | プライバシー・コンプライアンスリスク |
| **LLMの出力をそのまま採用** | 必ず検証・評価が必要 |

### 核心原則

**汎用プロンプト → 汎用な結果**

具体的なコンテキスト（仕様、制約、例）を提供するほど、AIの出力品質が向上する。

---

## リスクと注意点

### 1. ハルシネーション対策

**問題**: LLMは存在しない情報を「もっともらしく」生成する可能性がある。

**対策**:
- **check-for-assumption戦術**: プロンプト末尾に「入力が条件を満たさない場合は生成しないでください」と明示
- **出力の必ず検証**: AIの生成物をそのまま信頼せず、人間が確認
- **Few-shot学習**: 期待する出力例を1-2個提示して方向性を示す

### 2. データプライバシー

**問題**: LLMへの入力データは学習データや外部システムに送信される可能性がある。

**対策**:
- ❌ 機密情報、ユーザーデータ、本番データをLLMに送らない
- ✅ サンプルデータ、匿名化データ、仕様のみを使用
- ✅ プライベートモデル、ローカルLLMの検討

### 3. 自動化バイアス

**問題**: AIの出力を無条件に信頼してしまう心理的傾向。

**対策**:
- **批判的評価**: 「この出力は正しいか？」「仕様と一致するか？」「漏れはないか?」
- **テストの意図を保持**: AIが生成したテストケースが本来のテスト目的と合致するか確認
- **人間が最終判断**: AIは提案者、人間が決定者

### 4. コンテキスト不足問題

**問題**: AIはプロジェクト固有のコンテキスト（過去の経緯、暗黙の前提、ビジネス制約）を持たない。

**対策**:
- **具体的な仕様・制約の明示**: プロンプトに含める
- **コンテキスト埋め込み**: RAG（Retrieval-Augmented Generation）で関連ドキュメントを自動注入
- **モデル活用**: システムの視覚モデル（図）を作成してから具体的なプロンプトを構築

---

## テスト向けプロンプト設計原則

### 1. デリミタで構造化

テスト対象の仕様、入力データ、期待出力をデリミタ（`###`, `"""`, `---`等）で明確に区切る。

```
以下の仕様に基づいてテストケースを生成してください。

### 仕様
ユーザー登録APIは以下のルールを検証する:
- emailフィールドは必須かつ有効な形式
- passwordは8文字以上
- usernameは3-20文字の英数字

### 出力形式
JSON配列で5つのテストケースを生成
```

### 2. 出力形式の指定

期待する形式を明示する（JSON、テーブル、コード等）。

```
出力形式: 以下のJSON構造で配列を生成
[
  {
    "input": {...},
    "expected": {...},
    "description": "..."
  }
]
```

### 3. 仮定チェック

生成条件を満たさない場合の挙動を指定する。

```
注意: 入力が条件を満たさない場合は生成しないでください。
条件を満たさないと判断した場合は「生成できません: <理由>」と返してください。
```

### 4. Few-shot学習

期待するテストケースの例を1-2個提示する。

```
期待する形式の例:
{
  "input": {"email": "valid@example.com", "password": "securePass123"},
  "expected": {"status": 200, "message": "User created"},
  "description": "有効な入力での正常系"
}

同様の形式で5つのテストケースを生成してください。
```

### 5. ステップ分割

複雑なテストタスクをサブタスクに分解し、段階的に実行する。

```
ステップ1: 仕様から入力パラメータのリストを抽出してください。
ステップ2: 各パラメータの境界値を特定してください。
ステップ3: 境界値に基づいてテストケースを生成してください。
```

### 6. 自己評価

LLMに生成物の妥当性を確認させる。

```
生成したテストケースが以下を満たすか確認してください:
- すべてのルールをカバーしているか
- 境界値が含まれているか
- 不正入力のケースが含まれているか

確認後、テストケースと評価結果を出力してください。
```

---

## まとめ

AI活用テストの成功の鍵:

1. **人間が主導、AIが加速** - テスト戦略は人間が決定
2. **具体的なコンテキスト** - 仕様、制約、例を明示
3. **批判的評価** - AIの出力を必ず検証
4. **適切なタスク分割** - 小さく具体的なタスクで活用
5. **データプライバシー** - 機密情報を含めない
6. **バランス** - AI依存過多と人間のみの両極端を避ける
